## Содержание <!-- omit in toc -->

- [Строительные блоки конкурентности Go](#строительные-блоки-конкурентности-go)
  - [Горутины](#горутины)

## Строительные блоки конкурентности Go

### Горутины

Горутины — это одна одна из самых основных единиц организации программы Go,
поэтому важно понимать, что это такое и как они работают. Фактически, в каждой
программе Go есть по крайней мере одна горутина: _основная (main) горутина_,
которая автоматически создаётся и запускается, когда запускается процесс.
Практически в любой программе, вероятно, придётся рано или поздно прибегнуть к
использованию горутин для решения задачи.

Проще говоря, горутина — это функция, которая выполняется конкурентно (не
обязательно параллельно!) с другим кодом. Мы можем запустить её просто добавив
ключевое слово `go` перед функцией:

```go
func main() {
  go sayHello()
  // продолжаем делать другие вещи
}

func sayHello() {
  fmt.Println("hello")
}
```

Анонимные функции тоже сработают. Пример, который делает то же самое, но вместо
создания горутины из обычной функции мы создаём горутину из анонимной функции:

```go
go func() {
  fmt.Println("hello")
}() // мы должны сразу же вызывать анонимную функцию при ключевом слове go
// продолжаем делать другие вещи
```

В качестве альтернативы мы можем присвоить функцию переменной и вызывать
анонимную функцию следующим образом:

```go
sayHello := func() {
  fmt.Println("hello")
}
go sayHello()
// продолжаем делать другие вещи
```

Замечательно! Мы можем создавать конкурентный блок логики с помощью функции и
единственного ключевого слова. Это всё, что нужно знать, чтобы запустить
горутину. Конечно, многое можно сказать о том, как правильно использовать
горутины, синхронизировать, организовать, но это действительно всё, что нужно
знать, чтобы начать их использовать.

Но что происходит за кулисами? Как горутины работают на самом деле? Это потоки
операционной системе? Это
[_зелёные потоки_](https://ru.wikipedia.org/wiki/Green_threads)? Как много мы
можем создать?

Горутины уникальны для Go (хотя в некоторых языках есть похожие примитивы
конкурентности). Это не потоки операционной системы, и это не совсем зелёные
потоки — потоки, управляемые средой выполнения языка. Они представляют собой
более высокий уровень абстракции, известный как сопрограммы (**к**орутины,
coroutines). Сопрограммы — это просто конкурентные подпрограммы (функции,
замыкания или методы в Go), которые не являются вытесняющими, то есть их нельзя
прервать. Вместо этого сопрограммы имеют несколько точек, в которых возможна
приостановка или возврат к исполнению.

Что делает горутины уникальными для Go — так это их глубокая интеграция в среду
выполнения Go. Горутины не определяют свои собственные точки приостановки или
повторного кода, а сама среда выполнения Go наблюдает за поведением горутин во
время выполнения и автоматически приостанавливает их, когда они блокируются, а
затем возобновляет их, когда они разблокируются. В некотором смысле это делает
их доступными для вытеснения, но только в тех точках, где они заблокированы. Это
элегантное партнёрство между средой выполнение и логикой горутины. Таким
образом, горутины можно рассматривать как особый класс сопрограмм.

Корутины и, следовательно, горутины являются неявно конкурентными конструкциями,
но конкурентность не является свойством сопрограммы: что-то должно одовременно
размещать несколько корутин и предоставлять каждой возможность выполнения —
иначе они бы не были конкурентными. Следует обратить внимание, что это не
означает, что программы неявно _параллельны_. Вполне возможно, что несколько
корутин будут выполняться последовательно, создавая иллюзию параллелизма, и на
самом деле это происходит в Go.

<!-- // TODO: ссылка на "позже" -->

Механизм Go для размещения горутин — это реализация так называемого _M:N
планировщика_ (_M:N scheduler_), что означает, что он отображает M зелёных
потоков на N потоков операционной системы. Затем горутины планируются на зелёные
потоки. Когда горутин больше, чем доступных зелёных потоков, планировщик
распределяет горутины по доступным потокам операционной системы и гарантирует,
что при блокировке этих горутин могут быть запущены другие горутины. То, как это
работает, будет рассмотрено позже.

Go следует модели конкурентности, называемой fork-join. Слово fork означает, что
в любой точке программы, она может отделить дочернюю ветвь выполнения для
конкурентного запуска с родительской. Слово join означает, что в какой-то точке
в будущем эти конкурентные ветви выполнения снова соединятся вместе. Место, где
дочерняя ветвь соединяется с родительской, называется точкой соединения (join
point). Графическое изображение этого:

<!-- TODO: добавить перевод сноски -->

![Точка соединения](images/join-point.svg)

Оператор `go` — это то, как Go выполняет fork, а форкнутые потоки выполнения —
это горутины. Вернёмся к нашему примеру с горутиной:

```go
sayHello := func() {
  fmt.Println("hello")
}
go sayHello()
// продолжаем делать другие вещи
```

Здесь функция `sayHello` будет запущена в своей собственной горутине, а
остальная часть программы продолжит выполнение. В этом примере нет точки
соединения. Горутина, выполняющая `sayHello`, просто завершит работу в какое-то
неопределённое время в будущем, а остальная часть программы уже будет продолжать
выполнение.

Однако в этом примере есть одна проблема: код написан так, что неизвестно, будет
ли функция `sayHello` вообще выполнена. Горутина будет создана и запланирована
средой выполнения Go, но она может не получить возможность запуститься до того,
как основная горутина завершится.

Действительно, поскольку для простоты мы опускаем остальную часть функции
`main`, при запуске этого примера, почти наверняка программа завершит выполнение
до того, как будет запущена горутина с вызовом `sayHello`. В результате мы можем
не увидеть `hello` в stdout. Мы могли бы указать `time.Sleep` после создания
горутины. _Но следует помнить, что на самом деле это не создаёт точку
соединения, а только состояние гонки_. Мы лишь увеличим вероятность того, что
горутина будет запущена перед завершением программы, но не гарантируем этого.
_Точка соединения — это то, что гарантирует корректность программы и устраняет
состояние гонки_.

Для создания точки соединения мы должны синхронизировать горутину `main`, а
затем горутину `sayHello`. Это можно сделать несколькими способами, но мы
воспользуемся `sync.WaitGroup`:

```go
var wg sync.WaitGroup
sayHello := func() {
  defer wg.Done()
  fmt.Println("hello")
}
wg.Add(1)
go sayHello()
wg.Wait() // это точка соединения
```

Этот код гарантированно выведет `hello`.

В этом примере горутина `main` будет детерминированно блокироваться до тех пор,
пока горутина с вызовом `sayHello` не завершит работу.

> В этом разделе для точек соединения будет использоваться `sync.WaitGroup` без
> объяснения работы. Существует множество способов создания точек соединения,
> они будут рассмотрены позже.

В наших примерах мы использовали много анонимных функций для быстрого создания
примеров горутин. Давайте обратим внимания на замыкания. Замыкания замыкаются
вокруг лексической области, в которой они созданы, тем самым захватывая
переменные. Если мы запустим замыкание в горутине, замыкание будет работать с
копией переменных или с их исходными ссылками? Проверим:

```go
var wg sync.WaitGroup
salutation := "hello"
wg.Add(1)
go func() {
  defer wg.Done()
  salutation = "welcome" // горутина меняет значение переменной salutation
}()
wg.Wait()
fmt.Println(salutation)
```

Результат:

<!-- markdownlint-disable MD040 -->

```
welcome
```

<!-- markdownlint-enable MD040 -->

Оказывается, горутины выполняются в том же адресном пространстве, где они были
созданы, и поэтому наша программа выводит `welcome`. Попробуем другой пример
([`code-samples/salutation-1.go`](code-samples/salutation-1.go)):

```go
var wg sync.WaitGroup
for _, salutation := range []string{"hello", "greetings", "good day"} {
  wg.Add(1)
  go func() {
    defer wg.Done()
    fmt.Println(salutation)
  }()
}
wg.Wait()
```

Кажется, что результатом будет `hello`, `greetings`, `good day` в
недетерминированном порядке. Но на самом деле:

<!-- markdownlint-disable MD040 -->

```
good day
good day
good day
```

<!-- markdownlint-enable MD040 -->

В этом примере горутина выполняет замыкание, которое замкнуто на итерационной
переменной `salutation` строкового типа. По мере итерации по циклу переменной
`salutation` присваивается следующее значение из среза. Поскольку
запланированные горутины могут запускаться _в любой момент в будущем_,
неопределённо, какие значения будут выведены из горутины. Существует большая
вероятность того, что цикл успеет завершиться до начала выполнения какой-либо из
горутин. В таком случае переменная `salutation` выйдет из области видимости. Что
произойдёт в этом случае? Могут ли горутины всё ещё ссылаться на то, что вышло
из области видимости? Не будут ли горутины обращаться к памяти, которая
потенциально может быть очищена сборщиком мусора?

Среда выполнения Go достаточно наблюдательна, чтобы понимать, что ссылка на
переменную приветствия всё ещё сохраняется, и поэтому перенесёт память в кучу,
чтобы горутины могли продолжить обращаться к ней.

Обычно цикл завершается до того, как начинают выполняться какие-либо горутины
(но это не гарантируется), поэтому приветствие переносится в кучу и к этому
моменту содержит ссылку на последнее значение — `good day`. Правильный способ
написать этот цикл — передать копию `salutation` в замыкание, чтобы к моменту
запуска горутины она работала с данными из своей итерации цикла
([`code-samples/salutation-2.go`](code-samples/salutation-2.go)):

```go
var wg sync.WaitGroup
for _, salutation := range []string{"hello", "greetings", "good day"} {
  wg.Add(1)
  go func(salutation string) { // принимаем параметр как в обычную функцию
    defer wg.Done()
    fmt.Println(salutation)
  }(salutation)
  // передаём текущую итерационную переменную в замыкание, создаётся копия
  // структуры строки
}
wg.Wait()
```

Поскольку горутины работают в одном адресном пространстве и просто содержат
функции, использование горутин является естественным расширением написания
неконкурентного кода. Компилятор Go отлично заботится о закреплении переменных в
памяти, чтобы горутины случайно не обращались к освобождённой памяти, что
позволяет разработчикам сосредоточиться на своей задаче вместо управления
памятью; однако это не означает полной свободы действий.

<!-- TODO: ссылки (две!) на позже -->

Поскольку несколько горутин могут работать с одним и тем же адресным
пространством, всё равно приходится беспокоиться о синхронизации. Как уже было
описано, можно выбрать либо синхронизацию доступа к общей памяти, к которой
обращаются горутины, либо примитивы CSP для совместного использования памяти
посредством коммуникации. Эти методы мы обсудим позже.

Ещё одним преимуществом горутин является то, что они необычайно лёгкие. Выдержка
из [Go FAQ](https://go.dev/doc/faq#goroutines):

> Только что созданной горутине отводится несколько килобайт, чего почти всегда
> достаточно. Когда это не так, среда выполнения автоматически увеличивает (и
> сокращает) память для хранения стека, позволяя множеству горутин существовать
> в скромном объёме памяти. Затраты процессорного времени составляют в среднем
> около трёх недорогих инструкций на вызов функции. Вполне практично создавать
> сотни тысяч горутин в одном адресном пространстве. Если бы горутины были
> просто потоками, системные ресурсы исчерпались бы уже при значительно меньшем
> количестве.
>
> _A newly minted goroutine is given a few kilobytes, which is almost always
> enough. When it isn't, the run-time grows (and shrinks) the memory for storing
> the stack automatically, allowing many goroutines to live in a modest amount
> of memory. The CPU overhead averages about three cheap instructions per
> function call. It is practical to create hundreds of thousands of goroutines
> in the same address space. If goroutines were just threads, system resources
> would run out at a much smaller number._

Несколько килобайт на горутину — это очень неплохо. Убедимся в этом, но прежде
чем мы это сделаем, следует знать об одной интересной вещи, связанной с
горутинами: сборщик мусора ничего не делает для сборы горутин, которые были
каким-либо образом заброшены. Если написать следующее:

```go
go func() {
  // операция, которая блокирует горутину навсегда
}
// продолжаем делать другие вещи
```

<!-- TODO: ссылка на "позже" -->

Горутина здесь будет работать до тех пор, пока процесс не завершится. Мы
обсудим, как решить эту проблему позже. Воспользуемся этим в следующем примере,
чтобы фактически измерить размер горутин.

В следующем примере мы объединяем факт того, что горутины не собираются
сборщиком мусора, с возможностью среды выполнения анализировать саму себя и
измерить количество выделенной памяти до и после создания горутины
([`code-samples/goroutines-mem.go`](code-samples/goroutines-mem.go)):

```go
memConsumed := func() uint64 {
  runtime.GC()
  var s runtime.MemStats
  runtime.ReadMemStats(&s)
  return s.Sys
}

var c <-chan interface{}
var wg sync.WaitGroup
// нам нужна горутина, которая никогда не завершится, чтобы хранить их в
// определённом количестве в памяти для измерений
noop := func() {
  wg.Done()
  <-c
}

// задаём число горутин для создания.
// будем использовать закон больших чисел, чтобы асимптотически приблизиться к
// размеру горутины
const goroutinesCount = 1e4
wg.Add(goroutinesCount)
// измеряем объём потребляемой памяти перед созданием горутин
before := memConsumed()
for i := 0; i < goroutinesCount; i++ {
  go noop()
}
wg.Wait()
// измеряем объём потребляемой памяти после создания горутин
after := memConsumed()
fmt.Printf("%.3fkb\n", float64(after-before)/goroutinesCount/1000)
```

Результат:

<!-- markdownlint-disable MD040 -->

```
2.576kb
```

<!-- markdownlint-enable MD040 -->

Похоже, документация верна. Это просто пустые горутины, которые ничего не
делают, но это всё равно даёт нам представление о количестве горутин, которые,
вероятно, можно создать. Следующая таблица приводит приблизительные оценки
количества горутин, которые можно создать на 64-битном CPU без использования
swap'а (файла подкачки):

| Память (ГБ) | Количество горутин / 100 000 | Порядок величины |
| ----------- | ---------------------------- | ---------------- |
| $2^0$       | 3,718                        | 3                |
| $2^1$       | 7,436                        | 3                |
| $2^2$       | 14,873                       | 6                |
| $2^3$       | 29,746                       | 6                |
| $2^4$       | 59,492                       | 6                |
| $2^5$       | 118,983                      | 6                |
| $2^6$       | 237,967                      | 6                |
| $2^7$       | 475,934                      | 6                |
| $2^8$       | 951,867                      | 6                |
| $2^9$       | 1903,735                     | 9                |

Но что-то может испортить нам настроение — это переключение контекста, когда
что-то, на чём размещён конкурентный процесс, должно сохранить своё состояние,
чтобы переключиться на запуск другого конкурентного процесса. Если у нас слишком
много конкурентных процессов, мы можем потратить всё процессорное время на
переключение контекста между ними и никогда не выполнить никакой полезной
работы. На уровне операционной системы, с потоками, это может быть довольно
затратным. Операционная система должна сохранить такие вещи, как значения
регистров, таблицы поиска и карты памяти, чтобы успешно переключиться обратно на
текущий поток в нужное время. Затем она должна загрузить ту же информацию для
пришедшего потока.

Переключение контекста на стороне софта (software) сравнительно гораздо дешевле.
При использовании программно определённого планировщика, среда выполнения может
быть более избирательна в том, что сохраняется для восстановления, как оно
сохраняется и когда происходит необходимость в сохранении. Давайте посмотрим на
относительную производительность переключения контекста на конкретной машине
между потоками операционной системы и горутинами. Сначала воспользуемся
встроенным набором тестов производительности в Linux, чтобы измерить, сколько
времени занимает отправка сообщения между двумя потоками на одном ядре:

```bash
taskset -c 0 perf bench sched pipe -T
```

> Чтобы тесты заработали нужно установить `linux-tools` для конкретного
> дистрибутива Linux и конкретной версии ядра.

Результат:

<!-- markdownlint-disable MD040 -->

```
# Running 'sched/pipe' benchmark:
# Executed 1000000 pipe operations between two threads

     Total time: 6.168 [sec]

       6.168206 usecs/op
         162121 ops/sec
```

<!-- markdownlint-enable MD040 -->

Этот бенчмарк фактически измеряет время, необходимое для отправки и получения
сообщения в потоке, поэтому нужно поделить результат на 2. Это даёт **3,084
микросекунд** на переключение контекста. Кажется не так уж плохо, но посмотрим
на переключения контекста между горутинами.

Построим аналогичный бенчмарк, используя Go. Используем несколько вещей, которые
ещё не обсуждались. В следующем примере будут созданы две горутины и отправлено
сообщение между ними
([`code-samples/context-switch_test.go`](code-samples/context-switch_test.go)):

```go
func BenchmarkContextSwitch(b *testing.B) {
  var wg sync.WaitGroup
  begin := make(chan struct{})
  c := make(chan struct{})

  var token struct{}
  sender := func() { // отправитель
    defer wg.Done()
    // ждём пока не будет команды начинать.
    // мы не хотим, чтобы затраты на настройку и запуск каждой горутины
    // учитывались при измерении
    <-begin
    for i := 0; i < b.N; i++ {
      // отправляем сообщения в горутину-получатель.
      // struct{}{} называется пустой структурой и не занимает памяти
      c <- token
    }
  }

  receiver := func() { // получатель
    defer wg.Done()
    <-begin
    for i := 0; i < b.N; i++ {
      <-c // получаем сообщение и ничего с ним не делаем
    }
  }

  wg.Add(2)
  go sender()
  go receiver()
  b.StartTimer() // запускаем таймер производительности
  close(begin)   // даём команду начинать двум горутинам
  wg.Wait()
}
```

Запустим бенчмарк, указав, что мы хотим использовать только один CPU, чтобы тест
был аналогичен бенчмарку Linux, с помощью следующей команды:

```bash
go test -bench=. -cpu=1 code-samples/context-switch_test.go
```

Результат:

<!-- markdownlint-disable MD040 -->

```
BenchmarkContextSwitch   4932397               241.2 ns/op
PASS
ok      command-line-arguments  1.442s
```

<!-- markdownlint-enable MD040 -->

<!-- TODO: выигрыш в процентах -->
<!-- TODO: перефразировать фразу о верхнем пределе -->

241 наносекунд на переключение контекста, воу! Это **0,241 микросекунд**, в разы
быстрее. Трудно говорить о том, сколько горутин вызовут слишком частое
переключение контекста, но можно с уверенностью сказать, что верхний предел,
скорее всего, не станет препятствием для использования горутин.

Создание горутин обходится очень дёшево и нам следует всерьёз обсуждать их
стоимость только в том случае, когда мы доказали, что они являются основной
причиной проблем с производительностью.
