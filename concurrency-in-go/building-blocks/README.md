## Содержание <!-- omit in toc -->

- [Строительные блоки конкурентности Go](#строительные-блоки-конкурентности-go)
  - [Горутины](#горутины)
  - [Пакет `sync`](#пакет-sync)
    - [`WaitGroup`](#waitgroup)
    - [`Mutex` и `RWMutex`](#mutex-и-rwmutex)
    - [`Cond`](#cond)
    - [`Once`](#once)
    - [`Pool`](#pool)

## Строительные блоки конкурентности Go

### Горутины

Горутины — это одна одна из самых основных единиц организации программы Go,
поэтому важно понимать, что это такое и как они работают. Фактически, в каждой
программе Go есть по крайней мере одна горутина: _основная (main) горутина_,
которая автоматически создаётся и запускается, когда запускается процесс.
Практически в любой программе, вероятно, придётся рано или поздно прибегнуть к
использованию горутин для решения задачи.

Проще говоря, горутина — это функция, которая выполняется конкурентно (не
обязательно параллельно!) с другим кодом. Мы можем запустить её просто добавив
ключевое слово `go` перед функцией:

```go
func main() {
  go sayHello()
  // продолжаем делать другие вещи
}

func sayHello() {
  fmt.Println("hello")
}
```

Анонимные функции тоже сработают. Пример, который делает то же самое, но вместо
создания горутины из обычной функции мы создаём горутину из анонимной функции:

```go
go func() {
  fmt.Println("hello")
}() // мы должны сразу же вызывать анонимную функцию при ключевом слове go
// продолжаем делать другие вещи
```

В качестве альтернативы мы можем присвоить функцию переменной и вызывать
анонимную функцию следующим образом:

```go
sayHello := func() {
  fmt.Println("hello")
}
go sayHello()
// продолжаем делать другие вещи
```

Замечательно! Мы можем создавать конкурентный блок логики с помощью функции и
единственного ключевого слова. Это всё, что нужно знать, чтобы запустить
горутину. Конечно, многое можно сказать о том, как правильно использовать
горутины, синхронизировать, организовать, но это действительно всё, что нужно
знать, чтобы начать их использовать.

Но что происходит за кулисами? Как горутины работают на самом деле? Это потоки
операционной системе? Это
[_зелёные потоки_](https://ru.wikipedia.org/wiki/Green_threads)? Как много мы
можем создать?

Горутины уникальны для Go (хотя в некоторых языках есть похожие примитивы
конкурентности). Это не потоки операционной системы, и это не совсем зелёные
потоки — потоки, управляемые средой выполнения языка. Они представляют собой
более высокий уровень абстракции, известный как сопрограммы (**к**орутины,
coroutines). Сопрограммы — это просто конкурентные подпрограммы (функции,
замыкания или методы в Go), которые не являются вытесняющими, то есть их нельзя
прервать. Вместо этого сопрограммы имеют несколько точек, в которых возможна
приостановка или возврат к исполнению.

Что делает горутины уникальными для Go — так это их глубокая интеграция в среду
выполнения Go. Горутины не определяют свои собственные точки приостановки или
повторного кода, а сама среда выполнения Go наблюдает за поведением горутин во
время выполнения и автоматически приостанавливает их, когда они блокируются, а
затем возобновляет их, когда они разблокируются. В некотором смысле это делает
их доступными для вытеснения, но только в тех точках, где они заблокированы. Это
элегантное партнёрство между средой выполнение и логикой горутины. Таким
образом, горутины можно рассматривать как особый класс сопрограмм.

Корутины и, следовательно, горутины являются неявно конкурентными конструкциями,
но конкурентность не является свойством сопрограммы: что-то должно одовременно
размещать несколько корутин и предоставлять каждой возможность выполнения —
иначе они бы не были конкурентными. Следует обратить внимание, что это не
означает, что программы неявно _параллельны_. Вполне возможно, что несколько
корутин будут выполняться последовательно, создавая иллюзию параллелизма, и на
самом деле это происходит в Go.

<!-- TODO: ссылка на "позже" -->

Механизм Go для размещения горутин — это реализация так называемого _M:N
планировщика_ (_M:N scheduler_), что означает, что он отображает M зелёных
потоков на N потоков операционной системы. Затем горутины планируются на зелёные
потоки. Когда горутин больше, чем доступных зелёных потоков, планировщик
распределяет горутины по доступным потокам операционной системы и гарантирует,
что при блокировке этих горутин могут быть запущены другие горутины. То, как это
работает, будет рассмотрено позже.

Go следует модели конкурентности, называемой fork-join. Слово fork означает, что
в любой точке программы, она может отделить дочернюю ветвь выполнения для
конкурентного запуска с родительской. Слово join означает, что в какой-то точке
в будущем эти конкурентные ветви выполнения снова соединятся вместе. Место, где
дочерняя ветвь соединяется с родительской, называется точкой соединения (join
point). Графическое изображение этого:

<!-- TODO: добавить перевод сноски -->

![Точка соединения](images/join-point.svg)

Оператор `go` — это то, как Go выполняет fork, а форкнутые потоки выполнения —
это горутины. Вернёмся к нашему примеру с горутиной:

```go
sayHello := func() {
  fmt.Println("hello")
}
go sayHello()
// продолжаем делать другие вещи
```

Здесь функция `sayHello` будет запущена в своей собственной горутине, а
остальная часть программы продолжит выполнение. В этом примере нет точки
соединения. Горутина, выполняющая `sayHello`, просто завершит работу в какое-то
неопределённое время в будущем, а остальная часть программы уже будет продолжать
выполнение.

Однако в этом примере есть одна проблема: код написан так, что неизвестно, будет
ли функция `sayHello` вообще выполнена. Горутина будет создана и запланирована
средой выполнения Go, но она может не получить возможность запуститься до того,
как основная горутина завершится.

Действительно, поскольку для простоты мы опускаем остальную часть функции
`main`, при запуске этого примера, почти наверняка программа завершит выполнение
до того, как будет запущена горутина с вызовом `sayHello`. В результате мы можем
не увидеть `hello` в stdout. Мы могли бы указать `time.Sleep` после создания
горутины. _Но следует помнить, что на самом деле это не создаёт точку
соединения, а только состояние гонки_. Мы лишь увеличим вероятность того, что
горутина будет запущена перед завершением программы, но не гарантируем этого.
_Точка соединения — это то, что гарантирует корректность программы и устраняет
состояние гонки_.

Для создания точки соединения мы должны синхронизировать горутину `main`, а
затем горутину `sayHello`. Это можно сделать несколькими способами, но мы
воспользуемся `sync.WaitGroup`:

```go
var wg sync.WaitGroup
sayHello := func() {
  defer wg.Done()
  fmt.Println("hello")
}
wg.Add(1)
go sayHello()
wg.Wait() // это точка соединения
```

Этот код гарантированно выведет `hello`.

В этом примере горутина `main` будет детерминированно блокироваться до тех пор,
пока горутина с вызовом `sayHello` не завершит работу.

> В этом разделе для точек соединения будет использоваться `sync.WaitGroup` без
> объяснения работы. Существует множество способов создания точек соединения,
> они будут рассмотрены позже.

В наших примерах мы использовали много анонимных функций для быстрого создания
примеров горутин. Давайте обратим внимания на замыкания. Замыкания замыкаются
вокруг лексической области, в которой они созданы, тем самым захватывая
переменные. Если мы запустим замыкание в горутине, замыкание будет работать с
копией переменных или с их исходными ссылками? Проверим:

```go
var wg sync.WaitGroup
salutation := "hello"
wg.Add(1)
go func() {
  defer wg.Done()
  salutation = "welcome" // горутина меняет значение переменной salutation
}()
wg.Wait()
fmt.Println(salutation)
```

Результат:

<!-- markdownlint-disable MD040 -->

```
welcome
```

<!-- markdownlint-enable MD040 -->

Оказывается, горутины выполняются в том же адресном пространстве, где они были
созданы, и поэтому наша программа выводит `welcome`. Попробуем другой пример
([`code-samples/salutation-1.go`](code-samples/salutation-1.go)):

```go
var wg sync.WaitGroup
for _, salutation := range []string{"hello", "greetings", "good day"} {
  wg.Add(1)
  go func() {
    defer wg.Done()
    fmt.Println(salutation)
  }()
}
wg.Wait()
```

Кажется, что результатом будет `hello`, `greetings`, `good day` в
недетерминированном порядке. Но на самом деле:

<!-- markdownlint-disable MD040 -->

```
good day
good day
good day
```

<!-- markdownlint-enable MD040 -->

В этом примере горутина выполняет замыкание, которое замкнуто на итерационной
переменной `salutation` строкового типа. По мере итерации по циклу переменной
`salutation` присваивается следующее значение из среза. Поскольку
запланированные горутины могут запускаться _в любой момент в будущем_,
неопределённо, какие значения будут выведены из горутины. Существует большая
вероятность того, что цикл успеет завершиться до начала выполнения какой-либо из
горутин. В таком случае переменная `salutation` выйдет из области видимости. Что
произойдёт в этом случае? Могут ли горутины всё ещё ссылаться на то, что вышло
из области видимости? Не будут ли горутины обращаться к памяти, которая
потенциально может быть очищена сборщиком мусора?

Среда выполнения Go достаточно наблюдательна, чтобы понимать, что ссылка на
переменную приветствия всё ещё сохраняется, и поэтому перенесёт память в кучу,
чтобы горутины могли продолжить обращаться к ней.

Обычно цикл завершается до того, как начинают выполняться какие-либо горутины
(но это не гарантируется), поэтому приветствие переносится в кучу и к этому
моменту содержит ссылку на последнее значение — `good day`. Правильный способ
написать этот цикл — передать копию `salutation` в замыкание, чтобы к моменту
запуска горутины она работала с данными из своей итерации цикла
([`code-samples/salutation-2.go`](code-samples/salutation-2.go)):

```go
var wg sync.WaitGroup
for _, salutation := range []string{"hello", "greetings", "good day"} {
  wg.Add(1)
  go func(salutation string) { // принимаем параметр как в обычную функцию
    defer wg.Done()
    fmt.Println(salutation)
  }(salutation)
  // передаём текущую итерационную переменную в замыкание, создаётся копия
  // структуры строки
}
wg.Wait()
```

Поскольку горутины работают в одном адресном пространстве и просто содержат
функции, использование горутин является естественным расширением написания
неконкурентного кода. Компилятор Go отлично заботится о закреплении переменных в
памяти, чтобы горутины случайно не обращались к освобождённой памяти, что
позволяет разработчикам сосредоточиться на своей задаче вместо управления
памятью; однако это не означает полной свободы действий.

<!-- TODO: ссылки (две!) на позже -->

Поскольку несколько горутин могут работать с одним и тем же адресным
пространством, всё равно приходится беспокоиться о синхронизации. Как уже было
описано, можно выбрать либо синхронизацию доступа к общей памяти, к которой
обращаются горутины, либо примитивы CSP для совместного использования памяти
посредством коммуникации. Эти методы мы обсудим позже.

Ещё одним преимуществом горутин является то, что они необычайно лёгкие. Выдержка
из [Go FAQ](https://go.dev/doc/faq#goroutines):

> Только что созданной горутине отводится несколько килобайт, чего почти всегда
> достаточно. Когда это не так, среда выполнения автоматически увеличивает (и
> сокращает) память для хранения стека, позволяя множеству горутин существовать
> в скромном объёме памяти. Затраты процессорного времени составляют в среднем
> около трёх недорогих инструкций на вызов функции. Вполне практично создавать
> сотни тысяч горутин в одном адресном пространстве. Если бы горутины были
> просто потоками, системные ресурсы исчерпались бы уже при значительно меньшем
> количестве.
>
> _A newly minted goroutine is given a few kilobytes, which is almost always
> enough. When it isn't, the run-time grows (and shrinks) the memory for storing
> the stack automatically, allowing many goroutines to live in a modest amount
> of memory. The CPU overhead averages about three cheap instructions per
> function call. It is practical to create hundreds of thousands of goroutines
> in the same address space. If goroutines were just threads, system resources
> would run out at a much smaller number._

Несколько килобайт на горутину — это очень неплохо. Убедимся в этом, но прежде
чем мы это сделаем, следует знать об одной интересной вещи, связанной с
горутинами: сборщик мусора ничего не делает для сборы горутин, которые были
каким-либо образом заброшены. Если написать следующее:

```go
go func() {
  // операция, которая блокирует горутину навсегда
}
// продолжаем делать другие вещи
```

<!-- TODO: ссылка на "позже" -->

Горутина здесь будет работать до тех пор, пока процесс не завершится. Мы
обсудим, как решить эту проблему позже. Воспользуемся этим в следующем примере,
чтобы фактически измерить размер горутин.

В следующем примере мы объединяем факт того, что горутины не собираются
сборщиком мусора, с возможностью среды выполнения анализировать саму себя и
измерить количество выделенной памяти до и после создания горутины
([`code-samples/goroutines-mem.go`](code-samples/goroutines-mem.go)):

```go
memConsumed := func() uint64 {
  runtime.GC()
  var s runtime.MemStats
  runtime.ReadMemStats(&s)
  return s.Sys
}

var c <-chan interface{}
var wg sync.WaitGroup
// нам нужна горутина, которая никогда не завершится, чтобы хранить их в
// определённом количестве в памяти для измерений
noop := func() {
  wg.Done()
  <-c
}

// задаём число горутин для создания.
// будем использовать закон больших чисел, чтобы асимптотически приблизиться к
// размеру горутины
const goroutinesCount = 1e4
wg.Add(goroutinesCount)
// измеряем объём потребляемой памяти перед созданием горутин
before := memConsumed()
for i := 0; i < goroutinesCount; i++ {
  go noop()
}
wg.Wait()
// измеряем объём потребляемой памяти после создания горутин
after := memConsumed()
fmt.Printf("%.3fkb\n", float64(after-before)/goroutinesCount/1000)
```

Результат:

<!-- markdownlint-disable MD040 -->

```
2.576kb
```

<!-- markdownlint-enable MD040 -->

Похоже, документация верна. Это просто пустые горутины, которые ничего не
делают, но это всё равно даёт нам представление о количестве горутин, которые,
вероятно, можно создать. Следующая таблица приводит приблизительные оценки
количества горутин, которые можно создать на 64-битном CPU без использования
swap'а (файла подкачки):

| Память (ГБ) | Количество горутин / 100 000 | Порядок величины |
| ----------- | ---------------------------- | ---------------- |
| $2^0$       | 3,718                        | 3                |
| $2^1$       | 7,436                        | 3                |
| $2^2$       | 14,873                       | 6                |
| $2^3$       | 29,746                       | 6                |
| $2^4$       | 59,492                       | 6                |
| $2^5$       | 118,983                      | 6                |
| $2^6$       | 237,967                      | 6                |
| $2^7$       | 475,934                      | 6                |
| $2^8$       | 951,867                      | 6                |
| $2^9$       | 1903,735                     | 9                |

Но что-то может испортить нам настроение — это переключение контекста, когда
что-то, на чём размещён конкурентный процесс, должно сохранить своё состояние,
чтобы переключиться на запуск другого конкурентного процесса. Если у нас слишком
много конкурентных процессов, мы можем потратить всё процессорное время на
переключение контекста между ними и никогда не выполнить никакой полезной
работы. На уровне операционной системы, с потоками, это может быть довольно
затратным. Операционная система должна сохранить такие вещи, как значения
регистров, таблицы поиска и карты памяти, чтобы успешно переключиться обратно на
текущий поток в нужное время. Затем она должна загрузить ту же информацию для
пришедшего потока.

Переключение контекста на стороне софта (software) сравнительно гораздо дешевле.
При использовании программно определённого планировщика, среда выполнения может
быть более избирательна в том, что сохраняется для восстановления, как оно
сохраняется и когда происходит необходимость в сохранении. Давайте посмотрим на
относительную производительность переключения контекста на конкретной машине
между потоками операционной системы и горутинами. Сначала воспользуемся
встроенным набором тестов производительности в Linux, чтобы измерить, сколько
времени занимает отправка сообщения между двумя потоками на одном ядре:

```bash
taskset -c 0 perf bench sched pipe -T
```

> Чтобы тесты заработали нужно установить `linux-tools` для конкретного
> дистрибутива Linux и конкретной версии ядра.

Результат:

<!-- markdownlint-disable MD040 -->

```
# Running 'sched/pipe' benchmark:
# Executed 1000000 pipe operations between two threads

     Total time: 6.168 [sec]

       6.168206 usecs/op
         162121 ops/sec
```

<!-- markdownlint-enable MD040 -->

Этот бенчмарк фактически измеряет время, необходимое для отправки и получения
сообщения в потоке, поэтому нужно поделить результат на 2. Это даёт **3,084
микросекунд** на переключение контекста. Кажется не так уж плохо, но посмотрим
на переключения контекста между горутинами.

Построим аналогичный бенчмарк, используя Go. Используем несколько вещей, которые
ещё не обсуждались. В следующем примере будут созданы две горутины и отправлено
сообщение между ними
([`code-samples/context-switch_test.go`](code-samples/context-switch_test.go)):

```go
func BenchmarkContextSwitch(b *testing.B) {
  var wg sync.WaitGroup
  begin := make(chan struct{})
  c := make(chan struct{})

  var token struct{}
  sender := func() { // отправитель
    defer wg.Done()
    // ждём пока не будет команды начинать.
    // мы не хотим, чтобы затраты на настройку и запуск каждой горутины
    // учитывались при измерении
    <-begin
    for i := 0; i < b.N; i++ {
      // отправляем сообщения в горутину-получатель.
      // struct{}{} называется пустой структурой и не занимает памяти
      c <- token
    }
  }

  receiver := func() { // получатель
    defer wg.Done()
    <-begin
    for i := 0; i < b.N; i++ {
      <-c // получаем сообщение и ничего с ним не делаем
    }
  }

  wg.Add(2)
  go sender()
  go receiver()
  b.StartTimer() // запускаем таймер производительности
  close(begin)   // даём команду начинать двум горутинам
  wg.Wait()
}
```

Запустим бенчмарк, указав, что мы хотим использовать только один CPU, чтобы тест
был аналогичен бенчмарку Linux, с помощью следующей команды:

```bash
go test -bench=. -cpu=1 code-samples/context-switch_test.go
```

Результат:

<!-- markdownlint-disable MD040 -->

```
BenchmarkContextSwitch   4932397               241.2 ns/op
PASS
ok      command-line-arguments  1.442s
```

<!-- markdownlint-enable MD040 -->

<!-- TODO: выигрыш в процентах -->
<!-- TODO: перефразировать фразу о верхнем пределе -->

241 наносекунд на переключение контекста, воу! Это **0,241 микросекунд**, в разы
быстрее. Трудно говорить о том, сколько горутин вызовут слишком частое
переключение контекста, но можно с уверенностью сказать, что верхний предел,
скорее всего, не станет препятствием для использования горутин.

Создание горутин обходится очень дёшево и нам следует всерьёз обсуждать их
стоимость только в том случае, когда мы доказали, что они являются основной
причиной проблем с производительностью.

### Пакет `sync`

Пакет `sync` содержит примитивы конкурентности, которые наиболее полезны для
низкоуровневой синхронизации доступа к памяти. Эти типы очень похожи на типы
языков, где конкурентность обеспечивается преимущественно синхронизацией доступа
к памяти. Разница между этими языками и Go заключается в том, что Go
предоставляет набор примитивов конкурентности, построенных поверх примитивов
синхронизации доступа к памяти и предоставляющих расширенный набор действий с
ними. Эти операции в основном используются в небольших скоупах, таких как
`struct`. Мы сами решаем, когда синхронизация доступа к памяти будет уместной.

#### `WaitGroup`

`WaitGroup` — это отличный способ дождаться набора конкурентных операций, когда
нас не интересует результат этих операций или мы имеем другой способ сбора их
результатов. Если ни одно из этих условий не верно, лучше использовать каналы и
выражение `select`.

Пример ([`code-samples/wait-group.go`](code-samples/wait-group.go)):

```go
var wg sync.WaitGroup

// Вызываем Add с аргументом 1, чтобы указать, что одна горутина будет
// запущена
wg.Add(1)
go func() {
  // Вызываем Done используя defer, чтобы убедиться в том, что перед
  // выходом из замыкания горутины, мы сообщим WaitGroup'е, что горутина
  // завершила работу
  defer wg.Done()
  fmt.Println("First goroutine sleeping...")
  time.Sleep(time.Second)
}()

wg.Add(1)
go func() {
  defer wg.Done()
  fmt.Println("Second goroutine sleeping...")
  time.Sleep(2 * time.Second)
}()

// Вызываем Wait, чтобы блокировать основную (main) горутину до тех пор,
// пока все горутины не сообщат, что они закончили работу
wg.Wait()

fmt.Println("All goroutines complete.")
```

Этот код произведёт следующий вывод:

```
First goroutine sleeping...
Second goroutine sleeping...
All goroutines complete.
```

Можно воспринимать `WaitGroup` как потокобезопасный счётчик: `Add` вызывается
для увелечения счётчика на переданное целое число, `Done` вызывается для
уменьшения счётчика на один. Вызов `Wait` блокирует до тех пор, пока счётчик не
станет равен нулю.

Следует обратить внимание, что вызовы `Add` происходят за пределами горутин,
которые они помогают отслеживать. Если делать вызовы внутри этих горутин, можно
получить состояние гонки, потому что нет гарантий, когда какая горутина будет
запланирована. В случае нахождения `Add` внутри замыканий горутин, вызов `Wait`
мог бы вообще ничего не заблокировать, так как вызовы `Add` могли бы успеть
произойти.

Как правило, нужно располагать вызовы `Add` как можно ближе к горутинам, которые
они помогают отслеживать, но иногда бывает, что отслеживать нужно группу горутин
сразу. Обычно тогда вызов `Add` следует делать до цикла
([`code-samples/wait-group-loop.go`](code-samples/wait-group-loop.go)):

```go
hello := func(wg *sync.WaitGroup, id int) {
defer wg.Done()
  fmt.Printf("Hello from %d\n", id)
}

const greetersCount = 5

var wg sync.WaitGroup

wg.Add(greetersCount)

for i := 0; i < greetersCount; i++ {
  go hello(&wg, i+1)
}

wg.Wait()
```

Этот код производит что-то подобное:

```
Hello from 2
Hello from 1
Hello from 3
Hello from 4
Hello from 5
```

#### `Mutex` и `RWMutex`

Название мьютекс (взаимное исключение, mutex) образовано от _**mut**ual
**ex**clusion_. Это способ защитить критическую секцию. Как обсуждалось ранее,
критическая секция — это участок программы, который требует исключительный
(эксклюзивный) доступ к общему ресурсу. `Mutex` предоставляет потокобезопасный
способ заявить об исключительном доступе к этому общему ресурсу. Go с помощью
каналов делит память коммуникацией, а `Mutex` делит память, создавая соглашение,
которому разработчики должны следовать, чтобы синхронизировать доступ к памяти.
Мы становимся ответственными за координацию доступа к памяти, защищая доступ к
ней с помощью мьютекса.

Простой пример, где две горутины пытаются инкрементировать и декрементировать
общее значение, они используют `Mutex` для синхронизации доступа
([`code-samples/mutex.go`](code-samples/mutex.go)):

```go
var count int
var lock sync.Mutex

increment := func() {
  lock.Lock()
  defer lock.Unlock()

  count++

  fmt.Printf("Incrementing: %d\n", count)
}

decrement := func() {
  // Запрашиваем исключительное использование критической секции — в этом
  // случае переменная count, защищённая Mutex'ом, блокируется
  lock.Lock()
  // Указываем, что мы закончили с блокировкой критической секции
  defer lock.Unlock()

  count--

  fmt.Printf("Decrementing: %d\n", count)
}

var wg sync.WaitGroup

for i := 0; i <= 5; i++ {
  wg.Add(1)
  go func() {
    defer wg.Done()

    increment()
  }()
}

for i := 0; i <= 5; i++ {
  wg.Add(1)
  go func() {
    defer wg.Done()

    decrement()
  }()
}

wg.Wait()

fmt.Println("Arithmetic complete.")
```

Этот код производит подобный вывод:

```
Incrementing: 1
Decrementing: 0
Incrementing: 1
Decrementing: 0
Decrementing: -1
Decrementing: -2
Decrementing: -3
Decrementing: -4
Incrementing: -3
Incrementing: -2
Incrementing: -1
Incrementing: 0
Arithmetic complete.
```

Следует обратить внимание, что `Unlock` всегда вызывается с `defer`. Это очень
общая идиома при использовании `Mutex`, чтобы убедиться, что вызов `Unlock`
произойдёт в любом случае, даже когда случается паника. Следовательно,
неиспользование `defer` в этом случае может привести к deadlock'у.

Критические секции так названы потому, что они — бутылочное горло программы.
Входить в них и выходить из них дорого, программисты обычно пытаются
минимизировать время выполнения, затраченное на критические секции.

Одна из стратегий — уменьшить сечение этой критической секции. Возможно, есть
память, которая должна быть разделена между несколькими конкурентными
процессами, но, вероятно, не все эти процессы будут _читать_ и _писать_ в эту
память. В таком случае, мы можем воспользоваться другим типом мьютекса —
`sync.RWMutex`.

`sync.RWMutex` концептуально одно и то же с `sync.Mutex`. Он защищает доступ к
памяти, однако, `RWMutex` даёт нам немного больше контроля над памятью. Мы можем
запросить блокировку на чтение, и в этом случае мы получим доступ, если только
блокировка не удерживается для записи. Это означает, что любое число читателей
может удерживать блокировку на чтение, пока ничто другое не удерживает
блокировку на запись.

Это пример, который демонстрирует производителя, который менее активен, чем
многочисленные потребители, создаваемые в коде
([`code-samples/rwmutex.go`](code-samples/rwmutex.go)):

```go
// Второй параметр функции имеет тип sync.Locker. Это интерфейс, который
// имеет два метода: Lock и Unlock. Mutex и RWMutex ему удовлетворяют
producer := func(wg *sync.WaitGroup, l sync.Locker) {
  defer wg.Done()

  for i := 0; i < 5; i++ {
    l.Lock()
    l.Unlock()
    // producer спит 1 секунду, что делает его менее активным, чем горутины observer
    time.Sleep(1)
  }
}

observer := func(wg *sync.WaitGroup, l sync.Locker) {
  defer wg.Done()

  l.Lock()
  defer l.Unlock()
}

test := func(observersCount int, mutex, rwMutex sync.Locker) time.Duration {
  var wg sync.WaitGroup

  wg.Add(observersCount + 1) // observers + 1 producer

  beginTestTime := time.Now()

  go producer(&wg, mutex)

  for i := 0; i < observersCount; i++ {
    go observer(&wg, rwMutex)
  }

  wg.Wait()

  return time.Since(beginTestTime)
}

tw := tabwriter.NewWriter(os.Stdout, 0, 1, 2, ' ', 0)
defer tw.Flush()

var m sync.RWMutex

_, _ = fmt.Fprintf(tw, "Readers\tRWMutex\tMutex\n")

for i := 0; i < 20; i++ {
  count := int(math.Pow(2, float64(i)))
  _, _ = fmt.Fprintf(
    tw,
    "%d\t%v\t%v\n",
    count,
    test(count, &m, m.RLocker()),
    test(count, &m, &m),
  )
}
```

Этот код производит следующий вывод:

```
Readers  RWMutex       Mutex
1        99.625µs      2.875µs
2        8.75µs        7.291µs
4        24.417µs      3.084µs
8        8µs           8.666µs
16       49.833µs      47.709µs
32       32.5µs        29.75µs
64       78.5µs        25.917µs
128      87.417µs      103.083µs
256      154.125µs     97.875µs
512      279.917µs     216.959µs
1024     449.209µs     816.75µs
2048     1.717292ms    1.51425ms
4096     2.353416ms    2.017208ms
8192     3.378625ms    3.883292ms
16384    4.830208ms    6.577209ms
32768    11.550625ms   13.031416ms
65536    21.696041ms   25.367958ms
131072   42.725375ms   51.290041ms
262144   87.44625ms    99.998333ms
524288   166.117542ms  202.075584ms
```

На этом конкретном примере можно видеть, что уменьшение сечения критической
области действительно начинает окупаться при около $2^{13} = 8192$ читателей.
Это значение будет варьироваться в зависимости от ого, что делает конкретная
критическая секция, но обычно рекомендуется использовать `RWMutex` вместо
обычного `Mutex`, когда это логически имеет смысл.

#### `Cond`

Комментарий к типу `Cond` действительно отлично выполняет свою работу, описывая
его назначение:

> ... рандеву (место встречи) для горутин, ожидающих или объявляющих о
> наступлении события.
>
> _...a rendezvous point for goroutines waiting for or announcing the occurrence
> of an event._

В этом определении, «сигнал» — это любой сигнал между двумя или более
горутинами, который не несёт в себе никакой информации, кроме факта, что он
произошёл. Очень часто мы хотим ждать один из этих сигналов для продолжения
выполнения горутины. Если бы мы думали, как это сделать без типа `Cond`, одним
из наивных подходов оказался бы бесконечный цикл:

```go
for !conditionIsTrue() {
}
```

Однако, это займёт всё время выполнения. Чтобы это исправить, можем ввести
`time.Sleep`:

```go
for !conditionIsTrue() {
  time.Sleep(1*time.Millisecond)
}
```

Это лучше, но всё ещё неэффективно и мы не можем знать, как долго нужно спать:
если слишком долго, мы искусственно снизим производительность; если слишком
мало, мы без надобности займём слишком много времени CPU. Было бы лучше
использовать какой-то инструмент, чтобы спать до тех пор, пока не будет передан
сигнал о том, что нужно возобновить работу и проверить условие. Это именно то,
что делает тип `sync.Cond`. Используя `sync.Cond`, мы бы написали предыдущий
пример как-то так:

```go
// Инициализируем новый Cond. Функция NewCond принимает тип, который
// удовлетворяет интерфейсу sync.Locker. Это то, что позволяет типу Cond
// координировать работу других горутин потокобезопасным способом
c := sync.NewCond(&sync.Mutex{})

// Закрываем Locker для проверки условия. Это важно, поскольку начало вызова
// Wait автоматически вызовет Unlock на Locker'е
c.L.Lock()

for !conditionIsTrue() {
  // Ждём события, что условие выполнилось. Это блокирующий вызов и горутина
  // будет приостановлена
  c.Wait()
}

// Какая-то логика (условие истинно) ...

// Разблокируем Locker после проверки условия. Это важно, поскольку выход из
// вызова Wait вызовет Lock на Locker'е
c.L.Unlock()
```

Такой подход _гораздо_ эффективнее. Следует обратить внимание, что вызов `Wait`
не просто блокирует, а _откладывает_ (_suspend_) текущую горутину, позволяя
другим горутинам работать в потоке ОС. При вызове `Wait` происходят несколько
интересных вещей: при входе в метод `Wait`, в `Locker` переменной типа `Cond`
вызывается метод `Unlock`, а при выходе из `Wait`, в `Locker` переменной типа
`Cond` вызывается метод `Lock`. К этому нужно немного привыкнуть. Фактически,
это скрытый сайд-эффект (побочный эффект) метода. Выглядит как будто мы
постоянно держим замок закрытым, пока ждём, когда условие станет истинным, но на
самом деле это не так. Когда мы пробегаемся глазами по коду, этот паттерн нужно
иметь ввиду.

Расширим этот пример и посмотрим на обе стороны уравнения: горутина, которая
ждёт сигнал, и горутина, которая посылает сигналы. Допустим, у нас есть очередь
фиксированной длины 2 и есть 10 элементов, которые мы хотим в неё пушить. Мы
хотим вносить элементы в очередь, как только появится место, поэтому хочется
получать уведомления, как только место появится
([`code-samples/cond.go`](code-samples/cond.go)):

```go
// Создаём условие, используя стандартный sync.Mutex в качестве Locker
c := sync.NewCond(&sync.Mutex{})
// Создаём срез с нулевой длиной. Мы заранее знаем capacity — 10 элементов
queue := make([]interface{}, 0, 10)

removeFromQueue := func(delay time.Duration) {
  time.Sleep(delay)

  // Мы снова входим в критическую секцию для условия, чтобы мы могли
  // изменить данные, относящиеся к условию
  c.L.Lock()
  // Симулируем удаление элемента из очереди путём изменения начала среза
  queue = queue[1:]

  fmt.Println("Removed from queue")

  // Выходим из критической секции условия, так как мы успешно удалили
  // элемент из очереди
  c.L.Unlock()

  // Сообщаем горутине, ждущей условие, что что-то произошло
  c.Signal()
}

for i := 0; i < 10; i++ {
  // Входим в критическую секцию условия, вызывая Lock на Locker'е условия
  c.L.Lock()
  // Проверяем длину очереди в цикле. Это важно, поскольку сигнал не
  // означает, что произошло именно то, чего мы ждали, а только что ЧТО-ТО
  // произошло
  for len(queue) == 2 {
    // Вызов Wait, который приостановит (suspend) main горутину до тех
    // пор, пока не будет отправлен сигнал условия
    c.Wait()
  }

  fmt.Println("Adding to queue")

  queue = append(queue, struct{}{})
  // Создаём новую горутину, которая будет удалять элемент из очереди
  // через одну секунду
  go removeFromQueue(1 * time.Second)
  // Выходим из критической секции, так как мы успешно запушили в очередь
  c.L.Unlock()
}
```

Примерный вывод программы:

```
Adding to queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Removed from queue
Adding to queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Removed from queue
Adding to queue
Adding to queue
```

Как можно видеть, программа успешно добавляет 10 элементов в очередь (и уже
успевает завершиться, когда у неё уже появляется возможность удалить из очереди
два последних элемента). Она также всегда ждёт, пока хотя бы один элемент будет
удалён из очереди, прежде чем пушить в неё.

<!-- TODO: точно ли норм перевёл то, что в скобках? "и уже успевает..." -->

Мы также видим новый метод в этом примере — `Signal`. Это один из двух методов,
которые предоставляет тип `Cond` для уведомления горутин, заблокированных при
вызове `Wait` о том, что условие произошло. Другой метод называется `Broadcast`.
Среда выполнения (рантайм) внутри держит FIFO-список горутин, ожидающих сигнала.
`Signal` находит горутину, которая ждала больше всего и уведомляет её, в то
время, как `Broadcat` отправляет сигнал _всем_ горутинам, которые ждут.
`Broadcast`, возможно, является более интересным из двух методов, поскольку он
обеспечивает способ общения с несколькими горутинами одновременно. Мы можем
тривиально воспроизвести поведение `Signal` с помощью каналов (будут рассмотрены
позже), но воспроизвести поведение повторяющихся вызовов `Broadcast` было бы
куда сложнее. В дополнение, тип `Cond` гораздо более производительный, чем
использование каналов.

<!-- TODO: корректно ли переводить condition как условие в данном контексте? -->

Чтобы понять `Broadcast`, представим, что мы создаём GUI-приложение с кнопкой.
Мы хотим регистрировать произвольное число функций, которые будут отрабатывать,
когда кнопка будет нажата. Тип `Cond` идеален для этого, потому что мы можем
использовать его метод `Broadcast` для уведомления всех зарегистрированных
обработчиков. Это может выглядеть так
([`code-samples/cond-broadcast.go`](code-samples/cond-broadcast.go)):

```go
// Определяем тип Button, который содержит Cond — Clicked
type Button struct {
  Clicked *sync.Cond
}

button := Button{Clicked: sync.NewCond(&sync.Mutex{})}

// Определяем функцию, которая позволит регистрировать функции для обработки
// сигналов из Cond. Каждый обработчик запускается в своей горутине, и
// subscribe не завершится, пока не будет подтверждено, что эта горутина
// запущена
subscribe := func(c *sync.Cond, fn func()) {
  var goroutineRunning sync.WaitGroup
  goroutineRunning.Add(1)

  // Устанавливаем обработчик для того, когда кнопка мыши отпущена. Он, в
  // свою очередь, вызывает Broadcast для Clicked Cond, чтобы сообщить
  // всем обработчикам, что кнопка мыши была нажата (более надёжная
  // реализация сначала проверила бы, что она была нажата)
  go func() {
    goroutineRunning.Done()
    c.L.Lock()
    defer c.L.Unlock()
    c.Wait()
    fn()
  }()
  goroutineRunning.Wait()
}

// Создаём WaitGroup только для того, чтобы быть уверенным, что программа не
// завершится до полного вывода в stdout
var clickRegistered sync.WaitGroup

clickRegistered.Add(3)

subscribe(button.Clicked, func() {
  fmt.Println("Maximizing window.")
  clickRegistered.Done()
})

subscribe(button.Clicked, func() {
  fmt.Println("Displaying annoying dialog box!")
  clickRegistered.Done()
})

subscribe(button.Clicked, func() {
  fmt.Println("Mouse clicked.")
  clickRegistered.Done()
})

// Симулируем то, как пользователь отпускает кнопку мыши после того, как
// нажал на кнопку в GUI
button.Clicked.Broadcast()

clickRegistered.Wait()
```

Этот код производит:

```
Mouse clicked.
Maximizing window.
Displaying annoying dialog box!
```

Можно видеть, что один вызов `Broadcast` на `Clicked`-условии заставляет трёх
обработчиков запуститься. Если бы не `WaitGroup`'а `clickRegistered`, мы бы
могли вызвать `button.Clicked.Broadcast()` несколько раз, и каждый раз
запускались бы все три обработчика. Это то, чего нельзя легко достичь с помощью
каналов – причина использования типа `Cond`.

Как и большинство других вещей в пакете `sync`, `Cond` работает лучше всего,
когда ограничен узким скоупом или расширяется на более широкий скоуп через тип,
который его (`Cond`) инкапсулирует.

<!-- TODO: непонятно, что имеется ввиду "если бы не waitgroup clickRegistered мы бы
могли вызывать ..." -->

#### `Once`

[`code-samples/once-1.go`](code-samples/once-1.go):

```go
var count int

increment := func() {
  count++
}

var once sync.Once

var increments sync.WaitGroup
increments.Add(100)

for i := 0; i < 100; i++ {
  go func() {
    defer increments.Done()
    once.Do(increment)
  }()
}

increments.Wait()

fmt.Printf("Count is %d\n", count)
```

Этот код произведёт `Count is 1`.

Как понятно из названия, `sync.Once` – это тип, который использует некоторые
примитивы внутри, чтобы гарантировать, что произойдёт один и только один вызов
переданной в `Do` функции.

Может показаться, что возможность вызвать функцию ровно один раз — это странная
вещь, чтобы инкапсулировать её и поместить в стандартную библиотеку (пакет), но
оказывается, что потребность в этом паттерне возникает довольно часто. Просто
для примера посмотрим, как часто сама стандартная библиотека Go использует этот
примитив, выполнив команду `grep -ir sync.Once $(go env GOROOT)/src |wc -l`, её
результат:

```
230
```

Важный момент по поводу `Once`. Этот код произведёт `Count is 1`
([`code-samples/once-2.go`](code-samples/once-2.go)):

```go
var count int

increment := func() {
  count++
}

decrement := func() {
  count--
}

var once sync.Once

once.Do(increment)
once.Do(decrement)

fmt.Printf("Count is %d\n", count)
```

> `sync.Once` гарантирует только число вызовов непосредственно `Do`, а не
> уникальных функций, переданных в `Do`.

Таким образом, копии `sync.Once` жёстко связаны с функциями, которые
предназначены для вызова. Опять же, использование типов из пакета `sync` лучше
всего работает в узком скоупе. То есть, лучше обернуть любое использование
`sync.Once` в небольшой лексический блок, например, в небольшую функцию. А можно
их обоих обернуть в один тип.

Следующий код ([`code-samples/once-3.go`](code-samples/once-3.go)) создаст
deadlock, поскольку вызов `Do` #1 не продолжится, пока вызов `Do` #2 не
завершится — классический пример deadlock'а. Это может показаться немного
контринтуитивным, так как кажется, что мы используем `sync.Once`, как
предполагается, для защиты от множественной инициализации, но единственное, что
гарантирует `sync.Once` — это то, что функции вызываются только один раз. Иногда
это, как и здесь, приводит к deadlock'у (взаимоблокировке) программы и
заставляет выявлять недостаток в логике — в данном случае выраженный в
циклической зависимости.

```go
var onceA, onceB sync.Once
var initB func()

initA := func() {
  onceB.Do(initB)
}

initB = func() {
  onceA.Do(initA) // 1
}

onceA.Do(initA) // 2
```

<!-- TODO: имеет ли смысл размещать инфу ниже здесь вообще? -->

> В комментариях в исходном коде Go для `func (o *Once) Do(f func())` написано
> следующее:
>
> `Do` гарантирует, что он не завершится до того, как `f` завершит выполнение.
>
> _(`Do` guarantees that when it returns, `f`` has finished.)_

<!-- TODO: Залезть в исходники и с atomic'ами в реализации Once разобраться -->

#### `Pool`

`Pool` — это потокобезопасная реализация паттерна проектирования
[«объектный пул»](https://ru.wikipedia.org/wiki/Объектный_пул) (object pool).

На высоком уровне, объектный пул — это способ создать и сделать доступным
фиксированное число, или пул, вещей для использования. Это особенно часто
используется для ограничения создания дорогих вещей (например, подключений к
базе данных) так, чтобы всегда только фиксированное число вещей было реально
создано при том, что неопределённое число операций могло запрашивать к ним
доступ.

`sync.Pool` в Go — это тип данных, который может безопасно использоваться
несколькими горутинами.

Основной реализуемый `Pool`'ом интерфейс — это его метод `Get`. Первым делом
`Get` проверяет, есть ли доступные инстансы (экземпляры) в пуле, чтобы вернуть
один из них вызывающей стороне. Если инстансов в пуле нет, метод `Get` вызовет
реализуемую нами функцию `New`, которая создаст один инстанс. После того, как
вызывающая сторона закончила работу с инстансом, она должна вызывать метод
`Put`, чтобы поместить инстанс обратно в пул для использования другими
процессами. Демонстрация работы с `sync.Pool`
([`code-samples/pool-1.go`](code-samples/pool-1.go)):

```go
myPool := &sync.Pool{
	New: func() interface{} {
		fmt.Println("Creating new instance")
		return struct{}{}
	},
}

// Вызываем метод Get пула. Этот вызов вызовет определённую нами функцию New,
// так как никаких инстансов ещё не было создано
myPool.Get()
// Снова вызываем метод Get пула. Этот вызов также вызовет New, ведь в прошлый
// раз мы не вернули инстанс обратно в пул
instance := myPool.Get()
// Здесь иы вернули ранее полученный инстанс обратно в пул. Это увеличит число
// доступных инстансов на один
myPool.Put(instance)
// Когда произойдёт этот вызов Get, мы переиспользуем ранее аллоцированный
// инстанс. Функция New не вызовется
myPool.Get()
```

Этот код выведет `Creating new instance` два раза.

Но зачем использовать пул, а не просто создавать инстансы объектов по мере
использования? В Go есть сборщик мусора, поэтому созданные объекты могут быть
автоматически удалены. В чём смысл? Рассмотрим этот пример:

```go
calculatorsNum := 0

calcPool := &sync.Pool{
	New: func() interface{} {
		calculatorsNum++
		mem := make([]byte, 1024)
		return &mem // мы храним адрес слайса байтов
	},
}

calcPool.Put(calcPool.New())
calcPool.Put(calcPool.New())
calcPool.Put(calcPool.New())
calcPool.Put(calcPool.New())

const workersNum = 1024 * 1024

var wg sync.WaitGroup
wg.Add(workersNum)

for i := 0; i < workersNum; i++ {
	go func() {
		defer wg.Done()

		// Утверждаем, что тип — это указатель на слайс байтов
		mem := calcPool.Get().(*[]byte)
		defer calcPool.Put(mem)

		// Предположим, что что-то интересное, но быстрое делается с этой памятью
	}()
}

wg.Wait()

fmt.Printf("%d calculators were created\n", calculatorsNum)
```

_Результат этой программы недетерминирован_. Результат программы:

```
8 calculators were created
```

Если написать такой код без `sync.Pool`, то в худшем случае программа могла бы
аллоцировать гибибайт памяти. Но как можно видеть, в нашем случае она
аллоцировала только лишь 4 кибибайта.

Ещё одна распространённая ситуация, когда пул полезен, — это предварительное
заполнение кэша (cache warming) аллоцированными объектами для операций, которые
должны выполняться настолько быстро, насколько это возможно.

Бенчмарки сетевых обработчиков с использованием `sync.Pool` и без него:
[`code-samples/cache_warming/cache_warming_test.go`](code-samples/cache_warming/cache_warming_test.go)
и
[`code-samples/cache_warming_with_pool/cache_warming_with_pool_test.go`](code-samples/cache_warming_with_pool/cache_warming_with_pool_test.go).

Запустим бенчмарки:

```bash
go test -benchtime=10s -bench=. code-samples/cache_warming/cache_warming_test.go
```

> ```
> goos: darwin
> goarch: arm64
> BenchmarkNetworkRequest-8             10        1004950088 ns/op
> PASS
> ok      command-line-arguments  14.114s
> ```

Без использования пула почти ровно $10^9$ наносекунд на операцию.

```bash
go test -benchtime=10s -bench=. code-samples/cache_warming_with_pool/cache_warming_with_pool_test.go
```

> ```
> goos: darwin
> goarch: arm64
> BenchmarkNetworkRequest-8           9704           5217934 ns/op
> PASS
> ok      command-line-arguments  79.540s
> ```

$5.2 \cdot 10^6$ наносекунд на операцию, на 3 порядка меньше!

<!-- TODO: подробнее расписать эти бенчмарки -->

Как мы увидели, пул объектов лучше всего применять в случаях, когда есть
конкурентные процессы, которым требуются объекты, но они быстро освобождаются
после создания, или когда создание этих объектов может негативно сказаться на
использовании памяти.

Однако, следует быть осторожным, когда код, использующий пул, требует
неоднородных вещей. Можно потратить больше времени на преобразование полученных
из пула данных, чем если сразу просто создать их с самого начала.

Поэтому при использовании `sync.Pool` следует помнить следующие моменты:

- При создании `sync.Pool` нужно предоставить ему функцию `New`, которая
  является потокобезопасной при вызове
- При получении инстанса через `Get` не нужно делать предположений о его
  состоянии. То есть, состояние может быть изменено предыдущим использованием
- По окончании работы с объектом, нужно вызвать `Put`. В противном случае пул
  бесполезен. Обычно это делается с помощью `defer`.
- Объекты в пуле должны быть примерно однородными по своему составу.

<!-- TODO: убедиться, что я правильно понял второй пункт -->
