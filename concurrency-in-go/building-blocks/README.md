## Содержание <!-- omit in toc -->

- [Строительные блоки конкурентности Go](#строительные-блоки-конкурентности-go)
  - [Горутины](#горутины)
  - [Пакет `sync`](#пакет-sync)
    - [`WaitGroup`](#waitgroup)
    - [`Mutex` и `RWMutex`](#mutex-и-rwmutex)
    - [`Cond`](#cond)
    - [`Once`](#once)
    - [`Pool`](#pool)
  - [Каналы](#каналы)
  - [Оператор `select`](#оператор-select)
  - [Рычаг `GOMAXPROCS`](#рычаг-gomaxprocs)

## Строительные блоки конкурентности Go

### Горутины

Горутины — это одна одна из самых основных единиц организации программы Go,
поэтому важно понимать, что это такое и как они работают. Фактически, в каждой
программе Go есть по крайней мере одна горутина: _основная (main) горутина_,
которая автоматически создаётся и запускается, когда запускается процесс.
Практически в любой программе, вероятно, придётся рано или поздно прибегнуть к
использованию горутин для решения задачи.

Проще говоря, горутина — это функция, которая выполняется конкурентно (не
обязательно параллельно!) с другим кодом. Мы можем запустить её просто добавив
ключевое слово `go` перед функцией:

```go
func main() {
  go sayHello()
  // продолжаем делать другие вещи
}

func sayHello() {
  fmt.Println("hello")
}
```

Анонимные функции тоже сработают. Пример, который делает то же самое, но вместо
создания горутины из обычной функции мы создаём горутину из анонимной функции:

```go
go func() {
  fmt.Println("hello")
}() // мы должны сразу же вызывать анонимную функцию при ключевом слове go
// продолжаем делать другие вещи
```

В качестве альтернативы мы можем присвоить функцию переменной и вызывать
анонимную функцию следующим образом:

```go
sayHello := func() {
  fmt.Println("hello")
}
go sayHello()
// продолжаем делать другие вещи
```

Замечательно! Мы можем создавать конкурентный блок логики с помощью функции и
единственного ключевого слова. Это всё, что нужно знать, чтобы запустить
горутину. Конечно, многое можно сказать о том, как правильно использовать
горутины, синхронизировать, организовать, но это действительно всё, что нужно
знать, чтобы начать их использовать.

Но что происходит за кулисами? Как горутины работают на самом деле? Это потоки
операционной системе? Это
[_зелёные потоки_](https://ru.wikipedia.org/wiki/Green_threads)? Как много мы
можем создать?

Горутины уникальны для Go (хотя в некоторых языках есть похожие примитивы
конкурентности). Это не потоки операционной системы, и это не совсем зелёные
потоки — потоки, управляемые средой выполнения языка. Они представляют собой
более высокий уровень абстракции, известный как сопрограммы (**к**орутины,
coroutines). Сопрограммы — это просто конкурентные подпрограммы (функции,
замыкания или методы в Go), которые не являются вытесняющими, то есть их нельзя
прервать. Вместо этого сопрограммы имеют несколько точек, в которых возможна
приостановка или возврат к исполнению.

Что делает горутины уникальными для Go — так это их глубокая интеграция в среду
выполнения Go. Горутины не определяют свои собственные точки приостановки или
повторного кода, а сама среда выполнения Go наблюдает за поведением горутин во
время выполнения и автоматически приостанавливает их, когда они блокируются, а
затем возобновляет их, когда они разблокируются. В некотором смысле это делает
их доступными для вытеснения, но только в тех точках, где они заблокированы. Это
элегантное партнёрство между средой выполнение и логикой горутины. Таким
образом, горутины можно рассматривать как особый класс сопрограмм.

Корутины и, следовательно, горутины являются неявно конкурентными конструкциями,
но конкурентность не является свойством сопрограммы: что-то должно одовременно
размещать несколько корутин и предоставлять каждой возможность выполнения —
иначе они бы не были конкурентными. Следует обратить внимание, что это не
означает, что программы неявно _параллельны_. Вполне возможно, что несколько
корутин будут выполняться последовательно, создавая иллюзию параллелизма, и на
самом деле это происходит в Go.

<!-- TODO: ссылка на "позже" -->

Механизм Go для размещения горутин — это реализация так называемого _M:N
планировщика_ (_M:N scheduler_), что означает, что он отображает M зелёных
потоков на N потоков операционной системы. Затем горутины планируются на зелёные
потоки. Когда горутин больше, чем доступных зелёных потоков, планировщик
распределяет горутины по доступным потокам операционной системы и гарантирует,
что при блокировке этих горутин могут быть запущены другие горутины. То, как это
работает, будет рассмотрено позже.

Go следует модели конкурентности, называемой fork-join. Слово fork означает, что
в любой точке программы, она может отделить дочернюю ветвь выполнения для
конкурентного запуска с родительской. Слово join означает, что в какой-то точке
в будущем эти конкурентные ветви выполнения снова соединятся вместе. Место, где
дочерняя ветвь соединяется с родительской, называется точкой соединения (join
point). Графическое изображение этого:

<!-- TODO: добавить перевод сноски -->

![Точка соединения](images/join-point.svg)

Оператор `go` — это то, как Go выполняет fork, а форкнутые потоки выполнения —
это горутины. Вернёмся к нашему примеру с горутиной:

```go
sayHello := func() {
  fmt.Println("hello")
}
go sayHello()
// продолжаем делать другие вещи
```

Здесь функция `sayHello` будет запущена в своей собственной горутине, а
остальная часть программы продолжит выполнение. В этом примере нет точки
соединения. Горутина, выполняющая `sayHello`, просто завершит работу в какое-то
неопределённое время в будущем, а остальная часть программы уже будет продолжать
выполнение.

Однако в этом примере есть одна проблема: код написан так, что неизвестно, будет
ли функция `sayHello` вообще выполнена. Горутина будет создана и запланирована
средой выполнения Go, но она может не получить возможность запуститься до того,
как основная горутина завершится.

Действительно, поскольку для простоты мы опускаем остальную часть функции
`main`, при запуске этого примера, почти наверняка программа завершит выполнение
до того, как будет запущена горутина с вызовом `sayHello`. В результате мы можем
не увидеть `hello` в stdout. Мы могли бы указать `time.Sleep` после создания
горутины. _Но следует помнить, что на самом деле это не создаёт точку
соединения, а только состояние гонки_. Мы лишь увеличим вероятность того, что
горутина будет запущена перед завершением программы, но не гарантируем этого.
_Точка соединения — это то, что гарантирует корректность программы и устраняет
состояние гонки_.

Для создания точки соединения мы должны синхронизировать горутину `main`, а
затем горутину `sayHello`. Это можно сделать несколькими способами, но мы
воспользуемся `sync.WaitGroup`:

```go
var wg sync.WaitGroup
sayHello := func() {
  defer wg.Done()
  fmt.Println("hello")
}
wg.Add(1)
go sayHello()
wg.Wait() // это точка соединения
```

Этот код гарантированно выведет `hello`.

В этом примере горутина `main` будет детерминированно блокироваться до тех пор,
пока горутина с вызовом `sayHello` не завершит работу.

> В этом разделе для точек соединения будет использоваться `sync.WaitGroup` без
> объяснения работы. Существует множество способов создания точек соединения,
> они будут рассмотрены позже.

В наших примерах мы использовали много анонимных функций для быстрого создания
примеров горутин. Давайте обратим внимания на замыкания. Замыкания замыкаются
вокруг лексической области, в которой они созданы, тем самым захватывая
переменные. Если мы запустим замыкание в горутине, замыкание будет работать с
копией переменных или с их исходными ссылками? Проверим:

```go
var wg sync.WaitGroup
salutation := "hello"
wg.Add(1)
go func() {
  defer wg.Done()
  salutation = "welcome" // горутина меняет значение переменной salutation
}()
wg.Wait()
fmt.Println(salutation)
```

Результат:

<!-- markdownlint-disable MD040 -->

```
welcome
```

<!-- markdownlint-enable MD040 -->

Оказывается, горутины выполняются в том же адресном пространстве, где они были
созданы, и поэтому наша программа выводит `welcome`. Попробуем другой пример
([`code-samples/salutation-1.go`](code-samples/salutation-1.go)):

```go
var wg sync.WaitGroup
for _, salutation := range []string{"hello", "greetings", "good day"} {
  wg.Add(1)
  go func() {
    defer wg.Done()
    fmt.Println(salutation)
  }()
}
wg.Wait()
```

Кажется, что результатом будет `hello`, `greetings`, `good day` в
недетерминированном порядке. Но на самом деле:

<!-- markdownlint-disable MD040 -->

```
good day
good day
good day
```

<!-- markdownlint-enable MD040 -->

В этом примере горутина выполняет замыкание, которое замкнуто на итерационной
переменной `salutation` строкового типа. По мере итерации по циклу переменной
`salutation` присваивается следующее значение из среза. Поскольку
запланированные горутины могут запускаться _в любой момент в будущем_,
неопределённо, какие значения будут выведены из горутины. Существует большая
вероятность того, что цикл успеет завершиться до начала выполнения какой-либо из
горутин. В таком случае переменная `salutation` выйдет из области видимости. Что
произойдёт в этом случае? Могут ли горутины всё ещё ссылаться на то, что вышло
из области видимости? Не будут ли горутины обращаться к памяти, которая
потенциально может быть очищена сборщиком мусора?

Среда выполнения Go достаточно наблюдательна, чтобы понимать, что ссылка на
переменную приветствия всё ещё сохраняется, и поэтому перенесёт память в кучу,
чтобы горутины могли продолжить обращаться к ней.

Обычно цикл завершается до того, как начинают выполняться какие-либо горутины
(но это не гарантируется), поэтому приветствие переносится в кучу и к этому
моменту содержит ссылку на последнее значение — `good day`. Правильный способ
написать этот цикл — передать копию `salutation` в замыкание, чтобы к моменту
запуска горутины она работала с данными из своей итерации цикла
([`code-samples/salutation-2.go`](code-samples/salutation-2.go)):

```go
var wg sync.WaitGroup
for _, salutation := range []string{"hello", "greetings", "good day"} {
  wg.Add(1)
  go func(salutation string) { // принимаем параметр как в обычную функцию
    defer wg.Done()
    fmt.Println(salutation)
  }(salutation)
  // передаём текущую итерационную переменную в замыкание, создаётся копия
  // структуры строки
}
wg.Wait()
```

Поскольку горутины работают в одном адресном пространстве и просто содержат
функции, использование горутин является естественным расширением написания
неконкурентного кода. Компилятор Go отлично заботится о закреплении переменных в
памяти, чтобы горутины случайно не обращались к освобождённой памяти, что
позволяет разработчикам сосредоточиться на своей задаче вместо управления
памятью; однако это не означает полной свободы действий.

<!-- TODO: ссылки (две!) на позже -->

Поскольку несколько горутин могут работать с одним и тем же адресным
пространством, всё равно приходится беспокоиться о синхронизации. Как уже было
описано, можно выбрать либо синхронизацию доступа к общей памяти, к которой
обращаются горутины, либо примитивы CSP для совместного использования памяти
посредством коммуникации. Эти методы мы обсудим позже.

Ещё одним преимуществом горутин является то, что они необычайно лёгкие. Выдержка
из [Go FAQ](https://go.dev/doc/faq#goroutines):

> Только что созданной горутине отводится несколько килобайт, чего почти всегда
> достаточно. Когда это не так, среда выполнения автоматически увеличивает (и
> сокращает) память для хранения стека, позволяя множеству горутин существовать
> в скромном объёме памяти. Затраты процессорного времени составляют в среднем
> около трёх недорогих инструкций на вызов функции. Вполне практично создавать
> сотни тысяч горутин в одном адресном пространстве. Если бы горутины были
> просто потоками, системные ресурсы исчерпались бы уже при значительно меньшем
> количестве.
>
> _A newly minted goroutine is given a few kilobytes, which is almost always
> enough. When it isn't, the run-time grows (and shrinks) the memory for storing
> the stack automatically, allowing many goroutines to live in a modest amount
> of memory. The CPU overhead averages about three cheap instructions per
> function call. It is practical to create hundreds of thousands of goroutines
> in the same address space. If goroutines were just threads, system resources
> would run out at a much smaller number._

Несколько килобайт на горутину — это очень неплохо. Убедимся в этом, но прежде
чем мы это сделаем, следует знать об одной интересной вещи, связанной с
горутинами: сборщик мусора ничего не делает для сборы горутин, которые были
каким-либо образом заброшены. Если написать следующее:

```go
go func() {
  // операция, которая блокирует горутину навсегда
}
// продолжаем делать другие вещи
```

<!-- TODO: ссылка на "позже" -->

Горутина здесь будет работать до тех пор, пока процесс не завершится. Мы
обсудим, как решить эту проблему позже. Воспользуемся этим в следующем примере,
чтобы фактически измерить размер горутин.

В следующем примере мы объединяем факт того, что горутины не собираются
сборщиком мусора, с возможностью среды выполнения анализировать саму себя и
измерить количество выделенной памяти до и после создания горутины
([`code-samples/goroutines-mem.go`](code-samples/goroutines-mem.go)):

```go
memConsumed := func() uint64 {
  runtime.GC()
  var s runtime.MemStats
  runtime.ReadMemStats(&s)
  return s.Sys
}

var c <-chan interface{}
var wg sync.WaitGroup
// нам нужна горутина, которая никогда не завершится, чтобы хранить их в
// определённом количестве в памяти для измерений
noop := func() {
  wg.Done()
  <-c
}

// задаём число горутин для создания.
// будем использовать закон больших чисел, чтобы асимптотически приблизиться к
// размеру горутины
const goroutinesCount = 1e4
wg.Add(goroutinesCount)
// измеряем объём потребляемой памяти перед созданием горутин
before := memConsumed()
for i := 0; i < goroutinesCount; i++ {
  go noop()
}
wg.Wait()
// измеряем объём потребляемой памяти после создания горутин
after := memConsumed()
fmt.Printf("%.3fkb\n", float64(after-before)/goroutinesCount/1000)
```

Результат:

<!-- markdownlint-disable MD040 -->

```
2.576kb
```

<!-- markdownlint-enable MD040 -->

Похоже, документация верна. Это просто пустые горутины, которые ничего не
делают, но это всё равно даёт нам представление о количестве горутин, которые,
вероятно, можно создать. Следующая таблица приводит приблизительные оценки
количества горутин, которые можно создать на 64-битном CPU без использования
swap'а (файла подкачки):

| Память (ГБ) | Количество горутин / 100 000 | Порядок величины |
| ----------- | ---------------------------- | ---------------- |
| $2^0$       | 3,718                        | 3                |
| $2^1$       | 7,436                        | 3                |
| $2^2$       | 14,873                       | 6                |
| $2^3$       | 29,746                       | 6                |
| $2^4$       | 59,492                       | 6                |
| $2^5$       | 118,983                      | 6                |
| $2^6$       | 237,967                      | 6                |
| $2^7$       | 475,934                      | 6                |
| $2^8$       | 951,867                      | 6                |
| $2^9$       | 1903,735                     | 9                |

Но что-то может испортить нам настроение — это переключение контекста, когда
что-то, на чём размещён конкурентный процесс, должно сохранить своё состояние,
чтобы переключиться на запуск другого конкурентного процесса. Если у нас слишком
много конкурентных процессов, мы можем потратить всё процессорное время на
переключение контекста между ними и никогда не выполнить никакой полезной
работы. На уровне операционной системы, с потоками, это может быть довольно
затратным. Операционная система должна сохранить такие вещи, как значения
регистров, таблицы поиска и карты памяти, чтобы успешно переключиться обратно на
текущий поток в нужное время. Затем она должна загрузить ту же информацию для
пришедшего потока.

Переключение контекста на стороне софта (software) сравнительно гораздо дешевле.
При использовании программно определённого планировщика, среда выполнения может
быть более избирательна в том, что сохраняется для восстановления, как оно
сохраняется и когда происходит необходимость в сохранении. Давайте посмотрим на
относительную производительность переключения контекста на конкретной машине
между потоками операционной системы и горутинами. Сначала воспользуемся
встроенным набором тестов производительности в Linux, чтобы измерить, сколько
времени занимает отправка сообщения между двумя потоками на одном ядре:

```bash
taskset -c 0 perf bench sched pipe -T
```

> Чтобы тесты заработали нужно установить `linux-tools` для конкретного
> дистрибутива Linux и конкретной версии ядра.

Результат:

<!-- markdownlint-disable MD040 -->

```
# Running 'sched/pipe' benchmark:
# Executed 1000000 pipe operations between two threads

     Total time: 6.168 [sec]

       6.168206 usecs/op
         162121 ops/sec
```

<!-- markdownlint-enable MD040 -->

Этот бенчмарк фактически измеряет время, необходимое для отправки и получения
сообщения в потоке, поэтому нужно поделить результат на 2. Это даёт **3,084
микросекунд** на переключение контекста. Кажется не так уж плохо, но посмотрим
на переключения контекста между горутинами.

Построим аналогичный бенчмарк, используя Go. Используем несколько вещей, которые
ещё не обсуждались. В следующем примере будут созданы две горутины и отправлено
сообщение между ними
([`code-samples/context-switch_test.go`](code-samples/context-switch_test.go)):

```go
func BenchmarkContextSwitch(b *testing.B) {
  var wg sync.WaitGroup
  begin := make(chan struct{})
  c := make(chan struct{})

  var token struct{}
  sender := func() { // отправитель
    defer wg.Done()
    // ждём пока не будет команды начинать.
    // мы не хотим, чтобы затраты на настройку и запуск каждой горутины
    // учитывались при измерении
    <-begin
    for i := 0; i < b.N; i++ {
      // отправляем сообщения в горутину-получатель.
      // struct{}{} называется пустой структурой и не занимает памяти
      c <- token
    }
  }

  receiver := func() { // получатель
    defer wg.Done()
    <-begin
    for i := 0; i < b.N; i++ {
      <-c // получаем сообщение и ничего с ним не делаем
    }
  }

  wg.Add(2)
  go sender()
  go receiver()
  b.StartTimer() // запускаем таймер производительности
  close(begin)   // даём команду начинать двум горутинам
  wg.Wait()
}
```

Запустим бенчмарк, указав, что мы хотим использовать только один CPU, чтобы тест
был аналогичен бенчмарку Linux, с помощью следующей команды:

```bash
go test -bench=. -cpu=1 code-samples/context-switch_test.go
```

Результат:

<!-- markdownlint-disable MD040 -->

```
BenchmarkContextSwitch   4932397               241.2 ns/op
PASS
ok      command-line-arguments  1.442s
```

<!-- markdownlint-enable MD040 -->

<!-- TODO: выигрыш в процентах -->
<!-- TODO: перефразировать фразу о верхнем пределе -->

241 наносекунд на переключение контекста, воу! Это **0,241 микросекунд**, в разы
быстрее. Трудно говорить о том, сколько горутин вызовут слишком частое
переключение контекста, но можно с уверенностью сказать, что верхний предел,
скорее всего, не станет препятствием для использования горутин.

Создание горутин обходится очень дёшево и нам следует всерьёз обсуждать их
стоимость только в том случае, когда мы доказали, что они являются основной
причиной проблем с производительностью.

### Пакет `sync`

Пакет `sync` содержит примитивы конкурентности, которые наиболее полезны для
низкоуровневой синхронизации доступа к памяти. Эти типы очень похожи на типы
языков, где конкурентность обеспечивается преимущественно синхронизацией доступа
к памяти. Разница между этими языками и Go заключается в том, что Go
предоставляет набор примитивов конкурентности, построенных поверх примитивов
синхронизации доступа к памяти и предоставляющих расширенный набор действий с
ними. Эти операции в основном используются в небольших скоупах, таких как
`struct`. Мы сами решаем, когда синхронизация доступа к памяти будет уместной.

#### `WaitGroup`

`WaitGroup` — это отличный способ дождаться набора конкурентных операций, когда
нас не интересует результат этих операций или мы имеем другой способ сбора их
результатов. Если ни одно из этих условий не верно, лучше использовать каналы и
выражение `select`.

Пример ([`code-samples/wait-group.go`](code-samples/wait-group.go)):

```go
var wg sync.WaitGroup

// Вызываем Add с аргументом 1, чтобы указать, что одна горутина будет
// запущена
wg.Add(1)
go func() {
  // Вызываем Done используя defer, чтобы убедиться в том, что перед
  // выходом из замыкания горутины, мы сообщим WaitGroup'е, что горутина
  // завершила работу
  defer wg.Done()
  fmt.Println("First goroutine sleeping...")
  time.Sleep(time.Second)
}()

wg.Add(1)
go func() {
  defer wg.Done()
  fmt.Println("Second goroutine sleeping...")
  time.Sleep(2 * time.Second)
}()

// Вызываем Wait, чтобы блокировать основную (main) горутину до тех пор,
// пока все горутины не сообщат, что они закончили работу
wg.Wait()

fmt.Println("All goroutines complete.")
```

Этот код произведёт следующий вывод:

```
First goroutine sleeping...
Second goroutine sleeping...
All goroutines complete.
```

Можно воспринимать `WaitGroup` как потокобезопасный счётчик: `Add` вызывается
для увелечения счётчика на переданное целое число, `Done` вызывается для
уменьшения счётчика на один. Вызов `Wait` блокирует до тех пор, пока счётчик не
станет равен нулю.

Следует обратить внимание, что вызовы `Add` происходят за пределами горутин,
которые они помогают отслеживать. Если делать вызовы внутри этих горутин, можно
получить состояние гонки, потому что нет гарантий, когда какая горутина будет
запланирована. В случае нахождения `Add` внутри замыканий горутин, вызов `Wait`
мог бы вообще ничего не заблокировать, так как вызовы `Add` могли бы успеть
произойти.

Как правило, нужно располагать вызовы `Add` как можно ближе к горутинам, которые
они помогают отслеживать, но иногда бывает, что отслеживать нужно группу горутин
сразу. Обычно тогда вызов `Add` следует делать до цикла
([`code-samples/wait-group-loop.go`](code-samples/wait-group-loop.go)):

```go
hello := func(wg *sync.WaitGroup, id int) {
defer wg.Done()
  fmt.Printf("Hello from %d\n", id)
}

const greetersCount = 5

var wg sync.WaitGroup

wg.Add(greetersCount)

for i := 0; i < greetersCount; i++ {
  go hello(&wg, i+1)
}

wg.Wait()
```

Этот код производит что-то подобное:

```
Hello from 2
Hello from 1
Hello from 3
Hello from 4
Hello from 5
```

#### `Mutex` и `RWMutex`

Название мьютекс (взаимное исключение, mutex) образовано от _**mut**ual
**ex**clusion_. Это способ защитить критическую секцию. Как обсуждалось ранее,
критическая секция — это участок программы, который требует исключительный
(эксклюзивный) доступ к общему ресурсу. `Mutex` предоставляет потокобезопасный
способ заявить об исключительном доступе к этому общему ресурсу. Go с помощью
каналов делит память коммуникацией, а `Mutex` делит память, создавая соглашение,
которому разработчики должны следовать, чтобы синхронизировать доступ к памяти.
Мы становимся ответственными за координацию доступа к памяти, защищая доступ к
ней с помощью мьютекса.

Простой пример, где две горутины пытаются инкрементировать и декрементировать
общее значение, они используют `Mutex` для синхронизации доступа
([`code-samples/mutex.go`](code-samples/mutex.go)):

```go
var count int
var lock sync.Mutex

increment := func() {
  lock.Lock()
  defer lock.Unlock()

  count++

  fmt.Printf("Incrementing: %d\n", count)
}

decrement := func() {
  // Запрашиваем исключительное использование критической секции — в этом
  // случае переменная count, защищённая Mutex'ом, блокируется
  lock.Lock()
  // Указываем, что мы закончили с блокировкой критической секции
  defer lock.Unlock()

  count--

  fmt.Printf("Decrementing: %d\n", count)
}

var wg sync.WaitGroup

for i := 0; i <= 5; i++ {
  wg.Add(1)
  go func() {
    defer wg.Done()

    increment()
  }()
}

for i := 0; i <= 5; i++ {
  wg.Add(1)
  go func() {
    defer wg.Done()

    decrement()
  }()
}

wg.Wait()

fmt.Println("Arithmetic complete.")
```

Этот код производит подобный вывод:

```
Incrementing: 1
Decrementing: 0
Incrementing: 1
Decrementing: 0
Decrementing: -1
Decrementing: -2
Decrementing: -3
Decrementing: -4
Incrementing: -3
Incrementing: -2
Incrementing: -1
Incrementing: 0
Arithmetic complete.
```

Следует обратить внимание, что `Unlock` всегда вызывается с `defer`. Это очень
общая идиома при использовании `Mutex`, чтобы убедиться, что вызов `Unlock`
произойдёт в любом случае, даже когда случается паника. Следовательно,
неиспользование `defer` в этом случае может привести к deadlock'у.

Критические секции так названы потому, что они — бутылочное горло программы.
Входить в них и выходить из них дорого, программисты обычно пытаются
минимизировать время выполнения, затраченное на критические секции.

Одна из стратегий — уменьшить сечение этой критической секции. Возможно, есть
память, которая должна быть разделена между несколькими конкурентными
процессами, но, вероятно, не все эти процессы будут _читать_ и _писать_ в эту
память. В таком случае, мы можем воспользоваться другим типом мьютекса —
`sync.RWMutex`.

`sync.RWMutex` концептуально одно и то же с `sync.Mutex`. Он защищает доступ к
памяти, однако, `RWMutex` даёт нам немного больше контроля над памятью. Мы можем
запросить блокировку на чтение, и в этом случае мы получим доступ, если только
блокировка не удерживается для записи. Это означает, что любое число читателей
может удерживать блокировку на чтение, пока ничто другое не удерживает
блокировку на запись.

Это пример, который демонстрирует производителя, который менее активен, чем
многочисленные потребители, создаваемые в коде
([`code-samples/rwmutex.go`](code-samples/rwmutex.go)):

```go
// Второй параметр функции имеет тип sync.Locker. Это интерфейс, который
// имеет два метода: Lock и Unlock. Mutex и RWMutex ему удовлетворяют
producer := func(wg *sync.WaitGroup, l sync.Locker) {
  defer wg.Done()

  for i := 0; i < 5; i++ {
    l.Lock()
    l.Unlock()
    // producer спит 1 секунду, что делает его менее активным, чем горутины observer
    time.Sleep(1)
  }
}

observer := func(wg *sync.WaitGroup, l sync.Locker) {
  defer wg.Done()

  l.Lock()
  defer l.Unlock()
}

test := func(observersCount int, mutex, rwMutex sync.Locker) time.Duration {
  var wg sync.WaitGroup

  wg.Add(observersCount + 1) // observers + 1 producer

  beginTestTime := time.Now()

  go producer(&wg, mutex)

  for i := 0; i < observersCount; i++ {
    go observer(&wg, rwMutex)
  }

  wg.Wait()

  return time.Since(beginTestTime)
}

tw := tabwriter.NewWriter(os.Stdout, 0, 1, 2, ' ', 0)
defer tw.Flush()

var m sync.RWMutex

_, _ = fmt.Fprintf(tw, "Readers\tRWMutex\tMutex\n")

for i := 0; i < 20; i++ {
  count := int(math.Pow(2, float64(i)))
  _, _ = fmt.Fprintf(
    tw,
    "%d\t%v\t%v\n",
    count,
    test(count, &m, m.RLocker()),
    test(count, &m, &m),
  )
}
```

Этот код производит следующий вывод:

```
Readers  RWMutex       Mutex
1        99.625µs      2.875µs
2        8.75µs        7.291µs
4        24.417µs      3.084µs
8        8µs           8.666µs
16       49.833µs      47.709µs
32       32.5µs        29.75µs
64       78.5µs        25.917µs
128      87.417µs      103.083µs
256      154.125µs     97.875µs
512      279.917µs     216.959µs
1024     449.209µs     816.75µs
2048     1.717292ms    1.51425ms
4096     2.353416ms    2.017208ms
8192     3.378625ms    3.883292ms
16384    4.830208ms    6.577209ms
32768    11.550625ms   13.031416ms
65536    21.696041ms   25.367958ms
131072   42.725375ms   51.290041ms
262144   87.44625ms    99.998333ms
524288   166.117542ms  202.075584ms
```

На этом конкретном примере можно видеть, что уменьшение сечения критической
области действительно начинает окупаться при около $2^{13} = 8192$ читателей.
Это значение будет варьироваться в зависимости от ого, что делает конкретная
критическая секция, но обычно рекомендуется использовать `RWMutex` вместо
обычного `Mutex`, когда это логически имеет смысл.

#### `Cond`

Комментарий к типу `Cond` действительно отлично выполняет свою работу, описывая
его назначение:

> ... рандеву (место встречи) для горутин, ожидающих или объявляющих о
> наступлении события.
>
> _...a rendezvous point for goroutines waiting for or announcing the occurrence
> of an event._

В этом определении, «сигнал» — это любой сигнал между двумя или более
горутинами, который не несёт в себе никакой информации, кроме факта, что он
произошёл. Очень часто мы хотим ждать один из этих сигналов для продолжения
выполнения горутины. Если бы мы думали, как это сделать без типа `Cond`, одним
из наивных подходов оказался бы бесконечный цикл:

```go
for !conditionIsTrue() {
}
```

Однако, это займёт всё время выполнения. Чтобы это исправить, можем ввести
`time.Sleep`:

```go
for !conditionIsTrue() {
  time.Sleep(1*time.Millisecond)
}
```

Это лучше, но всё ещё неэффективно и мы не можем знать, как долго нужно спать:
если слишком долго, мы искусственно снизим производительность; если слишком
мало, мы без надобности займём слишком много времени CPU. Было бы лучше
использовать какой-то инструмент, чтобы спать до тех пор, пока не будет передан
сигнал о том, что нужно возобновить работу и проверить условие. Это именно то,
что делает тип `sync.Cond`. Используя `sync.Cond`, мы бы написали предыдущий
пример как-то так:

```go
// Инициализируем новый Cond. Функция NewCond принимает тип, который
// удовлетворяет интерфейсу sync.Locker. Это то, что позволяет типу Cond
// координировать работу других горутин потокобезопасным способом
c := sync.NewCond(&sync.Mutex{})

// Закрываем Locker для проверки условия. Это важно, поскольку начало вызова
// Wait автоматически вызовет Unlock на Locker'е
c.L.Lock()

for !conditionIsTrue() {
  // Ждём события, что условие выполнилось. Это блокирующий вызов и горутина
  // будет приостановлена
  c.Wait()
}

// Какая-то логика (условие истинно) ...

// Разблокируем Locker после проверки условия. Это важно, поскольку выход из
// вызова Wait вызовет Lock на Locker'е
c.L.Unlock()
```

Такой подход _гораздо_ эффективнее. Следует обратить внимание, что вызов `Wait`
не просто блокирует, а _откладывает_ (_suspend_) текущую горутину, позволяя
другим горутинам работать в потоке ОС. При вызове `Wait` происходят несколько
интересных вещей: при входе в метод `Wait`, в `Locker` переменной типа `Cond`
вызывается метод `Unlock`, а при выходе из `Wait`, в `Locker` переменной типа
`Cond` вызывается метод `Lock`. К этому нужно немного привыкнуть. Фактически,
это скрытый сайд-эффект (побочный эффект) метода. Выглядит как будто мы
постоянно держим замок закрытым, пока ждём, когда условие станет истинным, но на
самом деле это не так. Когда мы пробегаемся глазами по коду, этот паттерн нужно
иметь ввиду.

Расширим этот пример и посмотрим на обе стороны уравнения: горутина, которая
ждёт сигнал, и горутина, которая посылает сигналы. Допустим, у нас есть очередь
фиксированной длины 2 и есть 10 элементов, которые мы хотим в неё пушить. Мы
хотим вносить элементы в очередь, как только появится место, поэтому хочется
получать уведомления, как только место появится
([`code-samples/cond.go`](code-samples/cond.go)):

```go
// Создаём условие, используя стандартный sync.Mutex в качестве Locker
c := sync.NewCond(&sync.Mutex{})
// Создаём срез с нулевой длиной. Мы заранее знаем capacity — 10 элементов
queue := make([]interface{}, 0, 10)

removeFromQueue := func(delay time.Duration) {
  time.Sleep(delay)

  // Мы снова входим в критическую секцию для условия, чтобы мы могли
  // изменить данные, относящиеся к условию
  c.L.Lock()
  // Симулируем удаление элемента из очереди путём изменения начала среза
  queue = queue[1:]

  fmt.Println("Removed from queue")

  // Выходим из критической секции условия, так как мы успешно удалили
  // элемент из очереди
  c.L.Unlock()

  // Сообщаем горутине, ждущей условие, что что-то произошло
  c.Signal()
}

for i := 0; i < 10; i++ {
  // Входим в критическую секцию условия, вызывая Lock на Locker'е условия
  c.L.Lock()
  // Проверяем длину очереди в цикле. Это важно, поскольку сигнал не
  // означает, что произошло именно то, чего мы ждали, а только что ЧТО-ТО
  // произошло
  for len(queue) == 2 {
    // Вызов Wait, который приостановит (suspend) main горутину до тех
    // пор, пока не будет отправлен сигнал условия
    c.Wait()
  }

  fmt.Println("Adding to queue")

  queue = append(queue, struct{}{})
  // Создаём новую горутину, которая будет удалять элемент из очереди
  // через одну секунду
  go removeFromQueue(1 * time.Second)
  // Выходим из критической секции, так как мы успешно запушили в очередь
  c.L.Unlock()
}
```

Примерный вывод программы:

```
Adding to queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Removed from queue
Adding to queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Removed from queue
Adding to queue
Adding to queue
```

Как можно видеть, программа успешно добавляет 10 элементов в очередь (и уже
успевает завершиться, когда у неё уже появляется возможность удалить из очереди
два последних элемента). Она также всегда ждёт, пока хотя бы один элемент будет
удалён из очереди, прежде чем пушить в неё.

<!-- TODO: точно ли норм перевёл то, что в скобках? "и уже успевает..." -->

Мы также видим новый метод в этом примере — `Signal`. Это один из двух методов,
которые предоставляет тип `Cond` для уведомления горутин, заблокированных при
вызове `Wait` о том, что условие произошло. Другой метод называется `Broadcast`.
Среда выполнения (рантайм) внутри держит FIFO-список горутин, ожидающих сигнала.
`Signal` находит горутину, которая ждала больше всего и уведомляет её, в то
время, как `Broadcat` отправляет сигнал _всем_ горутинам, которые ждут.
`Broadcast`, возможно, является более интересным из двух методов, поскольку он
обеспечивает способ общения с несколькими горутинами одновременно. Мы можем
тривиально воспроизвести поведение `Signal` с помощью каналов (будут рассмотрены
позже), но воспроизвести поведение повторяющихся вызовов `Broadcast` было бы
куда сложнее. В дополнение, тип `Cond` гораздо более производительный, чем
использование каналов.

<!-- TODO: корректно ли переводить condition как условие в данном контексте? -->

Чтобы понять `Broadcast`, представим, что мы создаём GUI-приложение с кнопкой.
Мы хотим регистрировать произвольное число функций, которые будут отрабатывать,
когда кнопка будет нажата. Тип `Cond` идеален для этого, потому что мы можем
использовать его метод `Broadcast` для уведомления всех зарегистрированных
обработчиков. Это может выглядеть так
([`code-samples/cond-broadcast.go`](code-samples/cond-broadcast.go)):

```go
// Определяем тип Button, который содержит Cond — Clicked
type Button struct {
  Clicked *sync.Cond
}

button := Button{Clicked: sync.NewCond(&sync.Mutex{})}

// Определяем функцию, которая позволит регистрировать функции для обработки
// сигналов из Cond. Каждый обработчик запускается в своей горутине, и
// subscribe не завершится, пока не будет подтверждено, что эта горутина
// запущена
subscribe := func(c *sync.Cond, fn func()) {
  var goroutineRunning sync.WaitGroup
  goroutineRunning.Add(1)

  // Устанавливаем обработчик для того, когда кнопка мыши отпущена. Он, в
  // свою очередь, вызывает Broadcast для Clicked Cond, чтобы сообщить
  // всем обработчикам, что кнопка мыши была нажата (более надёжная
  // реализация сначала проверила бы, что она была нажата)
  go func() {
    goroutineRunning.Done()
    c.L.Lock()
    defer c.L.Unlock()
    c.Wait()
    fn()
  }()
  goroutineRunning.Wait()
}

// Создаём WaitGroup только для того, чтобы быть уверенным, что программа не
// завершится до полного вывода в stdout
var clickRegistered sync.WaitGroup

clickRegistered.Add(3)

subscribe(button.Clicked, func() {
  fmt.Println("Maximizing window.")
  clickRegistered.Done()
})

subscribe(button.Clicked, func() {
  fmt.Println("Displaying annoying dialog box!")
  clickRegistered.Done()
})

subscribe(button.Clicked, func() {
  fmt.Println("Mouse clicked.")
  clickRegistered.Done()
})

// Симулируем то, как пользователь отпускает кнопку мыши после того, как
// нажал на кнопку в GUI
button.Clicked.Broadcast()

clickRegistered.Wait()
```

Этот код производит:

```
Mouse clicked.
Maximizing window.
Displaying annoying dialog box!
```

Можно видеть, что один вызов `Broadcast` на `Clicked`-условии заставляет трёх
обработчиков запуститься. Если бы не `WaitGroup`'а `clickRegistered`, мы бы
могли вызвать `button.Clicked.Broadcast()` несколько раз, и каждый раз
запускались бы все три обработчика. Это то, чего нельзя легко достичь с помощью
каналов – причина использования типа `Cond`.

Как и большинство других вещей в пакете `sync`, `Cond` работает лучше всего,
когда ограничен узким скоупом или расширяется на более широкий скоуп через тип,
который его (`Cond`) инкапсулирует.

<!-- TODO: непонятно, что имеется ввиду "если бы не waitgroup clickRegistered мы бы
могли вызывать ..." -->

#### `Once`

[`code-samples/once-1.go`](code-samples/once-1.go):

```go
var count int

increment := func() {
  count++
}

var once sync.Once

var increments sync.WaitGroup
increments.Add(100)

for i := 0; i < 100; i++ {
  go func() {
    defer increments.Done()
    once.Do(increment)
  }()
}

increments.Wait()

fmt.Printf("Count is %d\n", count)
```

Этот код произведёт `Count is 1`.

Как понятно из названия, `sync.Once` – это тип, который использует некоторые
примитивы внутри, чтобы гарантировать, что произойдёт один и только один вызов
переданной в `Do` функции.

Может показаться, что возможность вызвать функцию ровно один раз — это странная
вещь, чтобы инкапсулировать её и поместить в стандартную библиотеку (пакет), но
оказывается, что потребность в этом паттерне возникает довольно часто. Просто
для примера посмотрим, как часто сама стандартная библиотека Go использует этот
примитив, выполнив команду `grep -ir sync.Once $(go env GOROOT)/src |wc -l`, её
результат:

```
230
```

Важный момент по поводу `Once`. Этот код произведёт `Count is 1`
([`code-samples/once-2.go`](code-samples/once-2.go)):

```go
var count int

increment := func() {
  count++
}

decrement := func() {
  count--
}

var once sync.Once

once.Do(increment)
once.Do(decrement)

fmt.Printf("Count is %d\n", count)
```

> `sync.Once` гарантирует только число вызовов непосредственно `Do`, а не
> уникальных функций, переданных в `Do`.

Таким образом, копии `sync.Once` жёстко связаны с функциями, которые
предназначены для вызова. Опять же, использование типов из пакета `sync` лучше
всего работает в узком скоупе. То есть, лучше обернуть любое использование
`sync.Once` в небольшой лексический блок, например, в небольшую функцию. А можно
их обоих обернуть в один тип.

Следующий код ([`code-samples/once-3.go`](code-samples/once-3.go)) создаст
deadlock, поскольку вызов `Do` #1 не продолжится, пока вызов `Do` #2 не
завершится — классический пример deadlock'а. Это может показаться немного
контринтуитивным, так как кажется, что мы используем `sync.Once`, как
предполагается, для защиты от множественной инициализации, но единственное, что
гарантирует `sync.Once` — это то, что функции вызываются только один раз. Иногда
это, как и здесь, приводит к deadlock'у (взаимоблокировке) программы и
заставляет выявлять недостаток в логике — в данном случае выраженный в
циклической зависимости.

```go
var onceA, onceB sync.Once
var initB func()

initA := func() {
  onceB.Do(initB)
}

initB = func() {
  onceA.Do(initA) // 1
}

onceA.Do(initA) // 2
```

<!-- TODO: имеет ли смысл размещать инфу ниже здесь вообще? -->

> В комментариях в исходном коде Go для `func (o *Once) Do(f func())` написано
> следующее:
>
> `Do` гарантирует, что он не завершится до того, как `f` завершит выполнение.
>
> _(`Do` guarantees that when it returns, `f`` has finished.)_

<!-- TODO: Залезть в исходники и с atomic'ами в реализации Once разобраться -->

#### `Pool`

`Pool` — это потокобезопасная реализация паттерна проектирования
[«объектный пул»](https://ru.wikipedia.org/wiki/Объектный_пул) (object pool).

На высоком уровне, объектный пул — это способ создать и сделать доступным
фиксированное число, или пул, вещей для использования. Это особенно часто
используется для ограничения создания дорогих вещей (например, подключений к
базе данных) так, чтобы всегда только фиксированное число вещей было реально
создано при том, что неопределённое число операций могло запрашивать к ним
доступ.

`sync.Pool` в Go — это тип данных, который может безопасно использоваться
несколькими горутинами.

Основной реализуемый `Pool`'ом интерфейс — это его метод `Get`. Первым делом
`Get` проверяет, есть ли доступные инстансы (экземпляры) в пуле, чтобы вернуть
один из них вызывающей стороне. Если инстансов в пуле нет, метод `Get` вызовет
реализуемую нами функцию `New`, которая создаст один инстанс. После того, как
вызывающая сторона закончила работу с инстансом, она должна вызывать метод
`Put`, чтобы поместить инстанс обратно в пул для использования другими
процессами. Демонстрация работы с `sync.Pool`
([`code-samples/pool-1.go`](code-samples/pool-1.go)):

```go
myPool := &sync.Pool{
  New: func() interface{} {
    fmt.Println("Creating new instance")
    return struct{}{}
  },
}

// Вызываем метод Get пула. Этот вызов вызовет определённую нами функцию New,
// так как никаких инстансов ещё не было создано
myPool.Get()
// Снова вызываем метод Get пула. Этот вызов также вызовет New, ведь в прошлый
// раз мы не вернули инстанс обратно в пул
instance := myPool.Get()
// Здесь иы вернули ранее полученный инстанс обратно в пул. Это увеличит число
// доступных инстансов на один
myPool.Put(instance)
// Когда произойдёт этот вызов Get, мы переиспользуем ранее аллоцированный
// инстанс. Функция New не вызовется
myPool.Get()
```

Этот код выведет `Creating new instance` два раза.

Но зачем использовать пул, а не просто создавать инстансы объектов по мере
использования? В Go есть сборщик мусора, поэтому созданные объекты могут быть
автоматически удалены. В чём смысл? Рассмотрим этот пример:

```go
calculatorsNum := 0

calcPool := &sync.Pool{
  New: func() interface{} {
    calculatorsNum++
    mem := make([]byte, 1024)
    return &mem // мы храним адрес слайса байтов
  },
}

calcPool.Put(calcPool.New())
calcPool.Put(calcPool.New())
calcPool.Put(calcPool.New())
calcPool.Put(calcPool.New())

const workersNum = 1024 * 1024

var wg sync.WaitGroup
wg.Add(workersNum)

for i := 0; i < workersNum; i++ {
  go func() {
    defer wg.Done()

    // Утверждаем, что тип — это указатель на слайс байтов
    mem := calcPool.Get().(*[]byte)
    defer calcPool.Put(mem)

    // Предположим, что что-то интересное, но быстрое делается с этой памятью
  }()
}

wg.Wait()

fmt.Printf("%d calculators were created\n", calculatorsNum)
```

_Результат этой программы недетерминирован_. Результат программы:

```
8 calculators were created
```

Если написать такой код без `sync.Pool`, то в худшем случае программа могла бы
аллоцировать гибибайт памяти. Но как можно видеть, в нашем случае она
аллоцировала только лишь 4 кибибайта.

Ещё одна распространённая ситуация, когда пул полезен, — это предварительное
заполнение кэша (cache warming) аллоцированными объектами для операций, которые
должны выполняться настолько быстро, насколько это возможно.

Бенчмарки сетевых обработчиков с использованием `sync.Pool` и без него:
[`code-samples/cache_warming/cache_warming_test.go`](code-samples/cache_warming/cache_warming_test.go)
и
[`code-samples/cache_warming_with_pool/cache_warming_with_pool_test.go`](code-samples/cache_warming_with_pool/cache_warming_with_pool_test.go).

Запустим бенчмарки:

```bash
go test -benchtime=10s -bench=. code-samples/cache_warming/cache_warming_test.go
```

> ```
> goos: darwin
> goarch: arm64
> BenchmarkNetworkRequest-8             10        1004950088 ns/op
> PASS
> ok      command-line-arguments  14.114s
> ```

Без использования пула почти ровно $10^9$ наносекунд на операцию.

```bash
go test -benchtime=10s -bench=. code-samples/cache_warming_with_pool/cache_warming_with_pool_test.go
```

> ```
> goos: darwin
> goarch: arm64
> BenchmarkNetworkRequest-8           9704           5217934 ns/op
> PASS
> ok      command-line-arguments  79.540s
> ```

$5.2 \cdot 10^6$ наносекунд на операцию, на 3 порядка меньше!

<!-- TODO: подробнее расписать эти бенчмарки -->

Как мы увидели, пул объектов лучше всего применять в случаях, когда есть
конкурентные процессы, которым требуются объекты, но они быстро освобождаются
после создания, или когда создание этих объектов может негативно сказаться на
использовании памяти.

Однако, следует быть осторожным, когда код, использующий пул, требует
неоднородных вещей. Можно потратить больше времени на преобразование полученных
из пула данных, чем если сразу просто создать их с самого начала.

Поэтому при использовании `sync.Pool` следует помнить следующие моменты:

- При создании `sync.Pool` нужно предоставить ему функцию `New`, которая
  является потокобезопасной при вызове
- При получении инстанса через `Get` не нужно делать предположений о его
  состоянии. То есть, состояние может быть изменено предыдущим использованием
- По окончании работы с объектом, нужно вызвать `Put`. В противном случае пул
  бесполезен. Обычно это делается с помощью `defer`.
- Объекты в пуле должны быть примерно однородными по своему составу.

<!-- TODO: убедиться, что я правильно понял второй пункт -->

### Каналы

Каналы — это один из примитивов синхронизации в Go, пришедший из CSP Хоара. Хотя
их можно использовать для синхронизации доступа к памяти, их лучше использовать
для обмена информацией между горутинам. Как мы обсуждали в
[«Философия конкурентности Go»](../basics/README.md#философия-конкурентности-go),
каналы чрезвычайно полезны в программах любого размера из-за их способности быть
объединёнными вместе. Это их объединение (композицию) мы рассмотрим позже, когда
будем разбирать выражение `select`.

<!-- TODO: про объединёнными вместе написать поумнее -->

<!-- TODO: ссылку на позже -->

Подобно реке, канал в Go служит каналом для потока информации (_сложно стройно
перевести channel и conduit_); значения могут передаваться вдоль по каналу, а
затем считываться вниз по течению. По этой мы будем часто заканчивать имена
переменных `chan` словом "Stream". При использовании каналов мы передаём
значение в переменную `chan`, а затем в другом месте нашей программы считываем
его из канала. Различные части нашей программы не требуют знания друг о друге,
они должны знать только ссылку на одно и то же место в памяти, где находится
канал. Это можно обеспечить передачей ссылок на каналы в нашей программе.

Создать канал очень просто. Вот пример с описанием способа создания канала:
сначала мы его объявляем, а затем непосредственно создаём. Как и с другими
значениями в Go, можно схлопнуть эти два этапа в один шаг с помощью оператора
`:=`, но часто придётся именно объявлять каналы, поэтому полезно видеть, как эти
два этапа реализуются в отдельных шагах:

```go
// Объявляем канал. Будем говорить, что это канал типа interface{}
var dataStream chan interface{}
// Инициализируем канал используя встроенную функцию make
dataStream = make(chan interface{})
```

Этот пример определят канал `dataStream`, откуда можно прочитать и куда можно
записать _любое_ значение (так как его тип — это пустой интерфейс). Каналы также
могут быть объявлены как поддерживающие только однонаправленный поток данных —
то есть, можно определить канал, поддерживающий только отправку или только
получение информации. Позже будет объяснено, почему это важно.

Чтобы объявить однонаправленный канал, нужно просто добавить оператор `<-`.
Чтобы объявить канал, который может только читать, нужно поместить оператор `<-`
слева:

```go
var dataStream <-chan interface{}
dataStream = make(<-chan interface{})
```

Чтобы объявить канал, который может только писать, нужно поместить оператор `<-`
справа:

```go
var dataStream chan<- interface{}
dataStream = make(chan<- interface{})
```

Однонаправленные каналы встречаются нечасто, но их часто можно увидеть в
параметрах функций и в возвращаемых ими типах. Это возможно потому, что Go
неявно преобразует двунаправленные каналы в однонаправленные, когда это
необходимо. Пример:

```go
var receiveChan <-chan interface{}
var sendChan chan<- interface{}
dataStream := make(chan interface{})

// Валидные выражения:
receiveChan = dataStream
sendChan = dataStream
```

Следует помнить, что каналы типизированные. В этом примере мы создаём
`chan interface{}`, что означает, что в такой канал мы можем поместить любой тип
данных, но также мы можем задать более строгий тип данных. Пример канала для
целых чисел (+ более каноничный способ инициализации каналов через оператор
`:=`):

```go
intStream := make(chan int)
```

Для использования каналов мы снова должны применить оператор `<-`. Отправка в
канал осуществляется помещением оператора `<-` справа от канала, а получение из
канала — помещением слева. Можно думать об этом так: поток данных следует в
направлении стрелки. Пример
([`code-samples/channels/channels-1.go`](code-samples/channels/channels-1.go)):

```go
stringStream := make(chan string)

go func() {
  stringStream <- "Hello channels!" // Пишем строчку в канал stringStream
}()

// Читаем строчку из канала stringStream и выводим её в stdout
fmt.Println(<-stringStream)
```

Этот код произведёт следующий вывод:

```
Hello channels!
```

Очень просто! Всё что нужно — это переменная канала, в неё можно можно
передавать данные и читать данные из неё. Однако, случится ошибка, если
попытаться писать в read-only (только для чтения) канал или писать в write-only
(только для записи) канал. Если попробовать скомпилировать следующий пример
([`code-samples/channels/channels-2.go`](code-samples/channels/channels-2.go)),
компилятор Go даст нам знать, что иы делаем что-то недопустимое:

```go
writeStream := make(chan<- interface{})
readStream := make(<-chan interface{})

<-writeStream
readStream <- struct{}{}
```

Результат компиляции:

```
code-samples/channels/channels-2.go:7:4: invalid operation: cannot receive from send-only channel writeStream (variable of type chan<- interface{})
code-samples/channels/channels-2.go:8:2: invalid operation: cannot send to receive-only channel readStream (variable of type <-chan interface{})
```

Это часть системы типов Go, которая позволяет обеспечить безопасность типов даже
при работе с примитивами конкурентности. Как мы увидим далее, это мощный
инструмент для создания деклараций нашего API и построения компонуемых,
логически стройных программ, о которых легко рассуждать.

Ранее мы подчёркивали факт, что только потому, что горутина запланирована, нет
гарантий, что она выполнится до завершения процесса. Тем не менее, предыдущий
пример
([`code-samples/channels/channels-1.go`](code-samples/channels/channels-1.go))
полностью правильный и завершается без «пропущенного» кода. Почему это так?
Просто случайность, что анонимная горутина завершилась раньше main-горутины?

Этот пример работает потому, что каналы в Go являются блокирующими. Это
означает, что любая горутина, которая пытается записать в заполненный канал,
будет ждать, пока канал не освободится, равно как и любая горутина, которая
пытается прочитать из пустого канала, будет ждать, пока хотя бы один элемент не
будет помещён в него. В этом примере `fmt.Println` в аргументе содержит
извлечение из канала `stringStream` и, соответственно, будет ожидать, пока в
канал не будет помещено значение. Точно так же анонимная горутина пытается
поместить строку в `stringStream`, поэтому горутина не завершится, пока запись
не будет успешной. Таким образом, main-горутина и анонимная горутина блокируются
_детерминированным_ образом.

Если правильно не структурировать программу, это может спровоцировать
deadlock'и. Посмотрим на следующий пример, который вводит бессмысленное условие,
чтобы предотвратить анонимной горутине помещение значения в канал
([`code-samples/channels/channels-3.go`](code-samples/channels/channels-3.go)):

```go
stringStream := make(chan string)

go func() {
  // Обеспечиваем невозможность получения значения из канала stringStream
  // из main-горутины
  if 0 != 1 {
    return
  }

  stringStream <- "Hello channels!"
}()

fmt.Println(<-stringStream)
```

Результат выполнения этого кода:

```
fatal error: all goroutines are asleep - deadlock!

goroutine 1 [chan receive]:
main.main()
        .../code-samples/channels/channels-3.go:17 +0x7c
exit status 2
```

main-горутина ждём помещения значения в канал `stringStream`, но по нашему
условию этого никогда не произойдёт. Когда анонимная горутина завершается, Go
корректно определяет, что все горутины asleep и сообщает о deadlock'е.

С помощью оператора `<-` опционально можно получать два значения
([`code-samples/channels/channels-4.go`](code-samples/channels/channels-4.go)):

```go
stringStream := make(chan string)

go func() {
  stringStream <- "Hello channels!"
}()

salutation, ok := <-stringStream
fmt.Printf("(%v): %v\n", ok, salutation)
```

Этот код произведёт:

```
(true): Hello channels!
```

Второе возвращаемое значение — это способ для операции чтения узнать, было ли
прочитанное с канала значение сгенерировано записью в другом месте, или это
значение по умолчанию, сгенерированное из закрытого канала.

Что такое закрытый канал? В программах очень полезно иметь возможность указать,
что больше по каналу значений передано не будет. Это помогает последующим
(downstream) процессам знать, когда двигаться дальше, завершаться, повторно
открывать коммуникации на новом канале и т.д. Мы могли бы добиться этого с
помощью специального значения-маяка для каждого типа (данных), но это
дублировало бы усилия для всех разработчиков, и на самом деле, это задача
канала, а не типа данных, поэтому закрытие канала — это универсальный маяк,
который говорит: «Эй, предшествующие (upstream) процессы больше не будут
записывать никаких значений, делай что хочешь». Для закрытия канала используется
встроенная функция `close`:

```go
valueStream := make(chan interface{})
close(valueStream)
```

Интересно, что мы можем также читать с закрытого канала
([`code-samples/channels/channels-5.go`](code-samples/channels/channels-5.go)):

```go
intStream := make(chan int)
close(intStream)

integer, ok := <-intStream // читаем из закрытого канала

fmt.Printf("(%v): %d\n", ok, integer)
```

Этот код произведёт:

```
(false): 0
```

Следует обратить внимание, что мы ничего не помещали в канал; мы его закрыли
немедленно после создания. Но мы всё ещё можем выполнять операцию чтения, и мы
могли бы продолжать читать из этого канала бесконечно, несмотря на то, что канал
закрыт. Это сделано для поддержки нескольких последующих операций чтения из
одного «писателя» в канал (далее можно увидеть, что это распространённый
сценарий). Второе возвращаемое значение, сохранённое в переменной `ok`, равно
`false` и указывает на то, что полученное нами значение в первом параметре
является нулевым значением (значением по умолчанию) для `int` — `0`, а не
значением, каким-то процессом действительно помещённым в канал.

<!-- TODO: "распространённый сценарий" будет рассмотрен в 4-й главе книги -->

Это открывает несколько новых паттернов для нас. Первый — перебор канала.
Ключевое слово `range` в сочетании с оператором `for` поддерживает каналы в
качестве операндов и автоматически прерывает цикл при закрытии канала. Это
позволяет лаконично выполнять итерацию по значениям в канале. Пример
([`code-samples/channels/channels-ranging.go`](code-samples/channels/channels-ranging.go)):

```go
intStream := make(chan int)

go func() {
  // Обеспечиваем, что канал будет закрыт перед выходом из горутины. Очень
  // распространённый паттерн
  defer close(intStream)

    for i := 1; i <= 5; i++ {
      intStream <- i
    }
}()

// Перебор канала intStream
for i := range intStream {
  fmt.Printf("%d ", i)
}

fmt.Println()
```

При запуске программы можно убедиться, что все значения будут выведены:

```
1 2 3 4 5
```

Следует обратить внимание, что циклу не нужен критерий выхода, а `range` не
возвращает второе булево значение. Работа цикла с закрытыми каналами управляется
Go за нас для лаконичности.

Закрытие каналов также является одним из способов сигнализирования нескольких
горутин одновременно. Если у нас есть $n$ горутин, ожидающих на одном канале, то
вместо того, чтобы записывать $n$ раз в канал для разблокировки каждой горутины,
можно просто закрыть канал. Поскольку закрытый канал может быть прочитан
неограниченное число раз, не имеет значения, сколько горутин ожидает его, и
закрытие канала обходится дешевле и быстрее, чем выполнение $n$ операций записи.
Пример разблокировки нескольких горутин одновременно
([`code-samples/channels/channels-multiple-unlock.g`](code-samples/channels/channels-multiple-unlock.go)):

```go
begin := make(chan interface{})

var wg sync.WaitGroup

for i := 0; i < 5; i++ {
  wg.Add(1)

  go func(i int) {
    defer wg.Done()

    <-begin // Здесь горутина ждёт, пока ей сообщат продолжать

    fmt.Printf("%d has begun\n", i)
  }(i)
}

fmt.Println("Unblocking goroutines...")

// Закрываем канал, тем самым разблокируя все горутины одновременно
close(begin)
wg.Wait()
```

Можно видеть, что ни одна из горутин не начнёт работать до тех пор, пока канал
`begin` не будет закрыт:

```
Unblocking goroutines...
0 has begun
4 has begun
3 has begun
2 has begun
1 has begun
```

В разделе "[`sync.Once`](#once)" рассматривался тип `sync.Cond` для реализации
такого же поведения. Можно использовать и его, однако, как мы говорили, каналы
компонуемые, поэтому их использование кажется более идиоматичным.

<!-- TODO: компонуемые (composable)? -->

Мы также можем создавать _буферизированные_ каналы, которым при создании
задаётся какая-то вместимость (capacity). Это означает, что даже если никаких
операций чтения из канала не выполняется, горутина всё равно может выполнить $n$
операций записи, где $n$ — вместимость буферизированного канала. Такой канал
объявляется и инициализируется таким образом:

```go
var dataStream chan interface{}
// Создаём буферизированный канал c вместимостью 4. Это означает, что мы можем
// поместить в него 4 элемента, независимо от того, читается ли он
dataStream = make(chan interface{}, 4)
```

Опять же, создание канала в этом примере разделено на две отдельные строчки.
Интересно здесь то, что вместимость (capacity) канала, в действительности,
задаётся той горутиной, которая его инициализирует. Это наводит на мысль, что
создание канала, вероятно, следует тесно связывать с горутинами, которые будут
выполнять запись в него, таким образом нам будет проще понимать его поведение и
производительность. Мы вернёмся к этому позже.

Небуферизированные каналы также определяются в терминах буферизированных
каналов: небуферизированный канал — это просто буферизированный канал, созданный
с вместимостью (capacity) `0`. Пример двух каналов, которые имеют одинаковую
функциональность:

```go
a := make(chan int)
b := make(chan int, 0)
```

Оба канала — это `int`-каналы с вместимостью (capacity) ноль. Когда мы обсуждали
блокирование, мы сказали, что запись в канал блокируется, когда канал заполнен,
а чтение из канала блокируется, когда канал пустой. «Заполненность» и «пустота»
— это функции вместимости, или размера буфера. Небуферизированный канал имеет
вместимость ноль, поэтому до любой операции записи он уже считается заполненным.
Буферизированный канал без «читателей» с вместимостью `4` будет считаться
заполненным после четырёх операций записи в него и заблокируется на пятой
операции записи, так как ему будет некуда поместить пятый элемент. Как и
небуферизированные каналы, буферизированные каналы являются блокирующими;
отличаются лишь условия, когда канал считается пустым, а когда заполненным.
Таким образом, буферизированные каналы — это **FIFO**-очередь (**F**irst **I**n,
**F**irst **O**ut, «первым пришёл — первым вышел»), с помощью которой общаются
между собой конкурентные процессы.

Демонстрация происходящего в канале с вместимостью (capacity) четыре.
Инициализируем его:

```go
c := make(chan rune, 4)

// Это создаст канал с буфером, состоящим из четырёх слотов:
//
// [ ] [ ] [ ] [ ]
```

Запишем в канал `'A'`. Когда канал не имеет «читателей», руна `'A'` поместиться
на первый слот в буфере канала:

```go
c <- 'A'

// [A] [ ] [ ] [ ]
```

Каждая последующая запись в буферизированный канал (опять же, если нет
«читателей») заполнит оставшиеся слоты в буферизированном канале:

```go
c <- 'B' // [A] [B] [ ] [ ]
c <- 'C' // [A] [B] [C] [ ]
c <- 'D' // [A] [B] [C] [D]
```

После четырёх записей, буферизированный канал с вместимостью (capacity) четыре
заполнился. Что произойдёт, если мы попытаемся записать в канал ещё?

```go
c <- 'E' // [A] [B] [C] [D] <--X-- E
```

Горутина, выполняющая эту запись, окажется заблокированной. Горутина будет
оставаться заблокированной до тех пор, пока какая-либо горутина, выполняющая
чтение, не освободит место в буфере. Это выглядит так:

```go
<-c // A <-- [B] [C] [D] [E]
```

Как можно видеть, операция чтения получила первую руну, которую мы поместили в
канал, `'A'`. Буфер был «обойдён» (от англ. слова "bypass"; то есть, как будто
буфера и не было в цепочке передачи и получения руны), и значение было передано
непосредственно от отправителя к получателю. На практике это происходит
прозрачно, но это стоит знать для понимания профиля производительности
буферизированных каналов.

Буферизированные каналы могут быть полезны в определённых ситуациях, но
создавать их нужно с осторожностью. Как будет показано далее, применение
буферизированных каналов может легко оказаться преждевременной оптимизацией, а
также скрыть deadlock'и, сделав их возникновение более маловероятным.

<!-- // TODO: ссылка на "далее" -->

Рассмотрим более полный пример кода, который использует буферизированные каналы,
чтобы получить лучшее представление об их работе
([`code-samples/channels/buffered-channels.go`](code-samples/channels/buffered-channels.go)):

```go
// Создаём буфер в памяти, чтобы ослабить недетерминированный характер
// вывода. Это не даёт нам никаких гарантий, однако это немного быстрее, чем
// писать в stdout напрямую
var stdoutBuff bytes.Buffer

// Этим мы гарантируем, что содержимое буфера будет записано в stdout перед
// завершением процесса
defer stdoutBuff.WriteTo(os.Stdout)

// Создаём буферизированный канал с вместимостью четыре
intStream := make(chan int, 4)

go func() {
  defer close(intStream)
  defer fmt.Fprintln(&stdoutBuff, "Producer Done.")

  for i := 0; i < 5; i++ {
    fmt.Fprintf(&stdoutBuff, "Sending: %d.\n", i)
    intStream <- i
  }
}()

for i := range intStream {
  _, _ = fmt.Fprintf(&stdoutBuff, "Received %d.\n", i)
}
```

В этом примере порядок вывода в stdout недетерминированный, но всё равно можно
получить приблизительное представление о том, как работает анонимная горутина.
Если посмотреть на вывод программы, можно увидеть, как анонимная горутина может
поместить все пять результатов в `intStream` и завершить свою работу до того,
как main-горутина выведет хотя бы один результат:

```
Sending: 0.
Sending: 1.
Sending: 2.
Sending: 3.
Sending: 4.
Producer Done.
Received 0.
Received 1.
Received 2.
Received 3.
Received 4.
```

Это пример оптимизации, которая может быть полезна при правильных условиях
использования: если горутина, выполняющая запись в канал, знает, сколько записей
она произведёт, может быть полезно создать буферизированный канал, вместимость
которого равна количеству выполняемых записей, а затем выполнить эти записи как
можно быстрее. Конечно, есть и предостережения, мы их рассмотрим позже.

<!-- TODO: ссылка по "позже" -->

Мы рассмотрели небуферизированные каналы, буферизированные каналы,
двунаправленные и однонаправленные каналы. Единственный аспект каналов, который
мы не рассмотрели, — это значение каналов по умолчанию (когда канал ещё не
инициализирован): `nil`. Как программы взаимодействуют с `nil`-каналом?
Во-первых, попробуем прочитать с `nil`-канала:

```go
var dataStream chan interface{}
<-dataStream
```

Произойдёт deadlock:

```
fatal error: all goroutines are asleep - deadlock!

goroutine 1 [chan receive (nil chan)]:
main.main()
  /tmp/sandbox957299940/prog.go:7 +0x17

Program exited.
```

Это индицирует, что чтение с `nil`-канала заблокирует (хотя и не обязательно
deadlock) программу.

Попробуем записать в `nil`-канал:

```go
var dataStream chan interface{}
dataStream <- struct{}{}
```

Произойдёт deadlock:

```
fatal error: all goroutines are asleep - deadlock!

goroutine 1 [chan send (nil chan)]:
main.main()
  /tmp/sandbox2198416751/prog.go:7 +0x32

Program exited.
```

Запись в `nil`-канал тоже приведёт к блокировке.

Осталась одна операция — `close`. Что случится, если попытаться закрыть
`nil`-канал?

```go
var dataStream chan interface{}
close(dataStream)
```

Это произведёт:

```
panic: close of nil channel

goroutine 1 [running]:
main.main()
  /tmp/sandbox1706046939/prog.go:7 +0x15

Program exited.
```

Это, вероятно, худший результат их всех операций, произведённых с `nil`-каналом,
— panic. Следует обязательно убедиться, что каналы, с которыми мы работаем,
инициализированы.

Мы рассмотрели множество правил взаимодействия с каналами. Теперь, когда мы
понимаем, как и почему выполняются операциями с каналами, создадим удобный
«справочник» для определения поведения каналов. В следующей таблицы приведены
операции с каналами и то, что произойдёт с учётом возможных их состояний:

<table>
  <thead>
    <tr>
      <th>Операция</th>
      <th>Состояние канала</th>
      <th>Результат</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="5">Чтение</td>
      <td><code>nil</code></td>
      <td>Блокировка</td>
    </tr>
    <tr>
      <td>Открытый и непустой</td>
      <td>Значение</td>
    </tr>
    <tr>
      <td>Открытый и пустой</td>
      <td>Блокировка</td>
    </tr>
    <tr>
      <td>Закрытый</td>
      <td><code>&lt;значение_по_умолчанию&gt;, false</code></td>
    </tr>
    <tr>
      <td>Только для записи</td>
      <td>Ошибка компиляции</td>
    </tr>
    <tr>
      <td rowspan="5">Запись</td>
      <td><code>nil</code></td>
      <td>Блокировка</td>
    </tr>
    <tr>
      <td>Открытый и заполненный</td>
      <td>Блокировка</td>
    </tr>
    <tr>
      <td>Открытый и незаполненный</td>
      <td>Запись значения</td>
    </tr>
    <tr>
      <td>Закрытый</td>
      <td><b>panic</b></td>
    </tr>
    <tr>
      <td>Только для чтения</td>
      <td>Ошибка компиляции</td>
    </tr>
    <tr>
      <td rowspan="5">Закрытие</td>
      <td><code>nil</code></td>
      <td><b>panic</b></td>
    </tr>
    <tr>
      <td>Открытый и непустой</td>
      <td>Закрытие канала; считывает успешно, пока канал не будет опустошён, после чего операции чтения производят значение по умолчанию</td>
    </tr>
    <tr>
      <td>Открытый и пустой</td>
      <td>Закрытие канала; операции чтения производят значение по умолчанию</td>
    </tr>
    <tr>
      <td>Закрытый</td>
      <td><b>panic</b></td>
    </tr>
    <tr>
      <td>Только для чтения</td>
      <td>Ошибка компиляции</td>
    </tr>
  </tbody>
</table>

Если мы посмотрим на эту таблицу, то увидим несколько ячеек, которые могут
привести к проблемам. У нас есть три операции, которые могут привести к
блокировке горутины, и три операции, которые могут вызвать panic в программе. На
первый взгляд кажется, что использование каналов может быть опасным, но после
исследования мотивации этих возникающих результатов и обоснования использования
каналов это становится менее пугающим и приобретает большой смысл. Взглянем на
то, как мы можем организовать различные типы каналов, чтобы начать создавать
что-то надёжное и стабильное.

Первое, что следует сделать, чтобы поместить каналы в правильный контекст, — это
назначить владельца канала. Владение каналом можно определить так: горутина
владеет каналом, если она инициализирует канал, пишет в него и закрывает.
Подобно работе с памятью в языках без сборщика мусора, важно чётко установить,
какой горутине принадлежит канал, чтобы можно было логически рассуждать о
поведении программы. Объявление однонаправленных каналов — это инструмент,
который позволяет различать горутины, которые владеют каналами и те, которые их
только используют: владельцы каналов имеют доступ к каналу для записи (`chan`
или `chan<-`), а горутины-пользователи имеют доступ к каналу только для чтения
(`<-chan`). Как только мы проведём границы различия между владельцами и
пользователями каналов, результаты в приведённой таблице будут следовать
естественным образом, и мы сможем начать разделять ответственность по отношению
к каналам между горутинами.

Начнём с горутин-владельцев каналами. Горутина, которая владеет каналом, должна:

1. Инициализировать канал (создать экземпляр)
2. Выполнять запись в канал или передавать владение им другой горутине
3. Закрывать канал
4. Инкапсулировать предыдущие 3 пункта и предоставлять их через читательский
   канал (канал только для чтения)

Таким образом когда мы назначаем горутине-владельцу канала эти обязанности,
происходит следующее:

- Поскольку только эта горутина (горутина-владелец) инициализирует канал,
  устраняется риск возникновения deadlock'а при записи в `nil`-канал
- Поскольку только эта горутина инициализирует канал, устраняется риск
  возникновения паники (panic) при закрытии `nil`-канала
- Поскольку только эта горутина решает, когда канал будет закрыт, мы устраняем
  риск возникновения паники (panic) при записи в закрытый канал
- Поскольку только эта горутина решает, когда канал будет закрыт, мы устраняем
  риск возникновения паники (panic) при закрытии канала более одного раза
- Мы используем средство проверки типов (type checker) во время компиляции,
  чтобы предотвратить неправильную запись в канал

Теперь рассмотрим блокирующие операции, которые могут возникать при чтении.
Пользователю канала нужно беспокоиться только о двух вещах:

- Знать, когда канал закрыт
- Ответственно обрабатывать блокировку, возникающую по любой причине

Чтобы решить задачу первого пункта, следует просто проверить второе возвращаемое
значение при операции чтения. Решить задачу второго пункта гораздо сложнее,
потому что это зависит от нашего алгоритма: например, можно установить таймаут,
можно просто прекратить чтение, когда кто-то скажет нам об этом, или вообще
просто заблокироваться на всё время работы процесса. Пользователю горутины также
важно учитывать, что операция чтения может и будет блокироваться. Позже мы
рассмотрим способы достижения любой цели читателя канала.

<!-- TODO: ссылка на "позже" -->

Рассмотрим пример, проясняющий эти концепции. Создадим горутину, которая чисто
владеет каналом, и пользователя, который чисто обрабатывает блокировку и
закрытие канала
([`code-samples/channels/channels-responsibilities.go`](code-samples/channels/channels-responsibilities.go)):

<!-- TODO: чисто (clearly)? -->

```go
chanOwner := func() <-chan int {
  // Инициализируем буферизированный канал. Поскольку мы знаем, что
  // произведём 6 результатов, создадим буферизированный канал с
  // вместимостью 5, чтобы горутина могла завершиться как можно быстрее
  resultStream := make(chan int, 5)

  // Здесь мы запускаем анонимную горутину, которая выполняет запись в
  // resultStream. Следует обратить внимание, что мы изменили способ
  // создания горутин. Теперь горутина инкапсулирована в окружающую
  // функцию
  go func() {
  // Гарантируем, что канал resultStream будет закрыт, как только мы
  // закончим с ним работать. Как владелец канала, мы несём за это
  // ответственность
  defer close(resultStream)

  for i := 0; i <= 5; i++ {
    resultStream <- i
  }
  }()

  // Здесь мы возвращаем канал. Поскольку возвращаемое значение объявлено
  // как канал только для чтения, resultStream будет неявно преобразован в
  // доступный только для чтения для пользователей
  return resultStream
}

resultStream := chanOwner()

// Здесь мы пробегаемся по resultStream. Как пользователя канала, нас
// беспокоят только блокировка и закрытость каналов
for result := range resultStream {
  fmt.Printf("Received: %d.\n", result)
}

fmt.Println("Done receiving!")
```

<!-- TODO: объяснить, почему вместимость канала 5, а кладём 6 -->

Этот код произведёт:

```
Received: 0.
Received: 1.
Received: 2.
Received: 3.
Received: 4.
Received: 5.
Done receiving!
```

Следует обратить внимание, как жизненный цикл канала `resultStream`
инкапсулирован в функцию `chanOwner`. Совершенно очевидно, что запись не будет
выполняться в закрытый или `nil`-канал и что закрытие произойдёт только один
раз. Это устраняет значительную часть рисков в нашей программе. Настоятельно
рекомендуется делать в программах всё возможное, чтобы сохранять скоуп владения
каналом небольшим, чтобы эти вещи оставались очевидными. Если наш канал — это
часть структуры (`struct`) с множеством методов. быстро станет неясно, как канал
будет себя вести.

Функция-пользователь имеет доступ к каналу только для чтения, и поэтому ей нужно
знать, как обрабатывать блокирующие чтения или закрытие канала. В этом небольшом
примере мы придерживаемся позиции, что совершенно нормально блокировать работу
программы до тех пор, пока канал не будет закрыт.

Если разрабатывать свой код в соответствии с этими принципами, станет намного
легче рассуждать о системе, и гораздо более вероятно, что она будет работать
так, как ожидается. Невозможно обещать, что таким образом разработчик никогда не
получит deadlock'ов или паник (panic), но когда это произойдёт, он, вероятно,
обнаружит, что либо скоуп владения стал слишком большим, либо владение стало
неясным.

### Оператор `select`

Оператор `select` — это связующий компонент для каналов. С помощью него мы можем
компоновать каналы вместе для формирования более крупных абстракций. Точно так
же мы говорили про каналы, — они связывают горутины вместе. Тогда что «связующий
компонент для каналов» означает в контексте оператора `select`? Не будет
преувеличением сказать, что операторы `select` — это одна из самых важных вещей
в программе с конкурентностью на Go. Операторы `select` могут связывать каналы
локально — в рамках одной функции или типа, а также глобально — на пересечении
двух или более компонентов в системе. В дополнение к объединению компонентов, на
этих критических моментах нашей программы операторы `select` помогут безопасно
объединить каналы с такими понятиями, как отмена (cancellation), таймауты
(timeouts), ожидание (waiting) и значения по умолчанию.

И наоборот, если операторы `select` — это основной язык нашей программы (лингва
франка) и они имеют дело исключительно с каналами, то как компоненты нашей
программы должны координироваться друг с другом? Этот вопрос мы рассмотрим позже
(подсказка: лучше использовать каналы).

<!-- TODO: ссылка на "позже" и, вообще, не очень понятный абзац -->

Как использовать каналы, очень простой пример:

```go
var c1, c2 <-chan interface{}
var c3 chan<- interface{}

select {
case <- c1:
  // Что-то делаем
case <- c2:
  // Что-то делаем
case c3<- struct{}{}:
  // Что-то делаем
}
```

Выглядит похожим на блок `switch`, не так ли? Точно так же, как и блок `switch`,
блок `select` включает в себя серию операторов `case`, которые включают в себя
серию других выражений, однако на этом сходство заканчивается. В отличие от
блоков `switch`, операторы `case` в блоке `select` не проверяются
последовательно, и выполнение автоматически не проваливается дальше, если ни
одно из условий `case` не соблюдено.

Вместо этого, все операции чтения из канала и записи в канал рассматриваются
одновременно (_то, что происходит под капотом, немного сложнее и будет
рассмотрено позже_), чтобы определить, готова ли какая-либо из них: заполненные
или закрытые каналы в случае с операциями чтения, и каналы, которые не заполнены
до их максимальной вместимости в случае с операциями записи. Если ни один из
каналов не готов, то блокируется вся инструкция `select`. Затем, когда один из
каналов будет готов, операция продолжится, и соответствующие ей инструкции (в
теле `case`) будут выполнены. Рассмотрим краткий пример
([`code-samples/select_statement/select.go`](code-samples/select_statement/select.go)):

<!-- TODO: ссылку на "позже" -->

```go
start := time.Now()

c := make(chan interface{})

go func() {
  time.Sleep(5 * time.Second)
  // Закрываем канал по прошествии пяти секунд
  close(c)
}()

fmt.Println("Blocking on read...")

select {
// Пытаемся читать с канала. Следует обратить внимание, что для такого кода
// не требуется оператор select, — мы могли бы просто написать <-c, но
// напишем его для примера
case <-c:
  fmt.Printf("Unblocking %v later.\n", time.Since(start))
}
```

Этот код произведёт:

```
Blocking on read...
Unblocking 5.001345625s later.
```

Можно видеть, что мы разблокируемся примерно через пять секунд после перехода
управления в блок `select`. Это простой и эффективный способ заблокироваться,
пока мы ждём, пока что-то произойдёт. Но возникают вопросы:

- Что произойдёт, когда нескольким каналам есть что читать?
- Что, если никогда не будет готовых каналов?
- Что если мы хотим что-то сделать, но ни один канал пока не готов?

Первый вопрос об одновременной готовности нескольких каналов кажется интересным.
Попробуем и посмотрим, что получится
([`code-samples/select_statement/select-multiple-ready.go`](code-samples/select_statement/select-multiple-ready.go)):

```go
c1 := make(chan interface{})
close(c1)

c2 := make(chan interface{})
close(c2)

var c1Count, c2Count int

for i := 0; i < 1000; i++ {
  select {
  case <-c1:
    c1Count++
  case <-c2:
    c2Count++
  }
}

fmt.Printf("c1Count: %d\nc2Count: %d\n", c1Count, c2Count)
```

Этот код производит примерно следующее:

```
c1Count: 493
c2Count: 507
```

Как мы можем видеть, за тысячу итераций, примерно в половине случаев оператор
`select` читает с `c1`, и примерно в другой половине он читает с `c2`. Это
выглядит интересным, и возможно, немного слишком случайным. На самом деле так и
есть! Среда выполнения (рантайм) Go выполняет псевдослучайный равномерный выбор
(pseudorandom uniform selection) по набору операторов `case`. Это просто
означает, что из нашего набора операторов `case`, каждый имеет равные шансы быть
выбранным по отношению к другим.

На первый взгляд это может показаться неважным, но рассуждения, стоящие за этим,
невероятно интересны. Сначала сделаем довольно очевидное утверждение: среда
выполнения Go ничего не может знать о намерениях нашего оператора `select`; то
есть, она не может определить нашу предметную область или почему мы объединили
группу каналов в операторе `select`. Поэтому лучшее, на что среда выполнения Go
может надеяться, — это хорошая работа с среднем случае. Хороший способ добиться
этого — ввести случайную величину в уравнение — в данном случае, какой канал
выбрать. При взвешивании вероятности каждого канала быть использованным так,
чтобы она была равной, все программы на Go, использующие оператор `select`,
будут хорошо работать в среднем случае.

<!-- TODO: разобраться с "проблемными" и "предметными" областями. Может здесь
вообще не они, речь в оригинале идёт о problem space -->

Насчёт второго вопроса: что, если никогда не будет готовых каналов? Если мы не
можем сделать никакой полезной работы, когда все каналы заблокированы, и при
этом мы также рискуем заблокироваться навсегда, то, возможно, мы захотим
добавить таймауты. Пакет `time` в Go предоставляет элегантный способ сделать это
с помощью каналов, который хорошо вписывается в парадигму операторов `select`.
Пример его использования
([`code-samples/select_statement/select-timeout.go`](code-samples/select_statement/select-timeout.go)):

```go
var c <-chan int

select {
// Этот оператор case никогда не будет разблокирован, поскольку он хочет
// читать с nil-канала
case <-c:
case <-time.After(1 * time.Second):
  fmt.Println("Timed out.")
}
```

Этот код произведёт:

```
Timed out.
```

Функция `time.After` принимает аргумент типа `time.Duration` и возвращает канал,
который отправит текущее время по истечении указанного времени. Это предлагает
краткий способ таймаута в операторах `select`. Мы вернёмся к этому паттерну
позже и обсудим более надёжное решение этой проблемы.

<!-- TODO: ссылка на "позже" -->

Остаётся последний вопрос: что если мы хотим что-то сделать, но ни один канал
пока не готов? Как и блок `switch`, блок `select` также позволяет использовать
оператор `default` на случай, если мы хотим что-то сделать, когда оказывается,
что все каналы, по которым мы `select`'им, заблокированы. Пример
([`code-samples/select_statement/select-default.go`](code-samples/select_statement/select-default.go)):

```go
start := time.Now()

var c1, c2 <-chan int

select {
case <-c1:
case <-c2:
default:
  fmt.Printf("Control in default clause after %v\n", time.Since(start))
}
```

Этот код произведёт что-то такое:

```
Control in default clause after 1.584µs
```

Можно заметить, что мы оказались в инструкции `default` почти мгновенно. Это
позволяет нам выйти из блока `select` без блокировки. Обычно можно увидеть
`default` в сочетании с циклом `for`-`select`. Это позволяет горутине выполнять
работу, при этом ещё и ожидая результата от другой горутины. Пример этого
([`code-samples/select_statement/select-default-in-for.go`](code-samples/select_statement/select-default-in-for.go)):

```go
done := make(chan interface{})

go func() {
  time.Sleep(5 * time.Second)
  close(done)
}()

workCounter := 0

loop:
for {
  select {
  case <-done:
    break loop
  default:
  }

  // Симулируем работу
  workCounter++
  time.Sleep(1 * time.Second)
}

fmt.Printf("Achieved %d cycles of work before signalled to stop.\n", workCounter)
```

Этот код произведёт (результат недетерминирован!):

```
Achieved 5 cycles of work before signalled to stop.
```

В этом случае у нас есть цикл, который выполняет какую-то работу и время от
времени проверяет, следует ли ему остановиться.

Наконец, существует особый случай пустых операторов `select`: операторы `select`
без операторов `case`. Они выглядят так:

```go
select {}
```

Это выражение просто заблокирует навсегда.

### Рычаг `GOMAXPROCS`

В пакете `runtime` Go есть функция под названием `GOMAXPROCS`. Кажется, название
может ввести в заблуждение: можно подумать, что эта функция как-то относится к
количеству логических процессоров на хост-машине — и в первом приближении это
так — но на самом деле эта функция контролирует количество потоков операционной
системы, которые будут размещать так называемые «рабочие очереди» ("work
queues"). Позже мы разберём принцип её работы более подробно.

<!-- TODO: ссылка на "позже" -->

До Go 1.5 `GOMAXPROCS` всегда был установлен в один, и обычно этот фрагмент
можно было найти в большинстве программ Go:

```go
runtime.GOMAXPROCS(runtime.NumCPU())
```

Почти всегда разработчики хотели воспользоваться всеми ядрами на машине, на
которой запущен их процесс. Из-за этого в последующих версиях Go `GOMAXPROCS`
автоматически устанавливается равным количеству логических процессоров на
хост-машине.

Почему мы можем захотеть изменить это значение? Большую часть времени мы не
захотим. Алгоритм планирования Go достаточно хорош для большинства ситуаций, так
что увеличение или уменьшение количества рабочих очередей (work queues) и
потоков, скорее всего, принесёт больше вреда, чем пользы. Но всё ещё есть
некоторые ситуации, когда изменение этого значения может быть полезно.

> Иногда увеличение этого значения может помочь чаще ловить состояния гонки. Так
> может быть проще их находить и исправлять.
