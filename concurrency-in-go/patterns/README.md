## Содержание <!-- omit in toc -->

- [Паттерны конкурентности в Go](#паттерны-конкурентности-в-go)
  - [Изоляция (Confinement)](#изоляция-confinement)
  - [Цикл for-select](#цикл-for-select)
  - [Предотвращение утечек горутин](#предотвращение-утечек-горутин)
  - [Канал с выбором (The or-channel)](#канал-с-выбором-the-or-channel)
  - [Обработка ошибок](#обработка-ошибок)

## Паттерны конкурентности в Go

В этом разделе мы подробно рассмотрим, как компоновать примитивы конкурентности
в паттерны, чтобы сохранять систему масштабируемой и поддерживаемой.

> Во многих примерах далее будут использоваться каналы с типом `interface{}`.
> Использование пустых интерфейсов в Go — это дискуссионный момент. Однако, это
> сделано по нескольким причинам. Первая причина заключается в том, что это
> позволяет писать примеры кода проще и лаконичнее. Вторая причина — часто такое
> стиль более репрезентативен, когда речь идёт о паттерне.

### Изоляция (Confinement)

<!-- TODO: убедиться, что confinement удачно переведён, может быть "ограничение"? -->

При работе с конкурентным кодом есть несколько различных вариантов обеспечить
его безопасность:

- Примитивы синхронизации для совместного использования памяти (например,
  `sync.Mutex`)
- Синхронизация через коммуникацию (например, каналы)

Тем не менее, есть несколько других вариантов, которые неявно безопасны при
нескольких конкурентных процессов:

- Неизменяемые (immutable) данные
- Данные, защищённые изоляцией (confinement)

В некотором смысле неизменяемые данные — это идеальный вариант, поскольку они
неявно потокобезопасны. Каждый конкурентный процесс может работать с одними и
теми же данными, но он не может их изменять. Если он хочет создать новые данные,
он должен создать новую копию данных с желаемыми изменениями. Это позволяет не
только снизить когнитивную нагрузку на разработчика, но и может поспособствовать
ускорению программ, если это приводит к уменьшению размера критических секций
(или совсем их устраняет). В Go можно достичь этого, написав код, который
использует копии значений вместо указателей (pointers) на значения в памяти.
Некоторые языки поддерживают использование указателей с явно неизменяемыми
(immutable) значениями, однако, Go не входит в их число.

<!-- TODO: потокобезопасны -> безопасны для конкурентности (concurrent-safe)? (везде) -->

<!-- TODO: Некоторые языки поддерживают использование указателей с явно неизменяемым (immutable) значениями? -->

Изоляция (confinement) также может обеспечить снижение когнитивной нагрузки на
разработчика и уменьшение размера критических секций. Техники изоляции
конкурентных значений немного сложнее, чем просто передача копий значений,
поэтому здесь мы подробно рассмотрим эти техники.

Изоляция (confinement) — это простая, но мощная идея обеспечения того, чтобы
информация была доступна только из _одного_ конкурентного процесса. Когда это
достигается, конкурентная программа неявно безопасна, и синхронизация не
требуется. Существуют два вида изоляций: специальная (ad hoc) и лексическая
(lexical).

Специальная изоляция — это когда мы достигаем изоляции через соглашение
(конвенцию), неважно кем установленное — сообществом языка, командой, в которой
мы работаем, или кодовой базой, с которой мы работаем. Но придерживаться
соглашения трудно для проектов любого размера, если нет инструментов
статического анализа кода, выполняемого каждый раз, когда кто-то коммитит свой
код. Вот пример специальной изоляции, демонстрирующей, почему это так:

```go
data := make([]int, 4)

loopData := func(handleData chan<- int) {
    defer close(handleData)

    for i := range data {
        handleData <- data[i]
    }
}

handleData := make(chan int)
go loopData(handleData)

for num := range handleData {
    fmt.Println(num)
}
```

Можно видеть, что слайс целых чисел `data` доступен как из функции `loopData`,
так и из цикла, проходящего по каналу `handleData`. Однако, по соглашению мы
получаем доступ к нему только из функции `loopData`. Но код трогается многими
людьми, дедлайны поджимают, ошибки могут быть совершены, а значит, изоляция
(confinement) может быть нарушена и вызвать проблемы. Как уже упоминалось,
инструмент статического анализа может отлавливать такого рода проблемы, но
статический анализ кодовой базы Go предполагает уровень зрелости, которого
достигают не многие команды. Именно поэтому кажется предпочтительнее
использовать лексическую изоляцию: она использует компилятор для обеспечения
изоляции (confinement).

Лексическая изоляция включает в себя использование лексической области видимости
(скоупа) для предоставления только правильных данных и примитивов конкурентности
для использования несколькими конкурентными процессами. Это делает невозможным
делать что-то неправильное. На самом деле мы уже затронули это в секции
[Каналы](../building-blocks/README.md#каналы), когда обсуждали предоставление
только читательских или только писательских аспектов канала конкурентным
процессам, нуждающимся в канале. Ещё раз взглянем на этот пример
[`code-samples/confinement/channels.go`](code-samples/confinement/channels.go):

```go
chanOwner := func() <-chan int {
// Инициализируем канал в пределах лексической области (скоупа) функции
// chanOwner. Это ограничивает область действия аспекта записи в канал
// results замыканием, определённым ниже. Другими словами, это изолирует
// аспект записи канала, чтобы предотвратить запись в него другими
// горутинами
results := make(chan int, 5)

go func() {
  defer close(results)

  for i := 0; i <= 5; i++ {
    results <- i
  }
}()

return results
}

// Получаем копию int-канала только для чтения. Объявляя, что единственное
// использование, которое нам требуется, — это доступ для чтения, мы
// изолируем использование канала в функции consume только чтениями
consumer := func(results <-chan int) {
  for result := range results {
    fmt.Printf("Received: %d\n", result)
  }

  fmt.Println("Done receiving!")
}

// Получаем аспект чтения канала и можем передать его в consumer, который
// ничего не сможет делать, кроме как читать из него. Ещё раз, это изолирует
// main-горутину так, чтобы она могла только читать из канала
results := chanOwner()
consumer(results)
```

Это хороший ввод в паттерн изоляции (confinement), но, вероятно, не очень
показательный, поскольку каналы потокобезопасны. Взглянем на пример изоляции,
использующей структуру данных, которая не является потокобезопасной —
`bytes.Buffer`
([`code-samples/confinement/bytes-buffer.go`](code-samples/confinement/bytes-buffer.go)):

```go
printData := func(wg *sync.WaitGroup, data []byte) {
  defer wg.Done()

  var buff bytes.Buffer
  for _, b := range data {
    _, _ = fmt.Fprintf(&buff, "%c", b)
  }

  fmt.Println(buff.String())
}

var wg sync.WaitGroup
wg.Add(2)

data := []byte("golang")

go printData(&wg, data[:3]) // передаём слайс из первых трёх байт data
go printData(&wg, data[3:]) // передаём слайс из последних трёх байт data

wg.Wait()
```

В этом примере можно видеть, что поскольку `printData` не замкнут вокруг слайса
`data`, он не может получить доступ к нему и должен принять слайс `byte`'ов, с
которым будет работать. Мы передаём разные подмножества слайса, таким образом
ограничивая запускаемые нами горутины только той частью слайса, которую мы
передаём. Благодаря лексическому скоупу мы сделали невозможными (мы намеренно
игнорируем возможность ручного манипулирования памятью с помощью пакета
`unsafe`; он не просто так называется `unsafe`!) неправильные действия, и
поэтому нам не нужно синхронизировать доступ к памяти или делиться данными через
коммуникацию.

<!-- TODO: а что, если передать просто data? Непонятно, где здесь лексическая изоляция -->

Так в чём смысл? Зачем стремиться к изоляции (confinement), если нам доступна
синхронизация? Ответ заключается в повышении производительности и снижении
когнитивной нагрузки на разработчиков. Синхронизация сопряжена с затратами, и
если мы можем избежать этого, у нас не будет критических секций, и,
следовательно, нам не придётся «оплачивать» их синхронизацию. Мы также обходим
целый класс проблем, возможных при использовании синхронизации; разработчикам
просто не нужно беспокоиться об этих проблемах. Конкурентный код, использующий
лексическую изоляцию, также имеет преимущество в более простом понимании по
сравнению с конкурентным кодом без лексически ограниченных переменных. Это
потому, что в контексте нашего лексического скоупа мы можем писать синхронный
код.

Иногда может быть трудно установить изоляцию и поэтому иногда приходится
возвращаться к нашим замечательным примитивам конкурентности Go.

### Цикл for-select

То, что мы будем видеть снова и снова в программах на Go, — это цикл for-select.
Это не что иное, как что-то вроде этого:

```go
for { // Либо бесконечный цикл, либо перебор чего-то
  select {
    // Некоторая работа с каналами
  }
}
```

Есть несколько различных сценариев, где можно встретить этот паттерн.

- Отправка переменных итерации в канал

  Часто может захотеться преобразовать что-то, что можно проитерировать, в
  значения в канале. В этом нет ничего необычного, и обычно это выглядит
  примерно так:

  ```go
  for _, s := range []string{"a", "b", "c"} {
    select {
    case <-done:
      return
    case stringStream <- s:
    }
  }
  ```

- Бесконечный цикл, ожидающий остановки

  Очень частое явление создавать горутины, которые содержат бесконечно что-то
  делают, пока не будут остановлены. Существует пара вариантов, как это сделать.
  Выбор зависит исключительно от стилистических предпочтений.

  Первый вариант сохранят выражение `select` как можно более коротким:

  ```go
  for {
    select {
    case <-done:
      return
    default:
    }

    // Выполняем операции, которые не могут быть прерваны
  }
  ```

  Если канал `done` не закрыт, мы выйдем из инструкции `select` и перейдём к
  остальной части нашего цикла `for`.

  Второй вариант встраивает работу в выражение `default`:

  ```go
  for {
    select {
    case <-done:
      return
    default:
      // Выполняем операции, которые не могут быть прерваны
    }
  }
  ```

  Когда мы входим в `select`, если канал `done` не был закрыт, мы выполняем
  содержимое `default`.

### Предотвращение утечек горутин

В разделе [«Горутины»](../building-blocks/README.md#горутины) мы узнали, что
создавать горутины дёшево и просто; это одна из вещей, которая делает Go таким
производительным языком. Рантайм (среда выполнения) обрабатывает
мультиплексирование горутин на любое число потоков операционной системы, так что
нам не часто приходится беспокоиться об этом уровне абстракции. Однако горутины
всё равно стоят каких-то ресурсов, и при этом они не собираются сборщиком мусора
в рантайме. Поэтому, несмотря на то, сколько мало памяти они занимают, мы не
хотим оставлять их в нашем процессе. Так как же нам убедиться, что они
освободили память?

Будем размышлять шаг за шагом: зачем нужна горутина? Ранее мы установили, что
горутины представляют собой единицы работы (units of work), которые могут
выполняться либо параллельно, либо нет. Горутина имеет несколько путей для
завершения (termination):

- Когда она завершила свою работу
- Когда она не может продолжить свою работу из-за неустранимой ошибки
  (unrecoverable error)
- Когда ей сообщили прекратить работу

Первые два пути нам достаются бесплатно — эти пути являются нашим алгоритмом —
но что насчёт отмены работы (work cancellation)? Это оказывается самым важным
моментом из-за сетевого эффекта: если мы запустили горутину, вероятнее всего,
она каким-то организованным образом взаимодействует с несколькими другими
горутинами. Мы могли бы даже представить эту взаимосвязь в виде графа: вопрос о
том, должна ли дочерняя горутина продолжать выполнение, может основываться на
знании состояния многих _других_ горутин. Родительская горутина (часто
main-горутина), обладающая всеми этими контекстуальными знаниями, должна быть в
состоянии сообщить своим дочерним горутинам о том, что нужно завершить работу.
Мы продолжим рассмотрение крупномасштабной взаимозависимости горутин позже, а
пока рассмотрим, как обеспечить гарантированную очистку одной дочерней горутины.
Начнём с простого примера утечки горутины
([`code-samples/preventing-goroutine-leaks/simple-goroutine-leak.go`](code-samples/preventing-goroutine-leaks/simple-goroutine-leak.go)):

<!-- TODO: ссылка на "позже" -->

```go
doWork := func(strings <-chan string) <-chan interface{} {
  completed := make(chan interface{})

  go func() {
    defer fmt.Println("doWork exited.")
    defer close(completed)

    for s := range strings {
      // Делаем что-то интересное
      fmt.Println(s)
    }
  }()

  return completed
}

doWork(nil)

// Здесь может быть проделана ещё какая-либо работа

fmt.Println("Done.")
```

Здесь мы видим, что main-горутина передаёт `nil`-канал в `doWork`. Таким
образом, канал `strings` на самом деле никогда не получит никаких строк, и
содержащаяся в `doWork` горутина останется в памяти на всё время существования
этого процесса (мы бы даже упали в deadlock, если бы создали точку соединения
(join point) горутины внутри `doWork` с main-горутиной).

В этом примере время жизни процесса очень короткое, но в реальной программе
горутины легко могли бы быть запущены в начале долгоживущей программы. В худшем
случае main-горутина может продолжать запускать горутины на протяжении всего
срока службы, что приведёт к постоянному увеличению потребления памяти по мере
работы процесса.

Способом успешного устранения этого является установление сигнала между
родительской горутиной и её дочерними горутинами. По соглашению, этот сигнал
обычно является каналом только для чтения с именем `done`. Родительская горутина
передаёт этот канал дочерней горутине, а затем закрывает канал, когда хочет
отменить дочернюю горутину. Пример
([`code-samples/preventing-goroutine-leaks/done-channel.go`](code-samples/preventing-goroutine-leaks/done-channel.go)):

```go
// В функции doWork ожидаем канал done. По соглашению он должен быть первым
// параметром
doWork := func(done <-chan interface{}, strings <-chan string) <-chan interface{} {
  terminated := make(chan interface{})

  go func() {
    defer fmt.Println("doWork exited.")
    defer close(terminated)

    for {
      select {
      case s := <-strings:
        // Делаем что-то интересное
        fmt.Println(s)
      // Здесь мы видим повсеместно используемый паттерн for-select.
      // Одним из наших условий является проверка того, был ли сигнал
      // горутине из канала done. Если да, то мы возвращаемся из
      // горутины
      case <-done:
        return
      }
    }
  }()

  return terminated
}

done := make(chan interface{})
terminated := doWork(done, nil)

// Здесь создаём другую горутину, которая отменит горутину, созданную в
// doWork, если пройдёт более одной секунды
go func() {
  // Останавливаем операцию через 1 секунду
  time.Sleep(1 * time.Second)
  fmt.Println("Canceling doWork goroutine.")
  close(done)
}()

// Точка соединения (join point) горутины, созданной в doWork с
// main-горутиной
<-terminated

fmt.Println("Done.")
```

Результат выполнения:

```
Canceling doWork goroutine.
doWork exited.
Done.
```

Можно видеть, что, несмотря на передачу значения `nil` для нашего канала
`strings`, наша горутина по-прежнему успешно завершает работу. В отличие от
предыдущего примера, в этом примере мы соединяем (join) две горутины и, тем не
менее, не получаем взаимоблокировку (deadlock). Это связано с тем, что перед
соединением (join) двух горутин мы создаём третью горутину, чтобы отменить
горутину в `doWork` через секунду. Мы успешно устранили утечку нашей горутины!

Предыдущий пример прекрасно обрабатывает случай, когда горутина получает данные
из канала, но что если мы имеем дело с обратной ситуацией: горутина
заблокирована при попытке записать значение в канал? Вот краткий пример,
демонстрирующий проблему
([`code-samples/preventing-goroutine-leaks/producer-block.go`](code-samples/preventing-goroutine-leaks/producer-block.go)):

```go
newRandStream := func() <-chan int {
  randStream := make(chan int)

  go func() {
    // Выводим сообщение, когда горутина успешно завершается
    defer fmt.Println("newRandStream closure exited.")

    defer close(randStream)

    for {
      randStream <- rand.Int()
    }
  }()

  return randStream
}

randStream := newRandStream()

fmt.Println("3 random ints:")
for i := 0; i < 3; i++ {
  fmt.Printf("%d: %d\n", i+1, <-randStream)
}
```

Код производит примерно следующий результат:

```
3 random ints:
1: 2399527266310276677
2: 4640016047858466284
3: 5606599328692408164
```

По результату выполнения кода можно увидеть, что отложенный вызов `fmt.Println`
никогда не срабатывает. После третьей итерации нашего цикла горутина блокирует
попытку отправить следующее случайное число в канал, из которого больше не
выполняется чтение. У нас нет способа сообщить горутине-производителю, что она
может больше не пытаться слать значения в канал. Решение, как и в случае с
примером с горутиной-получателем, состоит в том, чтобы предоставить горутине
канал, информирующий её о выходе
([`code-samples/preventing-goroutine-leaks/producer-ok.go`](code-samples/preventing-goroutine-leaks/producer-ok.go)):

```go
newRandStream := func(done <-chan interface{}) <-chan int {
  randStream := make(chan int)

  go func() {
    defer fmt.Println("newRandStream closure exited.")

    defer close(randStream)

    for {
      select {
      case randStream <- rand.Int():
      case <-done:
        return
      }
    }
  }()

  return randStream
}

done := make(chan interface{})
randStream := newRandStream(done)

fmt.Println("3 random ints:")
for i := 0; i < 3; i++ {
  fmt.Printf("%d: %d\n", i+1, <-randStream)
}

close(done)

// Имитируем продолжающуюся работу
time.Sleep(1 * time.Second)
```

Этот код произведёт примерно следующее:

```
3 random ints:
1: 302978367576501321
2: 7580288934885243035
3: 6700322878534526592
newRandStream closure exited.
```

Теперь мы видим, что горутина должным образом очищена.

Теперь, когда мы знаем, как обеспечить, чтобы горутины не утекали, можно
оговорить соглашение: _если горутина отвечает за создание горутины, она также
отвечает за обеспечение того, чтобы она могла остановить горутину_.

Это соглашение помогает гарантировать, что наши программы будут компонуемые и их
будет можно масштабировать по мере их роста. Мы вернёмся к этому методу в
разделах "Pipelines" и "Пакет context". Способы, которыми мы обеспечиваем
возможность остановки горутин, могут отличаться в зависимости от типа и
назначения горутины, но все они основаны на передаче `done`-канала.

<!-- TODO: компонуемые (composable)? -->

<!-- TODO: ссылки и норм перевод разделов "Pipelines" и "Пакет context" -->

### Канал с выбором (The or-channel)

Иногда хочется объединить один или несколько `done`-каналов в один `done`-канал,
который будет закрываться, если любой из его составляющих каналов закрывается.
Вполне приемлемо, хотя и довольно многословно, написать оператор `select`,
который выполняет это связывание каналов; однако, иногда мы не можем знать
количество `done`-каналов, с которыми рантайму (среде выполнения) придётся
работать. В таком случае, или если мы просто предпочитаем однострочный вариант,
мы можем объединить эти каналы вместе, используя паттерн _канал с выбором_
(_or-channel_).

Этот паттерн создаёт составной `done`-канал через рекурсию и горутины. Посмотрим
на пример
([`code-samples/or-channel/or-channel.go`](code-samples/or-channel/or-channel.go)):

```go
// Наша функция or, которая принимает произвольный слайс каналов и возвращает
// одиночный канал
func or(channels ...<-chan interface{}) <-chan interface{} {
  switch len(channels) {
  // Поскольку это рекурсивная функция, мы должны задать базовый случай.
  // В первом случае, если произвольный слайс пустой, мы просто вернём
  // nil-канал. Это консистентно с общим ожидаемым поведением функции:
  // в случае, когда мы не передали ни один канал, мы не ожидаем, что
  // составной канал что-то будет делать
  case 0:
    return nil
  // Второй базовый случай: если произвольный слайс состоит только из одного
  // элемента, мы просто вернём этот же элемент
  case 1:
    return channels[0]
  }

  orDone := make(chan interface{})

  // Основное тело функции, где происходит рекурсия. Мы создаём горутину,
  // чтобы мы могли ожидать сообщения на наших каналах без блокировки
  go func() {
    defer close(orDone)

    switch len(channels) {
    // Из-за того, как мы выполняем рекурсию, каждый рекурсивный вызов or
    // будет иметь, по крайней мере, два канала. В качестве оптимизации,
    // чтобы ограничить количество создаваемых горутин, мы помещаем здесь
    // особый случай для вызовов or только с двумя каналами
    case 2:
      select {
      case <-channels[0]:
      case <-channels[1]:
      }
    // Здесь мы рекурсивно создаём or-канал из всех каналов из нашего
    // слайса, начиная с индекса 3, а затем выполняем select по ним. Это
    // рекуррентное соотношение деструктурирует остальную часть среза на
    // or-каналы, чтобы сформировать дерево, из которого вернётся первый
    // сигнал. Мы также передаём канал orDone, чтобы когда горутины вверху
    // дерева завершатся, горутины внизу также завершились.
    default:
      select {
      case <-channels[0]:
      case <-channels[1]:
      case <-channels[2]:
      case <-or(append(channels[3:], orDone)...):
      }
    }
  }()

  return orDone
}
```

<!-- TODO: добавить какую-то иллюстрацию, изобразить дерево рекурсии, например -->

Это довольно простая функция, которая позволяет объединить любое количество
каналов в один канал, который закроется, как только любой из его составляющих
каналов будет закрыт или в него будет записана информация. Посмотрим, как мы
можем использовать эту функцию. Краткий пример, в котором используются каналы,
закрывающиеся по истечении заданного времени, и используется функция `or` для
объединения их в один канал, который закрывается
([`code-samples/or-channel/or-channel-usage.go`](code-samples/or-channel/or-channel-usage.go)):

> Чтобы запустить этот код, можно воспользоваться командой
> `go run or-channel/*.go`.

```go
// Эта функция просто создаёт канал, который закрывается по прошествии
// времени, указанного в after
sig := func(after time.Duration) <-chan interface{} {
  c := make(chan interface{})

  go func() {
    defer close(c)
    time.Sleep(after)
  }()

  return c
}

// Здесь мы запоминаем приблизительное время, когда канал из функции or
// начинает блокировать main-горутину
start := time.Now()

<-or(
  sig(2*time.Hour),
  sig(5*time.Minute),
  sig(1*time.Second),
  sig(1*time.Hour),
  sig(1*time.Minute),
)

// Выводим время, которое потребовалось для выполнения считывания из канала,
// возвращённого функцией or
fmt.Printf("done after %v\n", time.Since(start))
```

<!-- TODO: на этом моменте я понял, что не форматировал комментарии в коде в
MD-файле, чтобы они оптимально вписывались в editor.rules -->

Если мы запустим эту программу, получим примерно такой результат:

```
done after 1.001202334s
```

Следует обратить внимание, что, несмотря на размещение нескольких каналов при
вызове нашей функции `or`, закрытие которых занимает разное время, канал,
закрывающийся через одну секунду, приводит к закрытию всего результирующего
канала, созданного вызовом `or`. Это происходит потому, что, несмотря на своё
место в дереве, которое строит функция `or`, он всегда будет закрываться первым,
и, таким образом, каналы, зависящие от его закрытия, также закроются.

Мы достигаем этой лаконичности за счёт создания дополнительных горутин —
$f\left(x\right) = \left\lfloor \dfrac{x}{2} \right\rfloor$
([округление к меньшему](https://ru.wikipedia.org/wiki/Целая_часть)), где $x$ —
это количество каналов, — но следует помнить, что одной из сильных сторон Go
является способность быстро создавать, планировать и запускать горутины, и язык
активно поощряет использование горутин для моделирования проблем (задач)
правильно. Беспокойство о количестве создаваемых здесь горутинах, вероятно,
является преждевременной оптимизацией. Опять же, если во время компиляции мы не
знаем, со сколькими `done`-каналами мы работаем, другого способа объединить
`done`-каналы нет.

<!-- TODO: убедиться, что я правильно исправил ошибку x - число -горутин- -> каналов -->

Этот паттерн полезно использовать на пересечении модулей в нашей системе. В этих
местах обычно возникает несколько условий для отмены деревьев горутин по стеку
вызовов. Используя функцию `or` мы можем просто объединить их вместе и передать
вниз по стеку. Мы также рассмотрим другой способ сделать это в разделе "Пакет
context", что тоже является хорошим способом, и, возможно, более описательным.

<!-- TODO: норм ссылка и название раздела "пакет context" -->

Мы также рассмотрим, как мы можем использовать вариацию этого паттерна для
формирования более сложного паттерна в разделе "Replicated Requests".

<!-- TODO: норм ссылка и название раздела "replicated requests" -->

### Обработка ошибок

В конкурентных программах бывает сложно правильно организовать обработку ошибок.
Иногда мы тратим так много времени на размышления о том, как наши различные
процессы будут обмениваться информацией и координироваться, что забываем
подумать о том, как изящно (gracefully) они будут обрабатывать ошибочные
состояния. Когда Go отказался от популярной модели представления ошибок в виде
исключений (exceptions), он как бы сделал заявление, что обработка ошибок важна,
и что при разработке наших программ мы должны уделять путям возникновения ошибок
такое же внимание, какое уделяем нашим алгоритмам. В этом же духе давайте
взглянем на том, как мы это делаем с несколькими конкурентными процессами.

Самый фундаментальный вопрос, который возникает при обработке ошибок, — «Кто
ответственен за обработку ошибки?». В какой-то момент программе всё же
необходимо прекратить передачу ошибки по стеку и действительно что-то с ней
сделать. Кто за это отвечает?

С конкурентными процессами, этот вопрос становится немного более комплексным.
Поскольку конкурентный процесс работает независимо от своего родителя или других
дочерних элементов родителя, ему может быть сложно принять решение о том, как
правильно поступить с ошибкой. Взглянем на этот код для понимания этой проблемы
([`code-samples/error-handling/issue.go`](code-samples/error-handling/issue.go)):

```go
checkStatus := func(done <-chan interface{}, urls ...string) <-chan *http.Response {
  responses := make(chan *http.Response)

  go func() {
    defer close(responses)

    for _, url := range urls {
      resp, err := http.Get(url)
      if err != nil {
        // Здесь мы видим, что горутина делает всё возможное, чтобы
        // сигнализировать о наличии ошибки. Что ещё она может сделать? Она не
        // может передать эту ошибку обратно. Сколько ошибок считать слишком
        // большим количеством? Продолжает ли она после сигнала об ошибке
        // отправлять запросы?
        fmt.Println(err)
        continue
      }

      select {
      case <-done:
        return
      case responses <- resp:
      }
    }
  }()

  return responses
}

done := make(chan interface{})
defer close(done)

urls := []string{"https://google.com", "https://badhost"}
for response := range checkStatus(done, urls...) {
  fmt.Printf("Response: %v\n", response.Status)
}
```

Этот код произведёт следующее:

```
Response: 200 OK
Get "https://badhost": dial tcp: lookup badhost: no such host
```

Здесь мы видим, что у горутины не было выбора в этом вопросе. Она не может
просто «проглотить» эту ошибку, и поэтому она делает единственную разумную вещь:
печатает эту ошибку и надеется, что кто-то обратит внимание. Не нужно ставить
свои горутины в такое неловкое положение. Можно руководствоваться следующим: в
общем, нашим конкурентным процессам следует отправлять ошибки в другую часть
нашей программы, которая обладает полной информацией о состоянии нашей программы
и может принять более обоснованное решение о том, что делать. Следующий пример
демонстрирует правильное решение этой проблемы
([`code-samples/error-handling/example.go`](code-samples/error-handling/example.go)):

```go
// Создаём тип, который включает в себя как *http.Response, так и ошибку,
// возможную в цикле нашей горутины
type Result struct {
  Error    error
  Response *http.Response
}

// Эта функция возвращает канал, из которого можно считывать результаты
// итераций нашего цикла
checkStatus := func(done <-chan interface{}, urls ...string) <-chan Result {
  results := make(chan Result)

  go func() {
    defer close(results)

    for _, url := range urls {
      resp, err := http.Get(url)

      // Создаём инстанс Result с необходимым набором полей
      result := Result{
        Error:    err,
        Response: resp,
      }

      select {
      case <-done:
        return
      // Пишем result в канал
      case results <- result:
      }
    }
  }()

  return results
}

done := make(chan interface{})
defer close(done)

urls := []string{"https://google.com", "https://badhost"}
for result := range checkStatus(done, urls...) {
  // Здесь, в нашей main-горутине, мы можем разумнее обрабатывать ошибки,
  // возникающие в горутине, запущенной из checkStatus, и в рамках более
  // обширного контекста
  if result.Error != nil {
    fmt.Printf("error: %v\n", result.Error)
    continue
  }

  fmt.Printf("Response: %v\n", result.Response.Status)
}
```

Этот код произведёт следующее:

```
Response: 200 OK
error: Get "https://badhost": dial tcp: lookup badhost: no such host
```

Ключевой момент, на который следует обратить внимание, — это то, как мы связали
потенциальный результат с потенциальной ошибкой. Это представляет собой полный
набор возможных результатов, созданных горутиной из `checkStatus`, и позволяет
нашей main-горутине принимать решение о том, что делать в случае ошибки. В более
широком смысле, мы успешно отделили задачи обработки ошибок от нашей
горутины-производителя. Так делать желательно потому, что горутина, которая
создала горутину-производителя — в данном случае так сделала main-горутина —
имеет больше информации о запущенной горутине и может принимать более разумные
решения о том, что делать с ошибками.

В предыдущем примере мы просто записывали ошибки в `stdout`, но мы могли бы
сделать кое-что ещё. Давайте изменим нашу программу так, чтобы она перестала
проверять статус при возникновении трёх или более ошибок
([`code-samples/error-handling/example-2.go`](code-samples/error-handling/example-2.go)):

```go
done := make(chan interface{})
defer close(done)

errCount := 0

urls := []string{"a", "https://google.com", "b", "c", "d"}
for result := range checkStatus(done, urls...) {
  if result.Error != nil {
    fmt.Printf("error: %v\n", result.Error)

    errCount++

    if errCount >= 3 {
      fmt.Println("Too many errors, breaking!")
      break
    }

    continue
  }

  fmt.Printf("Response: %v\n", result.Response.Status)
}
```

Результат выполнения этого кода:

```
error: Get "a": unsupported protocol scheme ""
Response: 200 OK
error: Get "b": unsupported protocol scheme ""
error: Get "c": unsupported protocol scheme ""
Too many errors, breaking!
```

Можно видеть, что, поскольку ошибки возвращаются из `checkStatus` и не
обрабатываются внутри горутины, обработка ошибок выполняется по присущему Go
паттерну. Это лишь простой пример, но нетрудно представить ситуации, где
main-горутина координирует результаты нескольких горутин и строит более сложные
правила для продолжения или завершения дочерних горутин. Опять же, основной
посыл здесь в том, что ошибки следует рассматривать как полноценные результаты
(они такие же первостепенные, как и обычные результат) при построении значений,
возвращаемых из горутин. Если наша горутина может производить ошибки, эти ошибки
должны быть тесно связаны с нашим результирующим типом и передаваться по тем же
каналам связи — точно так же, как и в обычных синхронных функциях.
