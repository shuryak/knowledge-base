## Содержание <!-- omit in toc -->

- [Паттерны конкурентности в Go](#паттерны-конкурентности-в-go)
  - [Изоляция (Confinement)](#изоляция-confinement)
  - [Цикл for-select](#цикл-for-select)
  - [Предотвращение утечек горутин](#предотвращение-утечек-горутин)
  - [Канал с выбором (The or-channel)](#канал-с-выбором-the-or-channel)
  - [Обработка ошибок](#обработка-ошибок)
  - [Пайплайны](#пайплайны)
    - [Лучшие практики построения пайплайнов](#лучшие-практики-построения-пайплайнов)
    - [Несколько удобных генераторов](#несколько-удобных-генераторов)
  - [Разветвление и объединение (Fan-Out, Fan-In)](#разветвление-и-объединение-fan-out-fan-in)

## Паттерны конкурентности в Go

В этом разделе мы подробно рассмотрим, как компоновать примитивы конкурентности
в паттерны, чтобы сохранять систему масштабируемой и поддерживаемой.

> Во многих примерах далее будут использоваться каналы с типом `interface{}`.
> Использование пустых интерфейсов в Go — это дискуссионный момент. Однако, это
> сделано по нескольким причинам. Первая причина заключается в том, что это
> позволяет писать примеры кода проще и лаконичнее. Вторая причина — часто такое
> стиль более репрезентативен, когда речь идёт о паттерне.

### Изоляция (Confinement)

<!-- TODO: убедиться, что confinement удачно переведён, может быть "ограничение"? -->

При работе с конкурентным кодом есть несколько различных вариантов обеспечить
его безопасность:

- Примитивы синхронизации для совместного использования памяти (например,
  `sync.Mutex`)
- Синхронизация через коммуникацию (например, каналы)

Тем не менее, есть несколько других вариантов, которые неявно безопасны при
нескольких конкурентных процессов:

- Неизменяемые (immutable) данные
- Данные, защищённые изоляцией (confinement)

В некотором смысле неизменяемые данные — это идеальный вариант, поскольку они
неявно потокобезопасны. Каждый конкурентный процесс может работать с одними и
теми же данными, но он не может их изменять. Если он хочет создать новые данные,
он должен создать новую копию данных с желаемыми изменениями. Это позволяет не
только снизить когнитивную нагрузку на разработчика, но и может поспособствовать
ускорению программ, если это приводит к уменьшению размера критических секций
(или совсем их устраняет). В Go можно достичь этого, написав код, который
использует копии значений вместо указателей (pointers) на значения в памяти.
Некоторые языки поддерживают использование указателей с явно неизменяемыми
(immutable) значениями, однако, Go не входит в их число.

<!-- TODO: потокобезопасны -> безопасны для конкурентности (concurrent-safe)? (везде) -->

<!-- TODO: Некоторые языки поддерживают использование указателей с явно неизменяемым (immutable) значениями? -->

Изоляция (confinement) также может обеспечить снижение когнитивной нагрузки на
разработчика и уменьшение размера критических секций. Техники изоляции
конкурентных значений немного сложнее, чем просто передача копий значений,
поэтому здесь мы подробно рассмотрим эти техники.

Изоляция (confinement) — это простая, но мощная идея обеспечения того, чтобы
информация была доступна только из _одного_ конкурентного процесса. Когда это
достигается, конкурентная программа неявно безопасна, и синхронизация не
требуется. Существуют два вида изоляций: специальная (ad hoc) и лексическая
(lexical).

Специальная изоляция — это когда мы достигаем изоляции через соглашение
(конвенцию), неважно кем установленное — сообществом языка, командой, в которой
мы работаем, или кодовой базой, с которой мы работаем. Но придерживаться
соглашения трудно для проектов любого размера, если нет инструментов
статического анализа кода, выполняемого каждый раз, когда кто-то коммитит свой
код. Вот пример специальной изоляции, демонстрирующей, почему это так:

```go
data := make([]int, 4)

loopData := func(handleData chan<- int) {
    defer close(handleData)

    for i := range data {
        handleData <- data[i]
    }
}

handleData := make(chan int)
go loopData(handleData)

for num := range handleData {
    fmt.Println(num)
}
```

Можно видеть, что слайс целых чисел `data` доступен как из функции `loopData`,
так и из цикла, проходящего по каналу `handleData`. Однако, по соглашению мы
получаем доступ к нему только из функции `loopData`. Но код трогается многими
людьми, дедлайны поджимают, ошибки могут быть совершены, а значит, изоляция
(confinement) может быть нарушена и вызвать проблемы. Как уже упоминалось,
инструмент статического анализа может отлавливать такого рода проблемы, но
статический анализ кодовой базы Go предполагает уровень зрелости, которого
достигают не многие команды. Именно поэтому кажется предпочтительнее
использовать лексическую изоляцию: она использует компилятор для обеспечения
изоляции (confinement).

Лексическая изоляция включает в себя использование лексической области видимости
(скоупа) для предоставления только правильных данных и примитивов конкурентности
для использования несколькими конкурентными процессами. Это делает невозможным
делать что-то неправильное. На самом деле мы уже затронули это в секции
[Каналы](../building-blocks/README.md#каналы), когда обсуждали предоставление
только читательских или только писательских аспектов канала конкурентным
процессам, нуждающимся в канале. Ещё раз взглянем на этот пример
[`code-samples/confinement/channels.go`](code-samples/confinement/channels.go):

```go
chanOwner := func() <-chan int {
// Инициализируем канал в пределах лексической области (скоупа) функции
// chanOwner. Это ограничивает область действия аспекта записи в канал
// results замыканием, определённым ниже. Другими словами, это изолирует
// аспект записи канала, чтобы предотвратить запись в него другими
// горутинами
results := make(chan int, 5)

go func() {
  defer close(results)

  for i := 0; i <= 5; i++ {
    results <- i
  }
}()

return results
}

// Получаем копию int-канала только для чтения. Объявляя, что единственное
// использование, которое нам требуется, — это доступ для чтения, мы
// изолируем использование канала в функции consume только чтениями
consumer := func(results <-chan int) {
  for result := range results {
    fmt.Printf("Received: %d\n", result)
  }

  fmt.Println("Done receiving!")
}

// Получаем аспект чтения канала и можем передать его в consumer, который
// ничего не сможет делать, кроме как читать из него. Ещё раз, это изолирует
// main-горутину так, чтобы она могла только читать из канала
results := chanOwner()
consumer(results)
```

Это хороший ввод в паттерн изоляции (confinement), но, вероятно, не очень
показательный, поскольку каналы потокобезопасны. Взглянем на пример изоляции,
использующей структуру данных, которая не является потокобезопасной —
`bytes.Buffer`
([`code-samples/confinement/bytes-buffer.go`](code-samples/confinement/bytes-buffer.go)):

```go
printData := func(wg *sync.WaitGroup, data []byte) {
  defer wg.Done()

  var buff bytes.Buffer
  for _, b := range data {
    _, _ = fmt.Fprintf(&buff, "%c", b)
  }

  fmt.Println(buff.String())
}

var wg sync.WaitGroup
wg.Add(2)

data := []byte("golang")

go printData(&wg, data[:3]) // передаём слайс из первых трёх байт data
go printData(&wg, data[3:]) // передаём слайс из последних трёх байт data

wg.Wait()
```

В этом примере можно видеть, что поскольку `printData` не замкнут вокруг слайса
`data`, он не может получить доступ к нему и должен принять слайс `byte`'ов, с
которым будет работать. Мы передаём разные подмножества слайса, таким образом
ограничивая запускаемые нами горутины только той частью слайса, которую мы
передаём. Благодаря лексическому скоупу мы сделали невозможными (мы намеренно
игнорируем возможность ручного манипулирования памятью с помощью пакета
`unsafe`; он не просто так называется `unsafe`!) неправильные действия, и
поэтому нам не нужно синхронизировать доступ к памяти или делиться данными через
коммуникацию.

<!-- TODO: а что, если передать просто data? Непонятно, где здесь лексическая изоляция -->

Так в чём смысл? Зачем стремиться к изоляции (confinement), если нам доступна
синхронизация? Ответ заключается в повышении производительности и снижении
когнитивной нагрузки на разработчиков. Синхронизация сопряжена с затратами, и
если мы можем избежать этого, у нас не будет критических секций, и,
следовательно, нам не придётся «оплачивать» их синхронизацию. Мы также обходим
целый класс проблем, возможных при использовании синхронизации; разработчикам
просто не нужно беспокоиться об этих проблемах. Конкурентный код, использующий
лексическую изоляцию, также имеет преимущество в более простом понимании по
сравнению с конкурентным кодом без лексически ограниченных переменных. Это
потому, что в контексте нашего лексического скоупа мы можем писать синхронный
код.

Иногда может быть трудно установить изоляцию и поэтому иногда приходится
возвращаться к нашим замечательным примитивам конкурентности Go.

### Цикл for-select

То, что мы будем видеть снова и снова в программах на Go, — это цикл for-select.
Это не что иное, как что-то вроде этого:

```go
for { // Либо бесконечный цикл, либо перебор чего-то
  select {
    // Некоторая работа с каналами
  }
}
```

Есть несколько различных сценариев, где можно встретить этот паттерн:

- Отправка переменных итерации в канал

  Часто может захотеться преобразовать что-то, что можно проитерировать, в
  значения в канале. В этом нет ничего необычного, и обычно это выглядит
  примерно так:

  ```go
  for _, s := range []string{"a", "b", "c"} {
    select {
    case <-done:
      return
    case stringStream <- s:
    }
  }
  ```

- Бесконечный цикл, ожидающий остановки

  Очень частое явление создавать горутины, которые содержат бесконечно что-то
  делают, пока не будут остановлены. Существует пара вариантов, как это сделать.
  Выбор зависит исключительно от стилистических предпочтений.

  Первый вариант сохранят выражение `select` как можно более коротким:

  ```go
  for {
    select {
    case <-done:
      return
    default:
    }

    // Выполняем операции, которые не могут быть прерваны
  }
  ```

  Если канал `done` не закрыт, мы выйдем из инструкции `select` и перейдём к
  остальной части нашего цикла `for`.

  Второй вариант встраивает работу в выражение `default`:

  ```go
  for {
    select {
    case <-done:
      return
    default:
      // Выполняем операции, которые не могут быть прерваны
    }
  }
  ```

  Когда мы входим в `select`, если канал `done` не был закрыт, мы выполняем
  содержимое `default`.

### Предотвращение утечек горутин

В разделе [«Горутины»](../building-blocks/README.md#горутины) мы узнали, что
создавать горутины дёшево и просто; это одна из вещей, которая делает Go таким
производительным языком. Рантайм (среда выполнения) обрабатывает
мультиплексирование горутин на любое число потоков операционной системы, так что
нам не часто приходится беспокоиться об этом уровне абстракции. Однако горутины
всё равно стоят каких-то ресурсов, и при этом они не собираются сборщиком мусора
в рантайме. Поэтому, несмотря на то, сколько мало памяти они занимают, мы не
хотим оставлять их в нашем процессе. Так как же нам убедиться, что они
освободили память?

Будем размышлять шаг за шагом: зачем нужна горутина? Ранее мы установили, что
горутины представляют собой единицы работы (units of work), которые могут
выполняться либо параллельно, либо нет. Горутина имеет несколько путей для
завершения (termination):

- Когда она завершила свою работу
- Когда она не может продолжить свою работу из-за неустранимой ошибки
  (unrecoverable error)
- Когда ей сообщили прекратить работу

Первые два пути нам достаются бесплатно — эти пути являются нашим алгоритмом —
но что насчёт отмены работы (work cancellation)? Это оказывается самым важным
моментом из-за сетевого эффекта: если мы запустили горутину, вероятнее всего,
она каким-то организованным образом взаимодействует с несколькими другими
горутинами. Мы могли бы даже представить эту взаимосвязь в виде графа: вопрос о
том, должна ли дочерняя горутина продолжать выполнение, может основываться на
знании состояния многих _других_ горутин. Родительская горутина (часто
main-горутина), обладающая всеми этими контекстуальными знаниями, должна быть в
состоянии сообщить своим дочерним горутинам о том, что нужно завершить работу.
Мы продолжим рассмотрение крупномасштабной взаимозависимости горутин позже, а
пока рассмотрим, как обеспечить гарантированную очистку одной дочерней горутины.
Начнём с простого примера утечки горутины
([`code-samples/preventing-goroutine-leaks/simple-goroutine-leak.go`](code-samples/preventing-goroutine-leaks/simple-goroutine-leak.go)):

<!-- TODO: ссылка на "позже" -->

```go
doWork := func(strings <-chan string) <-chan interface{} {
  completed := make(chan interface{})

  go func() {
    defer fmt.Println("doWork exited.")
    defer close(completed)

    for s := range strings {
      // Делаем что-то интересное
      fmt.Println(s)
    }
  }()

  return completed
}

doWork(nil)

// Здесь может быть проделана ещё какая-либо работа

fmt.Println("Done.")
```

Здесь мы видим, что main-горутина передаёт `nil`-канал в `doWork`. Таким
образом, канал `strings` на самом деле никогда не получит никаких строк, и
содержащаяся в `doWork` горутина останется в памяти на всё время существования
этого процесса (мы бы даже упали в deadlock, если бы создали точку соединения
(join point) горутины внутри `doWork` с main-горутиной).

В этом примере время жизни процесса очень короткое, но в реальной программе
горутины легко могли бы быть запущены в начале долгоживущей программы. В худшем
случае main-горутина может продолжать запускать горутины на протяжении всего
срока службы, что приведёт к постоянному увеличению потребления памяти по мере
работы процесса.

Способом успешного устранения этого является установление сигнала между
родительской горутиной и её дочерними горутинами. По соглашению, этот сигнал
обычно является каналом только для чтения с именем `done`. Родительская горутина
передаёт этот канал дочерней горутине, а затем закрывает канал, когда хочет
отменить дочернюю горутину. Пример
([`code-samples/preventing-goroutine-leaks/done-channel.go`](code-samples/preventing-goroutine-leaks/done-channel.go)):

```go
// В функции doWork ожидаем канал done. По соглашению он должен быть первым
// параметром
doWork := func(done <-chan interface{}, strings <-chan string) <-chan interface{} {
  terminated := make(chan interface{})

  go func() {
    defer fmt.Println("doWork exited.")
    defer close(terminated)

    for {
      select {
      case s := <-strings:
        // Делаем что-то интересное
        fmt.Println(s)
      // Здесь мы видим повсеместно используемый паттерн for-select.
      // Одним из наших условий является проверка того, был ли сигнал
      // горутине из канала done. Если да, то мы возвращаемся из
      // горутины
      case <-done:
        return
      }
    }
  }()

  return terminated
}

done := make(chan interface{})
terminated := doWork(done, nil)

// Здесь создаём другую горутину, которая отменит горутину, созданную в
// doWork, если пройдёт более одной секунды
go func() {
  // Останавливаем операцию через 1 секунду
  time.Sleep(1 * time.Second)
  fmt.Println("Canceling doWork goroutine.")
  close(done)
}()

// Точка соединения (join point) горутины, созданной в doWork с
// main-горутиной
<-terminated

fmt.Println("Done.")
```

Результат выполнения:

```
Canceling doWork goroutine.
doWork exited.
Done.
```

Можно видеть, что, несмотря на передачу значения `nil` для нашего канала
`strings`, наша горутина по-прежнему успешно завершает работу. В отличие от
предыдущего примера, в этом примере мы соединяем (join) две горутины и, тем не
менее, не получаем взаимоблокировку (deadlock). Это связано с тем, что перед
соединением (join) двух горутин мы создаём третью горутину, чтобы отменить
горутину в `doWork` через секунду. Мы успешно устранили утечку нашей горутины!

Предыдущий пример прекрасно обрабатывает случай, когда горутина получает данные
из канала, но что если мы имеем дело с обратной ситуацией: горутина
заблокирована при попытке записать значение в канал? Вот краткий пример,
демонстрирующий проблему
([`code-samples/preventing-goroutine-leaks/producer-block.go`](code-samples/preventing-goroutine-leaks/producer-block.go)):

```go
newRandStream := func() <-chan int {
  randStream := make(chan int)

  go func() {
    // Выводим сообщение, когда горутина успешно завершается
    defer fmt.Println("newRandStream closure exited.")

    defer close(randStream)

    for {
      randStream <- rand.Int()
    }
  }()

  return randStream
}

randStream := newRandStream()

fmt.Println("3 random ints:")
for i := 0; i < 3; i++ {
  fmt.Printf("%d: %d\n", i+1, <-randStream)
}
```

Код производит примерно следующий результат:

```
3 random ints:
1: 2399527266310276677
2: 4640016047858466284
3: 5606599328692408164
```

По результату выполнения кода можно увидеть, что отложенный вызов `fmt.Println`
никогда не срабатывает. После третьей итерации нашего цикла горутина блокирует
попытку отправить следующее случайное число в канал, из которого больше не
выполняется чтение. У нас нет способа сообщить горутине-производителю, что она
может больше не пытаться слать значения в канал. Решение, как и в случае с
примером с горутиной-получателем, состоит в том, чтобы предоставить горутине
канал, информирующий её о выходе
([`code-samples/preventing-goroutine-leaks/producer-ok.go`](code-samples/preventing-goroutine-leaks/producer-ok.go)):

```go
newRandStream := func(done <-chan interface{}) <-chan int {
  randStream := make(chan int)

  go func() {
    defer fmt.Println("newRandStream closure exited.")

    defer close(randStream)

    for {
      select {
      case randStream <- rand.Int():
      case <-done:
        return
      }
    }
  }()

  return randStream
}

done := make(chan interface{})
randStream := newRandStream(done)

fmt.Println("3 random ints:")
for i := 0; i < 3; i++ {
  fmt.Printf("%d: %d\n", i+1, <-randStream)
}

close(done)

// Имитируем продолжающуюся работу
time.Sleep(1 * time.Second)
```

Этот код произведёт примерно следующее:

```
3 random ints:
1: 302978367576501321
2: 7580288934885243035
3: 6700322878534526592
newRandStream closure exited.
```

Теперь мы видим, что горутина должным образом очищена.

Теперь, когда мы знаем, как обеспечить, чтобы горутины не утекали, можно
оговорить соглашение: _если горутина отвечает за создание горутины, она также
отвечает за обеспечение того, чтобы она могла остановить горутину_.

Это соглашение помогает гарантировать, что наши программы будут компонуемые и их
будет можно масштабировать по мере их роста. Мы вернёмся к этому методу в
разделах "Pipelines" и "Пакет context". Способы, которыми мы обеспечиваем
возможность остановки горутин, могут отличаться в зависимости от типа и
назначения горутины, но все они основаны на передаче `done`-канала.

<!-- TODO: компонуемые (composable)? -->

<!-- TODO: ссылки и норм перевод разделов "Pipelines" и "Пакет context" -->

### Канал с выбором (The or-channel)

Иногда хочется объединить один или несколько `done`-каналов в один `done`-канал,
который будет закрываться, если любой из его составляющих каналов закрывается.
Вполне приемлемо, хотя и довольно многословно, написать оператор `select`,
который выполняет это связывание каналов; однако, иногда мы не можем знать
количество `done`-каналов, с которыми рантайму (среде выполнения) придётся
работать. В таком случае, или если мы просто предпочитаем однострочный вариант,
мы можем объединить эти каналы вместе, используя паттерн _канал с выбором_
(_or-channel_).

Этот паттерн создаёт составной `done`-канал через рекурсию и горутины. Посмотрим
на пример
([`code-samples/or-channel/or-channel.go`](code-samples/or-channel/or-channel.go)):

```go
// Наша функция or, которая принимает произвольный слайс каналов и возвращает
// одиночный канал
func or(channels ...<-chan interface{}) <-chan interface{} {
  switch len(channels) {
  // Поскольку это рекурсивная функция, мы должны задать базовый случай.
  // В первом случае, если произвольный слайс пустой, мы просто вернём
  // nil-канал. Это консистентно с общим ожидаемым поведением функции:
  // в случае, когда мы не передали ни один канал, мы не ожидаем, что
  // составной канал что-то будет делать
  case 0:
    return nil
  // Второй базовый случай: если произвольный слайс состоит только из одного
  // элемента, мы просто вернём этот же элемент
  case 1:
    return channels[0]
  }

  orDone := make(chan interface{})

  // Основное тело функции, где происходит рекурсия. Мы создаём горутину,
  // чтобы мы могли ожидать сообщения на наших каналах без блокировки
  go func() {
    defer close(orDone)

    switch len(channels) {
    // Из-за того, как мы выполняем рекурсию, каждый рекурсивный вызов or
    // будет иметь, по крайней мере, два канала. В качестве оптимизации,
    // чтобы ограничить количество создаваемых горутин, мы помещаем здесь
    // особый случай для вызовов or только с двумя каналами
    case 2:
      select {
      case <-channels[0]:
      case <-channels[1]:
      }
    // Здесь мы рекурсивно создаём or-канал из всех каналов из нашего
    // слайса, начиная с индекса 3, а затем выполняем select по ним. Это
    // рекуррентное соотношение деструктурирует остальную часть среза на
    // or-каналы, чтобы сформировать дерево, из которого вернётся первый
    // сигнал. Мы также передаём канал orDone, чтобы когда горутины вверху
    // дерева завершатся, горутины внизу также завершились.
    default:
      select {
      case <-channels[0]:
      case <-channels[1]:
      case <-channels[2]:
      case <-or(append(channels[3:], orDone)...):
      }
    }
  }()

  return orDone
}
```

<!-- TODO: добавить какую-то иллюстрацию, изобразить дерево рекурсии, например -->

Это довольно простая функция, которая позволяет объединить любое количество
каналов в один канал, который закроется, как только любой из его составляющих
каналов будет закрыт или в него будет записана информация. Посмотрим, как мы
можем использовать эту функцию. Краткий пример, в котором используются каналы,
закрывающиеся по истечении заданного времени, и используется функция `or` для
объединения их в один канал, который закрывается
([`code-samples/or-channel/or-channel-usage.go`](code-samples/or-channel/or-channel-usage.go)):

> Чтобы запустить этот код, можно воспользоваться командой
> `go run or-channel/*.go`.

```go
// Эта функция просто создаёт канал, который закрывается по прошествии
// времени, указанного в after
sig := func(after time.Duration) <-chan interface{} {
  c := make(chan interface{})

  go func() {
    defer close(c)
    time.Sleep(after)
  }()

  return c
}

// Здесь мы запоминаем приблизительное время, когда канал из функции or
// начинает блокировать main-горутину
start := time.Now()

<-or(
  sig(2*time.Hour),
  sig(5*time.Minute),
  sig(1*time.Second),
  sig(1*time.Hour),
  sig(1*time.Minute),
)

// Выводим время, которое потребовалось для выполнения считывания из канала,
// возвращённого функцией or
fmt.Printf("done after %v\n", time.Since(start))
```

<!-- TODO: на этом моменте я понял, что не форматировал комментарии в коде в
MD-файле, чтобы они оптимально вписывались в editor.rules -->

Если мы запустим эту программу, получим примерно такой результат:

```
done after 1.001202334s
```

Следует обратить внимание, что, несмотря на размещение нескольких каналов при
вызове нашей функции `or`, закрытие которых занимает разное время, канал,
закрывающийся через одну секунду, приводит к закрытию всего результирующего
канала, созданного вызовом `or`. Это происходит потому, что, несмотря на своё
место в дереве, которое строит функция `or`, он всегда будет закрываться первым,
и, таким образом, каналы, зависящие от его закрытия, также закроются.

Мы достигаем этой лаконичности за счёт создания дополнительных горутин —
$f\left(x\right) = \left\lfloor \dfrac{x}{2} \right\rfloor$
([округление к меньшему](https://ru.wikipedia.org/wiki/Целая_часть)), где $x$ —
это количество каналов, — но следует помнить, что одной из сильных сторон Go
является способность быстро создавать, планировать и запускать горутины, и язык
активно поощряет использование горутин для моделирования проблем (задач)
правильно. Беспокойство о количестве создаваемых здесь горутинах, вероятно,
является преждевременной оптимизацией. Опять же, если во время компиляции мы не
знаем, со сколькими `done`-каналами мы работаем, другого способа объединить
`done`-каналы нет.

<!-- TODO: убедиться, что я правильно исправил ошибку x - число -горутин- -> каналов -->

Этот паттерн полезно использовать на пересечении модулей в нашей системе. В этих
местах обычно возникает несколько условий для отмены деревьев горутин по стеку
вызовов. Используя функцию `or` мы можем просто объединить их вместе и передать
вниз по стеку. Мы также рассмотрим другой способ сделать это в разделе "Пакет
context", что тоже является хорошим способом, и, возможно, более описательным.

<!-- TODO: норм ссылка и название раздела "пакет context" -->

Мы также рассмотрим, как мы можем использовать вариацию этого паттерна для
формирования более сложного паттерна в разделе "Replicated Requests".

<!-- TODO: норм ссылка и название раздела "replicated requests" -->

### Обработка ошибок

В конкурентных программах бывает сложно правильно организовать обработку ошибок.
Иногда мы тратим так много времени на размышления о том, как наши различные
процессы будут обмениваться информацией и координироваться, что забываем
подумать о том, как изящно (gracefully) они будут обрабатывать ошибочные
состояния. Когда Go отказался от популярной модели представления ошибок в виде
исключений (exceptions), он как бы сделал заявление, что обработка ошибок важна,
и что при разработке наших программ мы должны уделять путям возникновения ошибок
такое же внимание, какое уделяем нашим алгоритмам. В этом же духе давайте
взглянем на том, как мы это делаем с несколькими конкурентными процессами.

Самый фундаментальный вопрос, который возникает при обработке ошибок, — «Кто
ответственен за обработку ошибки?». В какой-то момент программе всё же
необходимо прекратить передачу ошибки по стеку и действительно что-то с ней
сделать. Кто за это отвечает?

С конкурентными процессами, этот вопрос становится немного более комплексным.
Поскольку конкурентный процесс работает независимо от своего родителя или других
дочерних элементов родителя, ему может быть сложно принять решение о том, как
правильно поступить с ошибкой. Взглянем на этот код для понимания этой проблемы
([`code-samples/error-handling/issue.go`](code-samples/error-handling/issue.go)):

```go
checkStatus := func(done <-chan interface{}, urls ...string) <-chan *http.Response {
  responses := make(chan *http.Response)

  go func() {
    defer close(responses)

    for _, url := range urls {
      resp, err := http.Get(url)
      if err != nil {
        // Здесь мы видим, что горутина делает всё возможное, чтобы
        // сигнализировать о наличии ошибки. Что ещё она может сделать? Она не
        // может передать эту ошибку обратно. Сколько ошибок считать слишком
        // большим количеством? Продолжает ли она после сигнала об ошибке
        // отправлять запросы?
        fmt.Println(err)
        continue
      }

      select {
      case <-done:
        return
      case responses <- resp:
      }
    }
  }()

  return responses
}

done := make(chan interface{})
defer close(done)

urls := []string{"https://google.com", "https://badhost"}
for response := range checkStatus(done, urls...) {
  fmt.Printf("Response: %v\n", response.Status)
}
```

Этот код произведёт следующее:

```
Response: 200 OK
Get "https://badhost": dial tcp: lookup badhost: no such host
```

Здесь мы видим, что у горутины не было выбора в этом вопросе. Она не может
просто «проглотить» эту ошибку, и поэтому она делает единственную разумную вещь:
печатает эту ошибку и надеется, что кто-то обратит внимание. Не нужно ставить
свои горутины в такое неловкое положение. Можно руководствоваться следующим: в
общем, нашим конкурентным процессам следует отправлять ошибки в другую часть
нашей программы, которая обладает полной информацией о состоянии нашей программы
и может принять более обоснованное решение о том, что делать. Следующий пример
демонстрирует правильное решение этой проблемы
([`code-samples/error-handling/example.go`](code-samples/error-handling/example.go)):

```go
// Создаём тип, который включает в себя как *http.Response, так и ошибку,
// возможную в цикле нашей горутины
type Result struct {
  Error    error
  Response *http.Response
}

// Эта функция возвращает канал, из которого можно считывать результаты
// итераций нашего цикла
checkStatus := func(done <-chan interface{}, urls ...string) <-chan Result {
  results := make(chan Result)

  go func() {
    defer close(results)

    for _, url := range urls {
      resp, err := http.Get(url)

      // Создаём инстанс Result с необходимым набором полей
      result := Result{
        Error:    err,
        Response: resp,
      }

      select {
      case <-done:
        return
      // Пишем result в канал
      case results <- result:
      }
    }
  }()

  return results
}

done := make(chan interface{})
defer close(done)

urls := []string{"https://google.com", "https://badhost"}
for result := range checkStatus(done, urls...) {
  // Здесь, в нашей main-горутине, мы можем разумнее обрабатывать ошибки,
  // возникающие в горутине, запущенной из checkStatus, и в рамках более
  // обширного контекста
  if result.Error != nil {
    fmt.Printf("error: %v\n", result.Error)
    continue
  }

  fmt.Printf("Response: %v\n", result.Response.Status)
}
```

Этот код произведёт следующее:

```
Response: 200 OK
error: Get "https://badhost": dial tcp: lookup badhost: no such host
```

Ключевой момент, на который следует обратить внимание, — это то, как мы связали
потенциальный результат с потенциальной ошибкой. Это представляет собой полный
набор возможных результатов, созданных горутиной из `checkStatus`, и позволяет
нашей main-горутине принимать решение о том, что делать в случае ошибки. В более
широком смысле, мы успешно отделили задачи обработки ошибок от нашей
горутины-производителя. Так делать желательно потому, что горутина, которая
создала горутину-производителя — в данном случае так сделала main-горутина —
имеет больше информации о запущенной горутине и может принимать более разумные
решения о том, что делать с ошибками.

В предыдущем примере мы просто записывали ошибки в `stdout`, но мы могли бы
сделать кое-что ещё. Давайте изменим нашу программу так, чтобы она перестала
проверять статус при возникновении трёх или более ошибок
([`code-samples/error-handling/example-2.go`](code-samples/error-handling/example-2.go)):

```go
done := make(chan interface{})
defer close(done)

errCount := 0

urls := []string{"a", "https://google.com", "b", "c", "d"}
for result := range checkStatus(done, urls...) {
  if result.Error != nil {
    fmt.Printf("error: %v\n", result.Error)

    errCount++

    if errCount >= 3 {
      fmt.Println("Too many errors, breaking!")
      break
    }

    continue
  }

  fmt.Printf("Response: %v\n", result.Response.Status)
}
```

Результат выполнения этого кода:

```
error: Get "a": unsupported protocol scheme ""
Response: 200 OK
error: Get "b": unsupported protocol scheme ""
error: Get "c": unsupported protocol scheme ""
Too many errors, breaking!
```

Можно видеть, что, поскольку ошибки возвращаются из `checkStatus` и не
обрабатываются внутри горутины, обработка ошибок выполняется по присущему Go
паттерну. Это лишь простой пример, но нетрудно представить ситуации, где
main-горутина координирует результаты нескольких горутин и строит более сложные
правила для продолжения или завершения дочерних горутин. Опять же, основной
посыл здесь в том, что ошибки следует рассматривать как полноценные результаты
(они такие же первостепенные, как и обычные результат) при построении значений,
возвращаемых из горутин. Если наша горутина может производить ошибки, эти ошибки
должны быть тесно связаны с нашим результирующим типом и передаваться по тем же
каналам связи — точно так же, как и в обычных синхронных функциях.

### Пайплайны

Когда мы разрабатываем программу, как правило, мы не сидим и не пишем одну
единственную длинную функцию. Обычно мы строим абстракции в виде функций,
структур, методов и т.д. Почему мы делаем это? Отчасти потому, что хотим
абстрагироваться от деталей, которые не имеют значения в контексте общей задачи,
а отчасти потому, что хотим работать над одной областью кода, не затрагивая
(without affecting) другие области. Вероятно, каждый сталкивался с ситуацией,
когда чтобы внести одно логическое изменение, необходимо затронуть множество
областей кода. Скорее всего, так происходило потому, что система страдает от
скудности абстракции.

_Пайплайн_ — это просто ещё один инструмент, который может использоваться для
формирования абстракции в нашей системе. В частности, это очень мощный
инструмент, используемый, когда нашей программе необходимо обрабатывать потоки
или пачки данных. Считается, что слово "pipeline" («трубопровод», пайплайн)
впервые было использовано в 1856 году и, вероятно, относилось к линии труб, по
которым жидкость транспортировалась из одного места в другое. Мы заимствуем это
слово для Computer Science, потому что мы также транспортируем что-то из одного
места в другое. Пайплайн ни что иное, как серия вещей, которые принимают данные,
выполняют операции над ними и передают данные обратно. Мы называем каждую из
таких операций _этапом_ (_stage_) пайплайна.

Используя пайплайн, мы разделяем задачи каждого этапа, чтобы обеспечивает ряд
преимуществ. Мы можем изменять этапы независимо друг от друга, можем смешивать и
сопоставлять (to match) то, как этапы составлены, независимо от изменения
этапов. Мы можем обрабатывать каждый этап конкурентно с восходящими (upstream) и
нисходящими (downstream) этапами, _разветвлять_ (_fan-out_) или _ограничивать
скорость_ (_rate-limit_, рейт-лимиты) отдельных участков нашего пайплайна. Мы
рассмотрим разветвление (fan-out) в разделе "Fan-Out, Fan-In", а рейт-лимиты — в
Главе 5. Сейчас не нужно беспокоиться о том, что означают эти термины; начнём с
простого и попробуем построить этап пайплайна.

<!-- TODO: норм перевод и ссылки на Fan-Out и рейт-лимиты. Главы 5 не будет, вместо этого ссылка ну нужный участок -->

Как говорилось ранее, этап — это просто что-то, что принимает данные, производит
трансформации над этими данными и отправляет эти данные обратно. Пример функции,
которую можно было бы рассматривать как этап пайплайна:

```go
multiply := func(values []int, factor int) []int {
  multipliedValues := make([]int, len(values))

  for i, v := range values {
    multipliedValues[i] = v * factor
  }

  return multipliedValues
}
```

Эта функция принимает слайс целых чисел и множителем, в цикле проходится по
слайсу и умножает каждый его элемент на `factor`, а затем возвращает новый
трансформированный слайс наружу.

И ещё одна скучная функция, которая создаёт новый слайс и добавляет к каждому
его элементу `additive`:

```go
add := func(values []int, additive int) []int {
  addedValues := make([]int, len(values))

  for i, v := range values {
    addedValues[i] = v + additive
  }

  return addedValues
}
```

На данный момент, непонятно, что делает эти две функции этапами пайплайна, а не
просто функциями. Попробуем скомбинировать их
([`code-samples/pipelines/combined-funcs.go`](code-samples/pipelines/combined-funcs.go)):

```go
ints := []int{1, 2, 3, 4}

for _, v := range add(multiply(ints, 2), 1) {
  fmt.Println(v)
}
```

Этот код производит:

```
3
5
7
9
```

Следует обратить внимание на то, как мы комбинируем функции `add` и `multiply` в
`range`. Это совершенно обычные функции, но мы их сконструировали так, чтобы они
обладали свойствами этапов пайплайна: мы можем объединить их и составить
пайплайн. Интересно, а какие свойства есть у этапа пайплайна?

- Этап принимает и возвращает один и тот же тип.
- Этап должен быть _овеществлён_ языком, чтобы его можно было передавать по
  кругу. Функции в Go являются овеществлёнными и отлично подходят для этой цели.

> В контексте языков, _овеществление_ (reification, реификация) означает, что
> язык предоставляет разработчикам концепцию, чтобы они могли работать с ней
> напрямую. Функции в Go можно назвать овеществленными, так мы можем определять
> переменные, которые имеют тип сигнатуры функции. Это также означат, что мы
> можем передавать функции по всей нашей программе.

Если вы знакомы с функциональным программированием, то, возможно, узнали здесь
что-то вроде функций высшего порядка и монад. Действительно, этапы пайплайна
очень тесно связаны с функциональным программированием и могут рассматриваться
как подмножество монад.

<!-- Похоже ли это на функции высшего порядка и на монады? -->

Наши этапы `multiply` и `add` удовлетворяют всех свойствам этапов пайплайна: они
оба принимают слайс из `int`'ов и возвращают слайс из `int`'ов, и, поскольку в
Go есть овеществлённые функции, мы можем передавать `add` и `multiply` по кругу.
Эти свойства этапов приводят к интересным свойствам пайплайна, о которых мы
упоминали ранее: этапы становится очень легко комбинировать на более высоком
уровне без изменения самих этапов.

Например, если мы хотим добавить дополнительный этап, умножающий всё на 2, в наш
пайплайн, нам нужно просто обернуть предыдущий пайплайн в новый `multiply`-этап,
примерно вот так
([`code-samples/pipelines/new-stage.go`](code-samples/pipelines/new-stage.go)):

```go
ints := []int{1, 2, 3, 4}

for _, v := range multiply(add(multiply(ints, 2), 1), 2) {
  fmt.Println(v)
}
```

Выполнив этот код, мы получим:

```
6
10
14
18
```

Следует обратить внимание, что мы сделали это без написания новой функции,
модифицирования существующей или модифицирования того, что мы делаем с
результатом нашего пайплайна. Конечно, мы могли бы написать этот код в
процедурном стиле:

```go
ints := []int{1, 2, 3, 4}

for _, v := range ints {
  fmt.Println(2*(v*2+1))
}
```

На первый взгляд это кажется намного проще, но, как мы увидим по ходу дела,
процедурный код не обеспечивает тех преимуществ, которые предоставляет пайплайн
при работе с потоками данных.

Также обратите внимание, как каждый этап берёт _слайс_ данных и возвращает
_слайс_ данных. Эти этапы выполняют то, что называем _пакетной обработкой_
(_batch processing_). Это просто означает, что они оперируют чанками (кусками)
данных одновременно, а не одним дискретным значением за раз. Существует другой
тип этапов контейнера, который подразумевает выполнение _потоковую обработку_
(_stream processing_). Это означает, что этап принимает и выпускает по одному
элементу за раз.

У пакетной обработки есть свои плюсы и минусы относительно потоковой обработки,
которые мы обсудим чуть позже. А пока следует обратить внимание, что для того,
чтобы исходные данные оставались неизменными, на каждом этапе необходимо
создавать новый слайс равной длины для хранения результатов своих вычислений.
Это означает, что объём памяти, что объём памяти, занимаемой нашей программой, в
любой момент в два раза превышает размер слайса, который мы отправляем в начало
нашего пайплайна. Преобразуем наши этапы в поточные (потоковая обработка) и
посмотрим, как это выглядит
([`code-samples/pipelines/stream-oriented-stages.go`](code-samples/pipelines/stream-oriented-stages.go)):

```go
multiply := func(value, factor int) int {
  return value * factor
}

add := func(value, additive int) int {
  return value + additive
}

ints := []int{1, 2, 3, 4}

for _, v := range ints {
  fmt.Println(multiply(add(multiply(v, 2), 1), 2))
}
```

Этот код производит:

```
6
10
14
18
```

Каждый этап принимает и выпускает дискретное значение, и объём памяти нашей
программы снова сократился только до размера входных данных пайплайна. Но нам
пришлось перенести пайплайн в тело цикла `for` и заставить `range` выполнять
работу по заполнению нашего пайплайна. Это не только ограничивает повторное
использование того, как мы заполняем пайплайн, но и, как мы увидим позже, также
ограничивает нашу способность к масштабированию. По сути, мы создаём инстанс
нашего пайплайна для каждой итерации цикла. Хотя вызовы функций дешёвая
операция, мы выполняем по три вызова функций для каждой итерации цикла. А что
насчёт конкурентности, Ранее было сказано, что одним из преимуществ
использования пайплайнов является возможность одновременной обработки отдельных
этапов, и было упомянуто кое-что о разветвлении. Откуда всё это берётся?

#### Лучшие практики построения пайплайнов

Каналы уникально подходят для построения пайплайнов, поскольку они удовлетворяют
всем нашим основным требованиям. Они могут принимать и выпускать значения, их
можно потокобезопасно использовать, по ним можно пробегаться в цикле, и они
овеществлены языком. Преобразуем предыдущий пример, чтобы он работал с каналами
([`code-samples/pipelines/pipeline-on-channels.go`](code-samples/pipelines/pipeline-on-channels.go)):

```go
generator := func(done <-chan interface{}, integers ...int) <-chan int {
  intStream := make(chan int)

  go func() {
    defer close(intStream)

    for _, i := range integers {
      select {
      case <-done:
        return
      case intStream <- i:
      }
    }
  }()

  return intStream
}

multiply := func(
  done <-chan interface{},
  intStream <-chan int,
  factor int,
) <-chan int {
  multipliedStream := make(chan int)

  go func() {
    defer close(multipliedStream)

    for i := range intStream {
      select {
      case <-done:
        return
      case multipliedStream <- i * factor:
      }
    }
  }()

  return multipliedStream
}

add := func(
  done <-chan interface{},
  intStream <-chan int,
  additive int
) <-chan int {
  addedStream := make(chan int)

  go func() {
    defer close(addedStream)

    for i := range intStream {
      select {
      case <-done:
        return
      case addedStream <- i + additive:
      }
    }
  }()

  return addedStream
}

done := make(chan interface{})
defer close(done)

intStream := generator(done, 1, 2, 3, 4)
pipeline := multiply(done, add(done, multiply(done, intStream, 2), 1), 2)

for v := range pipeline {
  fmt.Println(v)
}
```

Этот код производит:

```
6
10
14
18
```

Похоже, мы просто воспроизвели желаемый результат, но за счёт использования
гораздо большего количества кода. В чём мы выиграли? Посмотрим на то, что мы
написали. Теперь у нас есть три функции вместо двух. Все они выглядят похоже —
запускают одну горутину внутри своего тела и используют паттерн рассмотренный в
разделе [«Предотвращение утечек горутин»](#предотвращение-утечек-горутин),
который подразумевает принятие канала, который может просигнализировать о том,
что горутина должна завершиться. Также все они возвращают каналы, а некоторые из
них при этом принимают дополнительный канал. Начнём разбирать этот код далее:

<!-- TODO: ставим ли кавычки для разделов? -->

```go
done := make(chan interface{})
defer close(done)
```

Первое, что наша программа делает — создаёт `done`-канал и через `defer`
откладывает вызов `close` для этого канала. Как и обсуждалось ранее, это
гарантирует то, что наша программа завершит работу чисто и никогда не произойдёт
утечки горутин. Здесь нет ничего нового. Теперь посмотрим на функцию
`generator`:

```go
generator := func(done <-chan interface{}, integers ...int) <-chan int {
  intStream := make(chan int)

  go func() {
    defer close(intStream)

    for _, i := range integers {
      select {
      case <-done:
        return
      case intStream <- i:
      }
    }
  }()

  return intStream
}

// ...

intStream := generator(done, 1, 2, 3, 4)
```

Функция `generator` принимает произвольный слайс целых чисел, собирает
буферизированный канал из целых чисел длины, равной длине входящего слайса,
запускает горутину и возвращает собранный канал. В созданной и запущенной здесь
горутине функция `generator` пробегает по всему произвольному слайсу, который мы
передали в функцию `generator` и отправляет элементы слайса в канал, который мы
создали.

Следует обратить внимание на то, что отправка в канал разделяет оператор
`select` с выбором на канале `done`. Опять же, это паттерн, который мы
рассмотрели в разделе
[«Предотвращение утечек горутин»](#предотвращение-утечек-горутин).

Итак, в двух словах, функция `generator` преобразует дискретный набор значений в
поток данных на канале. Как раз-таки такой тип функций называется _генератором_.
При работе с пайплайнами мы часто будем сталкиваться с тем, что в начале
пайплайна будет некоторый пакет данных (batch of data), который нужно
преобразовать в канал. Закончим разбор этой программы — наконец, мы строим
пайплайн:

```go
pipeline := multiply(done, add(done, multiply(done, intStream, 2), 1), 2)
```

Это такой же пайплайн, с которым мы работали всё это время: некоторый поток
чисел мы умножаем на 2, добавляем единицу, а затем результат умножаем на 2. Этот
пайплайн аналогичен предыдущему нашему пайплайну, использующему функции, из
предыдущего примера, но он отличается очень важными аспектами.

Первое — мы используем каналы. Это очевидно, но важно, потому что это позволяет
сделать две вещи: в конце нашего пайплайна мы можем использовать выражение
`range` для извлечения значений, и на каждом этапе мы можем безопасно выполнять
его конкурентно, потому что его входы и выходы безопасны в контексте
конкурентности.

Это подводит нас ко второму отличию: каждый этап пайплайна выполняется
конкурентно. Это означает, что любому этапу нужно только дождаться своих входных
данных и иметь возможность отправить свои выходные данные. Оказывается, это
имеет серьёзные последствия, которые мы обсудим в разделе "Fan-Out, Fan-In", но
пока можно просто отметить, что это позволяет нашим этапам выполняться
независимо друг от друга в течение некоторого промежутка времени.

<!-- TODO: ссылка и норм перевод "Fan-Out, Fan-In -->

И в конце нашего примера мы проходим по всему этому пайплайну и извлекаем
значения из всей этой системы:

```go
for v := range pipeline {
  fmt.Println(v)
}
```

Это таблица, демонстрирующая, как каждое из значений в системе будет попадать в
каждый канал, и когда каналы окажутся закрытыми. Номер итерации — это счётчик,
который начинается с нули и отражает номер текущей итерации цикла `for`, а число
в каждом столбце — это значение в том виде, в каком оно приходит на этап
пайплайна:

| Номер итерации | `generator` | `multiply` | `add`    | `multiply` | Результат |
| -------------- | ----------- | ---------- | -------- | ---------- | --------- |
| 0              | 1           |            |          |            |           |
| 0              |             | 1          |          |            |           |
| 0              | 2           |            | 2        |            |           |
| 0              |             | 2          |          | 3          |           |
| 0              | 3           |            | 4        |            | 6         |
| 1              |             | 3          |          | 5          |           |
| 1              | 4           |            | 6        |            | 10        |
| 2              | (закрыт)    | 4          |          | 7          |           |
| 2              |             | (закрыт)   | 8        |            | 14        |
| 3              |             |            | (закрыт) | 9          |           |
| 3              |             |            |          | (закрыт)   | 18        |

Давайте также более внимательно рассмотрим использование паттерна для подачи
горутинам сигнала о завершении. Когда мы имеем дело с несколькими
взаимозависимыми горутинами, как этот паттерн работает? Что произойдёт, если мы
вызовем `close` на канале `done` до завершения выполнения программы?

Чтобы ответить на эти вопросы, ещё раз взглянем на конструкцию нашего пайплайна:

```go
pipeline := multiply(done, add(done, multiply(done, intStream, 2), 1), 2)
```

Этапы связаны между собой двумя связями: общим каналом `done` и каналами,
которые передаются в последующие этапы пайплайна. Другими словами, канал,
созданный функцией `multiply`, передаётся в функцию `add` и т.д. Вернёмся к
предыдущей таблице и, прежде чем позволить циклу завершиться, вызовем `close` на
канале `done` и посмотрим, что произойдёт:

| Номер итерации | `generator` | `multiply` | `add`    | `multiply` | Результат        |
| -------------- | ----------- | ---------- | -------- | ---------- | ---------------- |
| 0              | 1           |            |          |            |                  |
| 0              |             | 1          |          |            |                  |
| 0              | 2           |            | 2        |            |                  |
| 0              |             | 2          |          | 3          |                  |
| 1              | 3           |            | 4        |            | 6                |
| `close(done)`  | (закрыт)    | 3          |          | 5          |                  |
|                |             | (закрыт)   | 6        |            |                  |
|                |             |            | (закрыт) | 7          |                  |
|                |             |            |          | (закрыт)   |                  |
|                |             |            |          |            | (выход из цикла) |

Видно, как закрытие канала `done` каскадно проходит по пайплайну. Это становится
возможным благодаря двум вещам на каждом этапе пайплайна:

- Перебор по входящему каналу. Когда входящий канал закрыт, перебор завершится.
- Отправка в канал разделяем одно `select`-выражение с каналом `done`.

Независимо от того, в каком состоянии находится этап пайплайна — в состоянии
ожидания на входящем канале или ожидания отправки — закрытие канала `done`
приведёт к принудительному завершению этапа пайплайна.

Здесь имеет место рекуррентное соотношение. В начале пайплайна мы установили,
что должны преобразовать дискретные значения в канал. В этом процессе есть два
момента, которые должны быть прерываемыми:

- Создание дискретного значения, которое не является мгновенным.
- Отправка дискретного значения по его каналу.

Первое зависит от нас. В нашем примере, в функции `generator`, дискретные
значения генерируются путём перебора по произвольному слайсу, который происходит
достаточно мгновенно и не требует прерывания. Второй пункт обрабатывается нашим
оператором `select` и каналом `done`, который гарантирует, что функция
`generator` может быть прервана, даже если она заблокирована при попытке записи
в `intStream`.

На другом конце пайплайна, конечный этап обеспечивается прерываемостью по
индукции. Он прерываем потому, что канал, по которому мы перебираем значения,
будет закрыт при прерывании, и, следовательно, наш перебор завершится, когда это
произойдёт. Конечный этап прерываем потому, что поток, от которого мы зависим,
является прерываемым.

Между началом и концом пайплайна код всегда перебирает канал и отправляет данные
по другому каналу в операторе `select`, этот оператор также содержит канал
`done`

Если этап заблокирован на получении значения из входного канала, он
разблокируется, когда этот канал будет закрыт. Мы знаем по индукции, что канал
будет закрыт потому, что это либо этап, написанный так же, как этот этап, внутри
которого мы находимся, либо начало пайплайна, который мы определили как
прерываемый. Если этап заблокирован на отправке значения, он прерываем благодаря
оператору `select`.

<!-- TODO: в этом абзаце в целом норм индукционная мысль, но "так же, как этот этап" вот здесь нужно уточнить или перефразировать -->

<!-- TODO: в целом вообще самому разобраться с этими индукционными размышлениями и что-то мб перефразировать -->

Таким образом, весь наш пайплайн всегда можно прервать закрытием канала `done`.
Круто!

#### Несколько удобных генераторов

Напомним, что генератор для пайплайна — это любая функция, которая преобразует
набор дискретных значений в поток значений на канале.

Взглянем на генератор под названием `repeat`:

```go
repeat := func(
  done <-chan interface{},
  values ...interface{}
) <-chan interface{} {
  valueStream := make(chan interface{})

  go func() {
    defer close(valueStream)

    for {
      for _, v := range values {
        select {
        case <-done:
          return
        case valueStream <- v:
        }
      }
    }
  }()

  return valueStream
}
```

Эта функция будет бесконечно повторять значения, которые мы ей передадим, пока
мы не скажем ей остановиться.

Рассмотрим другой общий этап пайплайна, который полезен при использовании в
сочетании с `repeat`, `take`:

```go
take := func(
  done <-chan interface{},
  valueStream <-chan interface{},
  num int,
) <-chan interface{} {
  takeStream := make(chan interface{})

  go func() {
    defer close(takeStream)

    for i := 0; i < num; i++ {
      select {
      case <-done:
        return
      case takeStream <- <-valueStream:
      }
    }
  }()

  return takeStream
}
```

Этот этап пайплайна будет извлекать только первые `num` элементов из входящего
канала `valueStream`, а затем завершать работу. Вместе они могут быть очень
мощными
([`code-samples/pipelines/generators/repeat-take.go`](code-samples/pipelines/generators/repeat-take.go)):

```go
done := make(chan interface{})
defer close(done)

for num := range take(done, repeat(done, 1), 10) {
  fmt.Printf("%d ", num)
}

fmt.Println()
```

Этот код произведёт:

```
1 1 1 1 1 1 1 1 1 1
```

В этом простом примере мы создаём `repeat`-генератор для генерации бесконечного
числа единиц, но затем берём только первые 10. Поскольку отправка значения в
`repeat`-генераторе блокирует получение на этапе `take`, `repeat`-генератор
очень эффективен. Хотя у нас есть возможность генерировать бесконечный поток
единиц, мы генерируем только $n + 1$ экземпляров, где $n$ — это число, которое
мы передаём на этап `take`.

Мы можем рассмотреть это подробнее. Создадим ещё один повторяющий генератор, но
на этот раз создадим такой, который повторно вызывает функцию. Назовём его
`repeatFn`
([`code-samples/pipelines/generators/repeat-fn.go`](code-samples/pipelines/generators/repeat-fn.go)):

```go
repeatFn := func(
  done <-chan interface{},
  fn func() interface{},
) <-chan interface{} {
  valueStream := make(chan interface{})

  go func() {
    defer close(valueStream)

    for {
      select {
      case <-done:
      return
      case valueStream <- fn():
      }
    }
  }()

  return valueStream
}
```

Используем этот генератор, чтобы сгенерировать 10 рандомных чисел:

```go
done := make(chan interface{})
defer close(done)

randFn := func() interface{} {
  return rand.Int()
}

for num := range take(done, repeatFn(done, randFn), 10) {
  fmt.Println(num)
}
```

Это произведёт что-то подобное:

```
5305141208658601736
6195187010991777015
6972756325307550674
8126717018566956418
5928375856424083536
8295798667179806995
492683986493178383
1807155695000307597
4986426348547186334
2220004159319114895
```

Отлично! Бесконечный канал рандомных чисел, генерируемых по необходимости!

> Мы могли бы с таким же успехом написать эти функции без использования
> `interface{}` и использовать явно заданный тип или даже придумать
> кодогенерацию для таких случаев.

Пустые интерфейсы немного табуированы в Go, но для этапов пайплайна кажется
нормальным работать с каналами типа `interface{}`, чтобы можно было использовать
стандартную библиотеку паттернов пайплайнов. Как мы обсуждали ранее, больша́я
часть полезности пайплайна исходит от повторно используемых этапов. Это лучше
всего достигается, когда этапы работают на уровне специфичности, соответствующем
самим себе. В генераторах `repeat` и `repeatFn` задача заключается в генерации
потока данных путём циклического перебора списка или оператора. На этапе `take`
задача заключается в ограничении (лимитировании) нашего пайплайна. Ни одна из
этих операций не требует информации о типах, с которыми она работает, а вместо
этого требует только знания [арности](https://ru.wikipedia.org/wiki/Арность) её
параметров.

Когда нужно иметь дело со специфичными типами, можно поместить в пайплайн этап,
который выполняет [type assertion](https://go.dev/tour/methods/15) за нас.
Накладные расходы (performance overhead), связанные с наличием дополнительного
этапа пайплайна (и, следовательно, горутины) и type assertion'а, как мы увидим
чуть позже, незначительны. Вот небольшой пример, который вводит этап пайплайна
`toString`
([`code-samples/pipelines/generators/to-string-stage.go`](code-samples/pipelines/generators/to-string-stage.go)):

```go
toString := func(
  done <-chan interface{},
  valueStream <-chan interface{},
) <-chan string {
  stringStream := make(chan string)

  go func() {
    defer close(stringStream)

    for v := range valueStream {
      select {
      case <-done:
        return
      case stringStream <- v.(string):
      }
    }
  }()

  return stringStream
}
```

И пример, как использовать этот этап:

```go
done := make(chan interface{})
defer close(done)

msg := ""
for token := range toString(done, take(done, repeat(done, "I", "am."), 5)) {
  msg += token
}

fmt.Printf("message: %s...\n", msg)
```

Этот код произведёт:

```
message: Iam.Iam.I...
```

Итак, давайте докажем самим себе, что затраты на генерирование частей нашего
пайплайна незначительны. Мы напишем две бенчмарк-функции: одну для тестирования
общих этапов, а вторую — для тестирования специфичных для типа этапов
([`code-samples/pipelines/generators/benchmark/pipelines_test.go`](code-samples/pipelines/generators/benchmark/pipelines_test.go)):

```go
func BenchmarkGeneric(b *testing.B) {
  done := make(chan interface{})
  defer close(done)

  b.ResetTimer()

  for range toString(done, take(done, repeat(done, "a"), b.N)) {
  }
}

func BenchmarkTyped(b *testing.B) {
  repeat := func(done <-chan interface{}, values ...string) <-chan string {
    valueStream := make(chan string)

    go func() {
      defer close(valueStream)

      for _, v := range values {
        select {
        case <-done:
          return
        case valueStream <- v:
        }
      }
    }()

    return valueStream
  }

  take := func(
    done <-chan interface{},
    valueStream <-chan string,
    num int,
  ) <-chan string {
    takeStream := make(chan string)

    go func() {
      defer close(takeStream)

      for i := num; i > 0 || i == -1; {
        if i != -1 {
          i--
        }

        select {
        case <-done:
          return
        case takeStream <- <-valueStream:
        }
      }
    }()

    return takeStream
  }

  done := make(chan interface{})
  defer close(done)

  b.ResetTimer()

  for range take(done, repeat(done, "a"), b.N) {
  }
}
```

Запустить эти бенчмарки можно следующей командой:

```bash
go test -bench=. -benchtime=1000000x -cpu=4 code-samples/pipelines/generators/benchmark/*.go
```

Следует ожидать подобные результаты:

```
goos: darwin
goarch: arm64
BenchmarkGeneric-4       1000000               637.5 ns/op
BenchmarkTyped-4         1000000               204.3 ns/op
PASS
ok      command-line-arguments  0.931s
```

Можно заметить, что этапы с явным типом, втрое быстрее, но лишь незначительно
быстрее по величине. В общем случае ограничивающим (limiting) фактором нашего
пайплайна будет либо наш генератор, либо один из этапов, требующий
вычислительных ресурсов. Если генератор не создаёт поток из памяти, как это
происходит в генераторах `repeat` и `repeatFn`, вероятно, мы будем ограничены
операциями ввода-вывода. То есть, всё равно, чтение с диска или через сеть,
скорее всего, превысит эти незначительные накладные расходы (performance
overhead).

<!-- TODO: как этом контексте лучше перевести magnitude? -->

Если один из наших этапов требует больших вычислительных затрат, это,
безусловно, затмит эти накладные расходы (performance overhead). Если всё равно
терять даже так мало в производительности не хочется, можно организовать
кодогенерацию.

### Разветвление и объединение (Fan-Out, Fan-In)

Представим, что мы настроили пайплайн. Данные отлично проходят через нашу
систему, трансформируются по мере прохождения этапов, которые мы соединили в
цепь. Это красивый поток, но он получился медленным. Почему он может занимать
так много времени?

Иногда этапы в нашем пайплайне могут быть особенно дорогостоящими с точки зрения
вычислений. Когда это происходит, вышестоящие (upstream) этапы в нашем пайплайне
могут блокироваться в ожидании завершения дорогостоящих этапов. Не только это,
но и выполнение самого пайплайна в целом может занять много времени. Как можно
решить эту проблему?

Одним из интересных свойств пайплайнов является возможность, которую они
предоставляют нам для работы с потоком данных, используя комбинацию отдельных,
часто переставляемых этапов. Мы можем многократно использовать этапы пайплайна.
Будет интересно попробовать переиспользовать конкретный один этап нашего
пайплайна в нескольких горутинах в попытке распараллелить (на самом деле просто
организовать конкурентное выполнение) запросы (pulls) с вышестоящего (upstream)
этапа. Возможно, это поможет улучшить производительность пайплайна.

На самом деле, оказывается, что такое возможно, и у этого паттерна есть
название: _fan-out, fan-in_ (_разветвление, объединение_)

Fan-out (разветвление) — это термин для описания процесса запуска нескольких
горутин для обработки входных данных пайплайна, а fan-in (объединение) — это
термин для описания процесса объединения нескольких результатов в один канал.

Итак, что же делает этап пайплайна подходящим для использования паттерна? Можно
рассмотреть возможность разветвления (fan-out) одного из наших этапов, если
применимы оба следующих утверждения:

- Он не полагается на значения, которые сам же этот этап вычислил ранее.
- Выполнение этого этапа занимает много времени.

Свойство независимости от порядка важно потому, что у нас нет гарантии, в каком
порядке будут выполняться конкурентные копии нашего этапа, и в каком порядке они
будут возвращать результат.

Взглянем на пример. Здесь использовать очень неэффективный способ поиска простых
чисел. Мы будем использовать множество этапов, созданных в разделе
[«Несколько удобных генераторов»](#несколько-удобных-генераторов)
([`code-samples/fan-out-fan-in/inefficient-primes/main.go`](code-samples/fan-out-fan-in/inefficient-primes/main.go)):

```go
randFn := func() interface{} {
  return rand.Intn(5_000_000_000)
}

done := make(chan interface{})
defer close(done)

randIntStream := stage.ToInt(done, stage.RepeatFn(done, randFn))

fmt.Println("Primes:")

start := time.Now()

for prime := range stage.TakeInt(done, stage.PrimeFinder(done, randIntStream), 10) {
  fmt.Printf("\t%d\n", prime)
}

fmt.Printf("Search took: %v\n", time.Since(start))
```

Результат выполнения этого кода:

```
Primes:
        3269281973
        3260034737
        4684901489
        4891926997
        2785052993
        4190313089
        4432837259
        3705865619
        4164671809
        1384483489
Search took: 30.518477959s
```

Мы генерируем поток случайных чисел, ограниченный `5_000_000_000`, преобразуем
поток в целочисленный, а затем передаём его на наш этап поиска простых чисел
`stage.PrimeFinder`. `stage.PrimeFinder` специально написан неэффективно — зато
это отличный пример этапа, занимающего _много_ времени.

В нашем цикле `for` мы перебираем найденные простые числа, выводим их в `stdout`
по мере поступления и, благодаря нашему этапу `stage.TakeInt`, закрываем
пайплайн после того, как найдено 10 простых чисел. Затем мы выводим в `stdout`,
сколько времени занял поиск, и `done`-канал закрывается с помощью выражения
`defer`, пайплайн перестаёт работать.

Чтобы избежать дублирования наших результатов, мы могли бы ввести ещё один этап
в наш пайплайн для кэширования простых чисел, которые были найдены в наборе, но
для простоты мы просто проигнорируем это.

Можно заметить, что для поиска десяти 10 простых чисел потребовалось примерно 30
секунд. Очень долго. Обычно в таком случае нужно критически посмотреть на наш
алгоритм поиска таких чисел и выявить в нём недостатки. Но цель данного этапа —
быть медленным. Вместо этого мы рассмотрим, как можно _разветвить_ (_fan-out_)
один или несколько этапов, чтобы быстрее выполнять медленные операции.

Это относительно простой пример, потому что у нас есть только два этапа:
генерация случайных чисел и просеивание простых чисел. В более крупной программе
наш пайплайн может состоять из гораздо большего количества этапов; как мы
узнаем, какой из них следует разветвить (fan-out)? Следует помнить наши
критерии: независимость от порядка и длительность выполнения. Наш генератор
случайных чисел, безусловно, не зависит от порядка, но его запуск не занимает
особенно много времени. Этап поиска простых чисел также не зависит от порядка —
числа либо простые, либо нет — и из-за нашего «тупого» алгоритма его выполнение
занимает много времени. Выглядит как хороший кандидат для разветвления (fanning
out).

К счастью, процесс разветвления (fanning out) этапа чрезвычайно прост. Всё, что
нам нужно сделать — это запустить несколько версий этого этапа. Поэтому вместо
этого:

```go
primeStream := primeFinder(done, randIntStream)
```

Мы можем сделать что-то вроде этого:

```go
numFinders := runtime.NumCPU()
finders := make([]<-chan int, numFinders)

for i := 0; i < numFinders; i++ {
  finders[i] = primeFinder(done, randIntStream)
}
```

Здесь мы запускаем столько копий этого этапа, скольку у нас CPU (на моём
компьютере их 8, в дальнейшем будем говорить об этом числе). В продакшене
следовало бы провести небольшое эмпирическое тестирование для определения
оптимального количества `numFinders`, но здесь мы сделаем просто предположим,
что CPU будет занят только копией этапа `findPrimes`.

И это всё! Теперь у нас восемь горутин, извлекающих данные из генератора
случайных чисел и пытающихся определить, является ли число простым. Генерация
случайных чисел не должна занимать много времени, и поэтому каждая горутина
этапа `findPrimes` должна быть в состоянии определить, является ли её число
простым, а затем немедленно получить доступ к другому случайному числу.

Однако всё ещё есть проблема: теперь, когда у нас есть восемь горутин, у нас
также есть восемь каналов, но наш перебор `range` ожидает только один канал. Это
приводит нас к _fan-in_ (объединяющей) части паттерна.

Как мы обсудили ранее, объединение (fanning in) означает _мультиплексирование_
или join нескольких потоков данных в один поток. Алгоритм для этого относительно
прост
([`code-samples/fan-out-fan-in/stage/stage.go`](code-samples/fan-out-fan-in/stage/stage.go)):

```go
// FanIn - Здесь мы принимаем наш стандартный done-канал, чтобы разрешить отмену
// наших горутин, а затем принимаем произвольный слайс типа interface{} для
// объединения (fan-in)
func FanIn(
  done <-chan interface{},
  channels ...<-chan interface{},
) <-chan interface{} {
  // Создаём sync.WaitGroup, чтобы мы могли дождаться, пока все каналы не будут
  // опустошены
  var wg sync.WaitGroup
  multiplexedStream := make(chan interface{})

  // Создаём функцию multiplex, которая при передаче канала будет считывать из
  // канала и передавать считанное значение в канал multiplexedStream
  multiplex := func(c <-chan interface{}) {
    defer wg.Done()

    for i := range c {
      select {
      case <-done:
        return
      case multiplexedStream <- i:
      }
    }
  }

  // Select из всех каналов.
  // Увеличиваем sync.WaitGroup на количество каналов, которые мы
  // мультиплексируем
  wg.Add(len(channels))
  for _, c := range channels {
    go multiplex(c)
  }

  // Ожидание завершения всех чтений.
  // Создаём горутину для ожидания, пока все каналы, которые мы
  // мультиплексируем, не будут опустошены, чтобы мы могли закрыть канал
  // multiplexedStream
  go func() {
    wg.Wait()
    close(multiplexedStream)
  }()

  return multiplexedStream
}
```

В двух словах, объединение (fanning in) включает в себя создание
мультиплексированного канала, с которого потребители будут считывать данные, а
затем запуск одной горутины для каждого входящего канала и одной горутины для
закрытия мультиплексированного канала, когда все входящие каналы будут закрыты.
Поскольку мы собираемся создать горутину, которая ожидает завершения $n$ других
горутин, имеет смысл создать `sync.WaitGroup` для координации действий. Функция
`multiplex` также уведомляет `sync.WaitGroup` о том, что работа завершена.

> **Дополнительное напоминание**
>
> Наивная реализация алгоритма fan-in, fan-out работает только в том случае,
> когда порядок, в котором поступают результаты, неважен. Мы ничего не сделали,
> чтобы гарантировать, что порядок, в котором элементы считываются из
> `randIntStream`, сохраняется при прохождении через «сито». Позже мы рассмотрим
> пример способа поддержания порядка.

Теперь объединим всё вместе и посмотрим, получим ли мы какое-либо сокращение
времени выполнения:

```go
randFn := func() interface{} {
  return rand.Intn(5_000_000_000)
}

done := make(chan interface{})
defer close(done)

randIntStream := stage.ToInt(done, stage.RepeatFn(done, randFn))

numFinders := runtime.NumCPU()

fmt.Printf("Spinning up %d prime finders.\n", numFinders)

finders := make([]<-chan int, numFinders)

fmt.Println("Primes:")
for i := 0; i < numFinders; i++ {
  finders[i] = stage.PrimeFinder(done, randIntStream)
}

start := time.Now()

for prime := range stage.TakeInt(done, stage.FanInInt(done, finders...), 10) {
  fmt.Printf("\t%d\n", prime)
}

fmt.Printf("Search took: %v\n", time.Since(start))
```

Результаты выполнения:

```
Spinning up 8 prime finders.
Primes:
        35497811
        88416457
        540747527
        1352798323
        1742810089
        2247303197
        1407857207
        1131157513
        221168177
        462010253
Search took: 3.977793459s
```

Время выполнения сократилось с ~30 секунд до ~4 секунд, очень неплохо! Мы смогли
сократить время выполнения программы в 7,5 раз без радикального изменения
структуры нашей программы.
