## Содержание <!-- omit in toc -->

- [Паттерны конкурентности в Go](#паттерны-конкурентности-в-go)
  - [Изоляция (Confinement)](#изоляция-confinement)
  - [Цикл for-select](#цикл-for-select)
  - [Предотвращение утечек горутин](#предотвращение-утечек-горутин)
  - [Канал с выбором (The or-channel)](#канал-с-выбором-the-or-channel)
  - [Обработка ошибок](#обработка-ошибок)
  - [Пайплайны](#пайплайны)
    - [Лучшие практики построения пайплайнов](#лучшие-практики-построения-пайплайнов)
    - [Несколько удобных генераторов](#несколько-удобных-генераторов)
  - [Разветвление и объединение (Fan-Out, Fan-In)](#разветвление-и-объединение-fan-out-fan-in)
  - [Канал or-done (The or-done-channel)](#канал-or-done-the-or-done-channel)
  - [Канал-тройник (The tee-channel)](#канал-тройник-the-tee-channel)
  - [Канал-мост (The bridge-channel)](#канал-мост-the-bridge-channel)
  - [Очереди (Queuing)](#очереди-queuing)
  - [Пакет `context`](#пакет-context)

## Паттерны конкурентности в Go

В этом разделе мы подробно рассмотрим, как компоновать примитивы конкурентности
в паттерны, чтобы сохранять систему масштабируемой и поддерживаемой.

> Во многих примерах далее будут использоваться каналы с типом `interface{}`.
> Использование пустых интерфейсов в Go — это дискуссионный момент. Однако, это
> сделано по нескольким причинам. Первая причина заключается в том, что это
> позволяет писать примеры кода проще и лаконичнее. Вторая причина — часто такое
> стиль более репрезентативен, когда речь идёт о паттерне.

### Изоляция (Confinement)

<!-- TODO: убедиться, что confinement удачно переведён, может быть "ограничение"? -->

При работе с конкурентным кодом есть несколько различных вариантов обеспечить
его безопасность:

- Примитивы синхронизации для совместного использования памяти (например,
  `sync.Mutex`)
- Синхронизация через коммуникацию (например, каналы)

Тем не менее, есть несколько других вариантов, которые неявно безопасны при
нескольких конкурентных процессов:

- Неизменяемые (immutable) данные
- Данные, защищённые изоляцией (confinement)

В некотором смысле неизменяемые данные — это идеальный вариант, поскольку они
неявно потокобезопасны. Каждый конкурентный процесс может работать с одними и
теми же данными, но он не может их изменять. Если он хочет создать новые данные,
он должен создать новую копию данных с желаемыми изменениями. Это позволяет не
только снизить когнитивную нагрузку на разработчика, но и может поспособствовать
ускорению программ, если это приводит к уменьшению размера критических секций
(или совсем их устраняет). В Go можно достичь этого, написав код, который
использует копии значений вместо указателей (pointers) на значения в памяти.
Некоторые языки поддерживают использование указателей с явно неизменяемыми
(immutable) значениями, однако, Go не входит в их число.

<!-- TODO: потокобезопасны -> безопасны для конкурентности (concurrent-safe)? (везде) -->

<!-- TODO: Некоторые языки поддерживают использование указателей с явно неизменяемым (immutable) значениями? -->

Изоляция (confinement) также может обеспечить снижение когнитивной нагрузки на
разработчика и уменьшение размера критических секций. Техники изоляции
конкурентных значений немного сложнее, чем просто передача копий значений,
поэтому здесь мы подробно рассмотрим эти техники.

Изоляция (confinement) — это простая, но мощная идея обеспечения того, чтобы
информация была доступна только из _одного_ конкурентного процесса. Когда это
достигается, конкурентная программа неявно безопасна, и синхронизация не
требуется. Существуют два вида изоляций: специальная (ad hoc) и лексическая
(lexical).

Специальная изоляция — это когда мы достигаем изоляции через соглашение
(конвенцию), неважно кем установленное — сообществом языка, командой, в которой
мы работаем, или кодовой базой, с которой мы работаем. Но придерживаться
соглашения трудно для проектов любого размера, если нет инструментов
статического анализа кода, выполняемого каждый раз, когда кто-то коммитит свой
код. Вот пример специальной изоляции, демонстрирующей, почему это так:

```go
data := make([]int, 4)

loopData := func(handleData chan<- int) {
    defer close(handleData)

    for i := range data {
        handleData <- data[i]
    }
}

handleData := make(chan int)
go loopData(handleData)

for num := range handleData {
    fmt.Println(num)
}
```

Можно видеть, что слайс целых чисел `data` доступен как из функции `loopData`,
так и из цикла, проходящего по каналу `handleData`. Однако, по соглашению мы
получаем доступ к нему только из функции `loopData`. Но код трогается многими
людьми, дедлайны поджимают, ошибки могут быть совершены, а значит, изоляция
(confinement) может быть нарушена и вызвать проблемы. Как уже упоминалось,
инструмент статического анализа может отлавливать такого рода проблемы, но
статический анализ кодовой базы Go предполагает уровень зрелости, которого
достигают не многие команды. Именно поэтому кажется предпочтительнее
использовать лексическую изоляцию: она использует компилятор для обеспечения
изоляции (confinement).

Лексическая изоляция включает в себя использование лексической области видимости
(скоупа) для предоставления только правильных данных и примитивов конкурентности
для использования несколькими конкурентными процессами. Это делает невозможным
делать что-то неправильное. На самом деле мы уже затронули это в секции
[Каналы](../building-blocks/README.md#каналы), когда обсуждали предоставление
только читательских или только писательских аспектов канала конкурентным
процессам, нуждающимся в канале. Ещё раз взглянем на этот пример
[`code-samples/confinement/channels.go`](code-samples/confinement/channels.go):

```go
chanOwner := func() <-chan int {
// Инициализируем канал в пределах лексической области (скоупа) функции
// chanOwner. Это ограничивает область действия аспекта записи в канал
// results замыканием, определённым ниже. Другими словами, это изолирует
// аспект записи канала, чтобы предотвратить запись в него другими
// горутинами
results := make(chan int, 5)

go func() {
  defer close(results)

  for i := 0; i <= 5; i++ {
    results <- i
  }
}()

return results
}

// Получаем копию int-канала только для чтения. Объявляя, что единственное
// использование, которое нам требуется, — это доступ для чтения, мы
// изолируем использование канала в функции consume только чтениями
consumer := func(results <-chan int) {
  for result := range results {
    fmt.Printf("Received: %d\n", result)
  }

  fmt.Println("Done receiving!")
}

// Получаем аспект чтения канала и можем передать его в consumer, который
// ничего не сможет делать, кроме как читать из него. Ещё раз, это изолирует
// main-горутину так, чтобы она могла только читать из канала
results := chanOwner()
consumer(results)
```

Это хороший ввод в паттерн изоляции (confinement), но, вероятно, не очень
показательный, поскольку каналы потокобезопасны. Взглянем на пример изоляции,
использующей структуру данных, которая не является потокобезопасной —
`bytes.Buffer`
([`code-samples/confinement/bytes-buffer.go`](code-samples/confinement/bytes-buffer.go)):

```go
printData := func(wg *sync.WaitGroup, data []byte) {
  defer wg.Done()

  var buff bytes.Buffer
  for _, b := range data {
    _, _ = fmt.Fprintf(&buff, "%c", b)
  }

  fmt.Println(buff.String())
}

var wg sync.WaitGroup
wg.Add(2)

data := []byte("golang")

go printData(&wg, data[:3]) // передаём слайс из первых трёх байт data
go printData(&wg, data[3:]) // передаём слайс из последних трёх байт data

wg.Wait()
```

В этом примере можно видеть, что поскольку `printData` не замкнут вокруг слайса
`data`, он не может получить доступ к нему и должен принять слайс `byte`'ов, с
которым будет работать. Мы передаём разные подмножества слайса, таким образом
ограничивая запускаемые нами горутины только той частью слайса, которую мы
передаём. Благодаря лексическому скоупу мы сделали невозможными (мы намеренно
игнорируем возможность ручного манипулирования памятью с помощью пакета
`unsafe`; он не просто так называется `unsafe`!) неправильные действия, и
поэтому нам не нужно синхронизировать доступ к памяти или делиться данными через
коммуникацию.

<!-- TODO: а что, если передать просто data? Непонятно, где здесь лексическая изоляция -->

Так в чём смысл? Зачем стремиться к изоляции (confinement), если нам доступна
синхронизация? Ответ заключается в повышении производительности и снижении
когнитивной нагрузки на разработчиков. Синхронизация сопряжена с затратами, и
если мы можем избежать этого, у нас не будет критических секций, и,
следовательно, нам не придётся «оплачивать» их синхронизацию. Мы также обходим
целый класс проблем, возможных при использовании синхронизации; разработчикам
просто не нужно беспокоиться об этих проблемах. Конкурентный код, использующий
лексическую изоляцию, также имеет преимущество в более простом понимании по
сравнению с конкурентным кодом без лексически ограниченных переменных. Это
потому, что в контексте нашего лексического скоупа мы можем писать синхронный
код.

Иногда может быть трудно установить изоляцию и поэтому иногда приходится
возвращаться к нашим замечательным примитивам конкурентности Go.

### Цикл for-select

То, что мы будем видеть снова и снова в программах на Go, — это цикл for-select.
Это не что иное, как что-то вроде этого:

```go
for { // Либо бесконечный цикл, либо перебор чего-то
  select {
    // Некоторая работа с каналами
  }
}
```

Есть несколько различных сценариев, где можно встретить этот паттерн:

- Отправка переменных итерации в канал

  Часто может захотеться преобразовать что-то, что можно проитерировать, в
  значения в канале. В этом нет ничего необычного, и обычно это выглядит
  примерно так:

  ```go
  for _, s := range []string{"a", "b", "c"} {
    select {
    case <-done:
      return
    case stringStream <- s:
    }
  }
  ```

- Бесконечный цикл, ожидающий остановки

  Очень частое явление создавать горутины, которые содержат бесконечно что-то
  делают, пока не будут остановлены. Существует пара вариантов, как это сделать.
  Выбор зависит исключительно от стилистических предпочтений.

  Первый вариант сохранят выражение `select` как можно более коротким:

  ```go
  for {
    select {
    case <-done:
      return
    default:
    }

    // Выполняем операции, которые не могут быть прерваны
  }
  ```

  Если канал `done` не закрыт, мы выйдем из инструкции `select` и перейдём к
  остальной части нашего цикла `for`.

  Второй вариант встраивает работу в выражение `default`:

  ```go
  for {
    select {
    case <-done:
      return
    default:
      // Выполняем операции, которые не могут быть прерваны
    }
  }
  ```

  Когда мы входим в `select`, если канал `done` не был закрыт, мы выполняем
  содержимое `default`.

### Предотвращение утечек горутин

В разделе [«Горутины»](../building-blocks/README.md#горутины) мы узнали, что
создавать горутины дёшево и просто; это одна из вещей, которая делает Go таким
производительным языком. Рантайм (среда выполнения) обрабатывает
мультиплексирование горутин на любое число потоков операционной системы, так что
нам не часто приходится беспокоиться об этом уровне абстракции. Однако горутины
всё равно стоят каких-то ресурсов, и при этом они не собираются сборщиком мусора
в рантайме. Поэтому, несмотря на то, сколько мало памяти они занимают, мы не
хотим оставлять их в нашем процессе. Так как же нам убедиться, что они
освободили память?

Будем размышлять шаг за шагом: зачем нужна горутина? Ранее мы установили, что
горутины представляют собой единицы работы (units of work), которые могут
выполняться либо параллельно, либо нет. Горутина имеет несколько путей для
завершения (termination):

- Когда она завершила свою работу
- Когда она не может продолжить свою работу из-за неустранимой ошибки
  (unrecoverable error)
- Когда ей сообщили прекратить работу

Первые два пути нам достаются бесплатно — эти пути являются нашим алгоритмом —
но что насчёт отмены работы (work cancellation)? Это оказывается самым важным
моментом из-за сетевого эффекта: если мы запустили горутину, вероятнее всего,
она каким-то организованным образом взаимодействует с несколькими другими
горутинами. Мы могли бы даже представить эту взаимосвязь в виде графа: вопрос о
том, должна ли дочерняя горутина продолжать выполнение, может основываться на
знании состояния многих _других_ горутин. Родительская горутина (часто
main-горутина), обладающая всеми этими контекстуальными знаниями, должна быть в
состоянии сообщить своим дочерним горутинам о том, что нужно завершить работу.
Мы продолжим рассмотрение крупномасштабной взаимозависимости горутин позже, а
пока рассмотрим, как обеспечить гарантированную очистку одной дочерней горутины.
Начнём с простого примера утечки горутины
([`code-samples/preventing-goroutine-leaks/simple-goroutine-leak.go`](code-samples/preventing-goroutine-leaks/simple-goroutine-leak.go)):

<!-- TODO: ссылка на "позже" -->

```go
doWork := func(strings <-chan string) <-chan interface{} {
  completed := make(chan interface{})

  go func() {
    defer fmt.Println("doWork exited.")
    defer close(completed)

    for s := range strings {
      // Делаем что-то интересное
      fmt.Println(s)
    }
  }()

  return completed
}

doWork(nil)

// Здесь может быть проделана ещё какая-либо работа

fmt.Println("Done.")
```

Здесь мы видим, что main-горутина передаёт `nil`-канал в `doWork`. Таким
образом, канал `strings` на самом деле никогда не получит никаких строк, и
содержащаяся в `doWork` горутина останется в памяти на всё время существования
этого процесса (мы бы даже упали в deadlock, если бы создали точку соединения
(join point) горутины внутри `doWork` с main-горутиной).

В этом примере время жизни процесса очень короткое, но в реальной программе
горутины легко могли бы быть запущены в начале долгоживущей программы. В худшем
случае main-горутина может продолжать запускать горутины на протяжении всего
срока службы, что приведёт к постоянному увеличению потребления памяти по мере
работы процесса.

Способом успешного устранения этого является установление сигнала между
родительской горутиной и её дочерними горутинами. По соглашению, этот сигнал
обычно является каналом только для чтения с именем `done`. Родительская горутина
передаёт этот канал дочерней горутине, а затем закрывает канал, когда хочет
отменить дочернюю горутину. Пример
([`code-samples/preventing-goroutine-leaks/done-channel.go`](code-samples/preventing-goroutine-leaks/done-channel.go)):

```go
// В функции doWork ожидаем канал done. По соглашению он должен быть первым
// параметром
doWork := func(done <-chan interface{}, strings <-chan string) <-chan interface{} {
  terminated := make(chan interface{})

  go func() {
    defer fmt.Println("doWork exited.")
    defer close(terminated)

    for {
      select {
      case s := <-strings:
        // Делаем что-то интересное
        fmt.Println(s)
      // Здесь мы видим повсеместно используемый паттерн for-select.
      // Одним из наших условий является проверка того, был ли сигнал
      // горутине из канала done. Если да, то мы возвращаемся из
      // горутины
      case <-done:
        return
      }
    }
  }()

  return terminated
}

done := make(chan interface{})
terminated := doWork(done, nil)

// Здесь создаём другую горутину, которая отменит горутину, созданную в
// doWork, если пройдёт более одной секунды
go func() {
  // Останавливаем операцию через 1 секунду
  time.Sleep(1 * time.Second)
  fmt.Println("Canceling doWork goroutine.")
  close(done)
}()

// Точка соединения (join point) горутины, созданной в doWork с
// main-горутиной
<-terminated

fmt.Println("Done.")
```

Результат выполнения:

```
Canceling doWork goroutine.
doWork exited.
Done.
```

Можно видеть, что, несмотря на передачу значения `nil` для нашего канала
`strings`, наша горутина по-прежнему успешно завершает работу. В отличие от
предыдущего примера, в этом примере мы соединяем (join) две горутины и, тем не
менее, не получаем взаимоблокировку (deadlock). Это связано с тем, что перед
соединением (join) двух горутин мы создаём третью горутину, чтобы отменить
горутину в `doWork` через секунду. Мы успешно устранили утечку нашей горутины!

Предыдущий пример прекрасно обрабатывает случай, когда горутина получает данные
из канала, но что если мы имеем дело с обратной ситуацией: горутина
заблокирована при попытке записать значение в канал? Вот краткий пример,
демонстрирующий проблему
([`code-samples/preventing-goroutine-leaks/producer-block.go`](code-samples/preventing-goroutine-leaks/producer-block.go)):

```go
newRandStream := func() <-chan int {
  randStream := make(chan int)

  go func() {
    // Выводим сообщение, когда горутина успешно завершается
    defer fmt.Println("newRandStream closure exited.")

    defer close(randStream)

    for {
      randStream <- rand.Int()
    }
  }()

  return randStream
}

randStream := newRandStream()

fmt.Println("3 random ints:")
for i := 0; i < 3; i++ {
  fmt.Printf("%d: %d\n", i+1, <-randStream)
}
```

Код производит примерно следующий результат:

```
3 random ints:
1: 2399527266310276677
2: 4640016047858466284
3: 5606599328692408164
```

По результату выполнения кода можно увидеть, что отложенный вызов `fmt.Println`
никогда не срабатывает. После третьей итерации нашего цикла горутина блокирует
попытку отправить следующее случайное число в канал, из которого больше не
выполняется чтение. У нас нет способа сообщить горутине-производителю, что она
может больше не пытаться слать значения в канал. Решение, как и в случае с
примером с горутиной-получателем, состоит в том, чтобы предоставить горутине
канал, информирующий её о выходе
([`code-samples/preventing-goroutine-leaks/producer-ok.go`](code-samples/preventing-goroutine-leaks/producer-ok.go)):

```go
newRandStream := func(done <-chan interface{}) <-chan int {
  randStream := make(chan int)

  go func() {
    defer fmt.Println("newRandStream closure exited.")

    defer close(randStream)

    for {
      select {
      case randStream <- rand.Int():
      case <-done:
        return
      }
    }
  }()

  return randStream
}

done := make(chan interface{})
randStream := newRandStream(done)

fmt.Println("3 random ints:")
for i := 0; i < 3; i++ {
  fmt.Printf("%d: %d\n", i+1, <-randStream)
}

close(done)

// Имитируем продолжающуюся работу
time.Sleep(1 * time.Second)
```

Этот код произведёт примерно следующее:

```
3 random ints:
1: 302978367576501321
2: 7580288934885243035
3: 6700322878534526592
newRandStream closure exited.
```

Теперь мы видим, что горутина должным образом очищена.

Теперь, когда мы знаем, как обеспечить, чтобы горутины не утекали, можно
оговорить соглашение: _если горутина отвечает за создание горутины, она также
отвечает за обеспечение того, чтобы она могла остановить горутину_.

Это соглашение помогает гарантировать, что наши программы будут компонуемые и их
будет можно масштабировать по мере их роста. Мы вернёмся к этому методу в
разделах "Pipelines" и "Пакет context". Способы, которыми мы обеспечиваем
возможность остановки горутин, могут отличаться в зависимости от типа и
назначения горутины, но все они основаны на передаче `done`-канала.

<!-- TODO: компонуемые (composable)? -->

<!-- TODO: ссылки и норм перевод разделов "Pipelines" и "Пакет context" -->

### Канал с выбором (The or-channel)

Иногда хочется объединить один или несколько `done`-каналов в один `done`-канал,
который будет закрываться, если любой из его составляющих каналов закрывается.
Вполне приемлемо, хотя и довольно многословно, написать оператор `select`,
который выполняет это связывание каналов; однако, иногда мы не можем знать
количество `done`-каналов, с которыми рантайму (среде выполнения) придётся
работать. В таком случае, или если мы просто предпочитаем однострочный вариант,
мы можем объединить эти каналы вместе, используя паттерн _канал с выбором_
(_or-channel_).

Этот паттерн создаёт составной `done`-канал через рекурсию и горутины. Посмотрим
на пример
([`code-samples/or-channel/or-channel.go`](code-samples/or-channel/or-channel.go)):

```go
// Наша функция or, которая принимает произвольный слайс каналов и возвращает
// одиночный канал
func or(channels ...<-chan interface{}) <-chan interface{} {
  switch len(channels) {
  // Поскольку это рекурсивная функция, мы должны задать базовый случай.
  // В первом случае, если произвольный слайс пустой, мы просто вернём
  // nil-канал. Это консистентно с общим ожидаемым поведением функции:
  // в случае, когда мы не передали ни один канал, мы не ожидаем, что
  // составной канал что-то будет делать
  case 0:
    return nil
  // Второй базовый случай: если произвольный слайс состоит только из одного
  // элемента, мы просто вернём этот же элемент
  case 1:
    return channels[0]
  }

  orDone := make(chan interface{})

  // Основное тело функции, где происходит рекурсия. Мы создаём горутину,
  // чтобы мы могли ожидать сообщения на наших каналах без блокировки
  go func() {
    defer close(orDone)

    switch len(channels) {
    // Из-за того, как мы выполняем рекурсию, каждый рекурсивный вызов or
    // будет иметь, по крайней мере, два канала. В качестве оптимизации,
    // чтобы ограничить количество создаваемых горутин, мы помещаем здесь
    // особый случай для вызовов or только с двумя каналами
    case 2:
      select {
      case <-channels[0]:
      case <-channels[1]:
      }
    // Здесь мы рекурсивно создаём or-канал из всех каналов из нашего
    // слайса, начиная с индекса 3, а затем выполняем select по ним. Это
    // рекуррентное соотношение деструктурирует остальную часть среза на
    // or-каналы, чтобы сформировать дерево, из которого вернётся первый
    // сигнал. Мы также передаём канал orDone, чтобы когда горутины вверху
    // дерева завершатся, горутины внизу также завершились.
    default:
      select {
      case <-channels[0]:
      case <-channels[1]:
      case <-channels[2]:
      case <-or(append(channels[3:], orDone)...):
      }
    }
  }()

  return orDone
}
```

<!-- TODO: добавить какую-то иллюстрацию, изобразить дерево рекурсии, например -->

Это довольно простая функция, которая позволяет объединить любое количество
каналов в один канал, который закроется, как только любой из его составляющих
каналов будет закрыт или в него будет записана информация. Посмотрим, как мы
можем использовать эту функцию. Краткий пример, в котором используются каналы,
закрывающиеся по истечении заданного времени, и используется функция `or` для
объединения их в один канал, который закрывается
([`code-samples/or-channel/or-channel-usage.go`](code-samples/or-channel/or-channel-usage.go)):

> Чтобы запустить этот код, можно воспользоваться командой
> `go run or-channel/*.go`.

```go
// Эта функция просто создаёт канал, который закрывается по прошествии
// времени, указанного в after
sig := func(after time.Duration) <-chan interface{} {
  c := make(chan interface{})

  go func() {
    defer close(c)
    time.Sleep(after)
  }()

  return c
}

// Здесь мы запоминаем приблизительное время, когда канал из функции or
// начинает блокировать main-горутину
start := time.Now()

<-or(
  sig(2*time.Hour),
  sig(5*time.Minute),
  sig(1*time.Second),
  sig(1*time.Hour),
  sig(1*time.Minute),
)

// Выводим время, которое потребовалось для выполнения считывания из канала,
// возвращённого функцией or
fmt.Printf("done after %v\n", time.Since(start))
```

<!-- TODO: на этом моменте я понял, что не форматировал комментарии в коде в
MD-файле, чтобы они оптимально вписывались в editor.rules -->

Если мы запустим эту программу, получим примерно такой результат:

```
done after 1.001202334s
```

Следует обратить внимание, что, несмотря на размещение нескольких каналов при
вызове нашей функции `or`, закрытие которых занимает разное время, канал,
закрывающийся через одну секунду, приводит к закрытию всего результирующего
канала, созданного вызовом `or`. Это происходит потому, что, несмотря на своё
место в дереве, которое строит функция `or`, он всегда будет закрываться первым,
и, таким образом, каналы, зависящие от его закрытия, также закроются.

Мы достигаем этой лаконичности за счёт создания дополнительных горутин —
$f\left(x\right) = \left\lfloor \dfrac{x}{2} \right\rfloor$
([округление к меньшему](https://ru.wikipedia.org/wiki/Целая_часть)), где $x$ —
это количество каналов, — но следует помнить, что одной из сильных сторон Go
является способность быстро создавать, планировать и запускать горутины, и язык
активно поощряет использование горутин для моделирования проблем (задач)
правильно. Беспокойство о количестве создаваемых здесь горутинах, вероятно,
является преждевременной оптимизацией. Опять же, если во время компиляции мы не
знаем, со сколькими `done`-каналами мы работаем, другого способа объединить
`done`-каналы нет.

<!-- TODO: убедиться, что я правильно исправил ошибку x - число -горутин- -> каналов -->

Этот паттерн полезно использовать на пересечении модулей в нашей системе. В этих
местах обычно возникает несколько условий для отмены деревьев горутин по стеку
вызовов. Используя функцию `or` мы можем просто объединить их вместе и передать
вниз по стеку. Мы также рассмотрим другой способ сделать это в разделе "Пакет
context", что тоже является хорошим способом, и, возможно, более описательным.

<!-- TODO: норм ссылка и название раздела "пакет context" -->

Мы также рассмотрим, как мы можем использовать вариацию этого паттерна для
формирования более сложного паттерна в разделе "Replicated Requests".

<!-- TODO: норм ссылка и название раздела "replicated requests" -->

### Обработка ошибок

В конкурентных программах бывает сложно правильно организовать обработку ошибок.
Иногда мы тратим так много времени на размышления о том, как наши различные
процессы будут обмениваться информацией и координироваться, что забываем
подумать о том, как изящно (gracefully) они будут обрабатывать ошибочные
состояния. Когда Go отказался от популярной модели представления ошибок в виде
исключений (exceptions), он как бы сделал заявление, что обработка ошибок важна,
и что при разработке наших программ мы должны уделять путям возникновения ошибок
такое же внимание, какое уделяем нашим алгоритмам. В этом же духе давайте
взглянем на том, как мы это делаем с несколькими конкурентными процессами.

Самый фундаментальный вопрос, который возникает при обработке ошибок, — «Кто
ответственен за обработку ошибки?». В какой-то момент программе всё же
необходимо прекратить передачу ошибки по стеку и действительно что-то с ней
сделать. Кто за это отвечает?

С конкурентными процессами, этот вопрос становится немного более комплексным.
Поскольку конкурентный процесс работает независимо от своего родителя или других
дочерних элементов родителя, ему может быть сложно принять решение о том, как
правильно поступить с ошибкой. Взглянем на этот код для понимания этой проблемы
([`code-samples/error-handling/issue.go`](code-samples/error-handling/issue.go)):

```go
checkStatus := func(done <-chan interface{}, urls ...string) <-chan *http.Response {
  responses := make(chan *http.Response)

  go func() {
    defer close(responses)

    for _, url := range urls {
      resp, err := http.Get(url)
      if err != nil {
        // Здесь мы видим, что горутина делает всё возможное, чтобы
        // сигнализировать о наличии ошибки. Что ещё она может сделать? Она не
        // может передать эту ошибку обратно. Сколько ошибок считать слишком
        // большим количеством? Продолжает ли она после сигнала об ошибке
        // отправлять запросы?
        fmt.Println(err)
        continue
      }

      select {
      case <-done:
        return
      case responses <- resp:
      }
    }
  }()

  return responses
}

done := make(chan interface{})
defer close(done)

urls := []string{"https://google.com", "https://badhost"}
for response := range checkStatus(done, urls...) {
  fmt.Printf("Response: %v\n", response.Status)
}
```

Этот код произведёт следующее:

```
Response: 200 OK
Get "https://badhost": dial tcp: lookup badhost: no such host
```

Здесь мы видим, что у горутины не было выбора в этом вопросе. Она не может
просто «проглотить» эту ошибку, и поэтому она делает единственную разумную вещь:
печатает эту ошибку и надеется, что кто-то обратит внимание. Не нужно ставить
свои горутины в такое неловкое положение. Можно руководствоваться следующим: в
общем, нашим конкурентным процессам следует отправлять ошибки в другую часть
нашей программы, которая обладает полной информацией о состоянии нашей программы
и может принять более обоснованное решение о том, что делать. Следующий пример
демонстрирует правильное решение этой проблемы
([`code-samples/error-handling/example.go`](code-samples/error-handling/example.go)):

```go
// Создаём тип, который включает в себя как *http.Response, так и ошибку,
// возможную в цикле нашей горутины
type Result struct {
  Error    error
  Response *http.Response
}

// Эта функция возвращает канал, из которого можно считывать результаты
// итераций нашего цикла
checkStatus := func(done <-chan interface{}, urls ...string) <-chan Result {
  results := make(chan Result)

  go func() {
    defer close(results)

    for _, url := range urls {
      resp, err := http.Get(url)

      // Создаём инстанс Result с необходимым набором полей
      result := Result{
        Error:    err,
        Response: resp,
      }

      select {
      case <-done:
        return
      // Пишем result в канал
      case results <- result:
      }
    }
  }()

  return results
}

done := make(chan interface{})
defer close(done)

urls := []string{"https://google.com", "https://badhost"}
for result := range checkStatus(done, urls...) {
  // Здесь, в нашей main-горутине, мы можем разумнее обрабатывать ошибки,
  // возникающие в горутине, запущенной из checkStatus, и в рамках более
  // обширного контекста
  if result.Error != nil {
    fmt.Printf("error: %v\n", result.Error)
    continue
  }

  fmt.Printf("Response: %v\n", result.Response.Status)
}
```

Этот код произведёт следующее:

```
Response: 200 OK
error: Get "https://badhost": dial tcp: lookup badhost: no such host
```

Ключевой момент, на который следует обратить внимание, — это то, как мы связали
потенциальный результат с потенциальной ошибкой. Это представляет собой полный
набор возможных результатов, созданных горутиной из `checkStatus`, и позволяет
нашей main-горутине принимать решение о том, что делать в случае ошибки. В более
широком смысле, мы успешно отделили задачи обработки ошибок от нашей
горутины-производителя. Так делать желательно потому, что горутина, которая
создала горутину-производителя — в данном случае так сделала main-горутина —
имеет больше информации о запущенной горутине и может принимать более разумные
решения о том, что делать с ошибками.

В предыдущем примере мы просто записывали ошибки в `stdout`, но мы могли бы
сделать кое-что ещё. Давайте изменим нашу программу так, чтобы она перестала
проверять статус при возникновении трёх или более ошибок
([`code-samples/error-handling/example-2.go`](code-samples/error-handling/example-2.go)):

```go
done := make(chan interface{})
defer close(done)

errCount := 0

urls := []string{"a", "https://google.com", "b", "c", "d"}
for result := range checkStatus(done, urls...) {
  if result.Error != nil {
    fmt.Printf("error: %v\n", result.Error)

    errCount++

    if errCount >= 3 {
      fmt.Println("Too many errors, breaking!")
      break
    }

    continue
  }

  fmt.Printf("Response: %v\n", result.Response.Status)
}
```

Результат выполнения этого кода:

```
error: Get "a": unsupported protocol scheme ""
Response: 200 OK
error: Get "b": unsupported protocol scheme ""
error: Get "c": unsupported protocol scheme ""
Too many errors, breaking!
```

Можно видеть, что, поскольку ошибки возвращаются из `checkStatus` и не
обрабатываются внутри горутины, обработка ошибок выполняется по присущему Go
паттерну. Это лишь простой пример, но нетрудно представить ситуации, где
main-горутина координирует результаты нескольких горутин и строит более сложные
правила для продолжения или завершения дочерних горутин. Опять же, основной
посыл здесь в том, что ошибки следует рассматривать как полноценные результаты
(они такие же первостепенные, как и обычные результат) при построении значений,
возвращаемых из горутин. Если наша горутина может производить ошибки, эти ошибки
должны быть тесно связаны с нашим результирующим типом и передаваться по тем же
каналам связи — точно так же, как и в обычных синхронных функциях.

### Пайплайны

Когда мы разрабатываем программу, как правило, мы не сидим и не пишем одну
единственную длинную функцию. Обычно мы строим абстракции в виде функций,
структур, методов и т.д. Почему мы делаем это? Отчасти потому, что хотим
абстрагироваться от деталей, которые не имеют значения в контексте общей задачи,
а отчасти потому, что хотим работать над одной областью кода, не затрагивая
(without affecting) другие области. Вероятно, каждый сталкивался с ситуацией,
когда чтобы внести одно логическое изменение, необходимо затронуть множество
областей кода. Скорее всего, так происходило потому, что система страдает от
скудности абстракции.

_Пайплайн_ — это просто ещё один инструмент, который может использоваться для
формирования абстракции в нашей системе. В частности, это очень мощный
инструмент, используемый, когда нашей программе необходимо обрабатывать потоки
или пачки данных. Считается, что слово "pipeline" («трубопровод», пайплайн)
впервые было использовано в 1856 году и, вероятно, относилось к линии труб, по
которым жидкость транспортировалась из одного места в другое. Мы заимствуем это
слово для Computer Science, потому что мы также транспортируем что-то из одного
места в другое. Пайплайн ни что иное, как серия вещей, которые принимают данные,
выполняют операции над ними и передают данные обратно. Мы называем каждую из
таких операций _этапом_ (_stage_) пайплайна.

Используя пайплайн, мы разделяем задачи каждого этапа, чтобы обеспечивает ряд
преимуществ. Мы можем изменять этапы независимо друг от друга, можем смешивать и
сопоставлять (to match) то, как этапы составлены, независимо от изменения
этапов. Мы можем обрабатывать каждый этап конкурентно с восходящими (upstream) и
нисходящими (downstream) этапами, _разветвлять_ (_fan-out_) или _ограничивать
скорость_ (_rate-limit_, рейт-лимиты) отдельных участков нашего пайплайна. Мы
рассмотрим разветвление (fan-out) в разделе "Fan-Out, Fan-In", а рейт-лимиты — в
Главе 5. Сейчас не нужно беспокоиться о том, что означают эти термины; начнём с
простого и попробуем построить этап пайплайна.

<!-- TODO: норм перевод и ссылки на Fan-Out и рейт-лимиты. Главы 5 не будет, вместо этого ссылка ну нужный участок -->

Как говорилось ранее, этап — это просто что-то, что принимает данные, производит
трансформации над этими данными и отправляет эти данные обратно. Пример функции,
которую можно было бы рассматривать как этап пайплайна:

```go
multiply := func(values []int, factor int) []int {
  multipliedValues := make([]int, len(values))

  for i, v := range values {
    multipliedValues[i] = v * factor
  }

  return multipliedValues
}
```

Эта функция принимает слайс целых чисел и множителем, в цикле проходится по
слайсу и умножает каждый его элемент на `factor`, а затем возвращает новый
трансформированный слайс наружу.

И ещё одна скучная функция, которая создаёт новый слайс и добавляет к каждому
его элементу `additive`:

```go
add := func(values []int, additive int) []int {
  addedValues := make([]int, len(values))

  for i, v := range values {
    addedValues[i] = v + additive
  }

  return addedValues
}
```

На данный момент, непонятно, что делает эти две функции этапами пайплайна, а не
просто функциями. Попробуем скомбинировать их
([`code-samples/pipelines/combined-funcs.go`](code-samples/pipelines/combined-funcs.go)):

```go
ints := []int{1, 2, 3, 4}

for _, v := range add(multiply(ints, 2), 1) {
  fmt.Println(v)
}
```

Этот код производит:

```
3
5
7
9
```

Следует обратить внимание на то, как мы комбинируем функции `add` и `multiply` в
`range`. Это совершенно обычные функции, но мы их сконструировали так, чтобы они
обладали свойствами этапов пайплайна: мы можем объединить их и составить
пайплайн. Интересно, а какие свойства есть у этапа пайплайна?

- Этап принимает и возвращает один и тот же тип.
- Этап должен быть _овеществлён_ языком, чтобы его можно было передавать по
  кругу. Функции в Go являются овеществлёнными и отлично подходят для этой цели.

> В контексте языков, _овеществление_ (reification, реификация) означает, что
> язык предоставляет разработчикам концепцию, чтобы они могли работать с ней
> напрямую. Функции в Go можно назвать овеществленными, так мы можем определять
> переменные, которые имеют тип сигнатуры функции. Это также означат, что мы
> можем передавать функции по всей нашей программе.

Если вы знакомы с функциональным программированием, то, возможно, узнали здесь
что-то вроде функций высшего порядка и монад. Действительно, этапы пайплайна
очень тесно связаны с функциональным программированием и могут рассматриваться
как подмножество монад.

<!-- Похоже ли это на функции высшего порядка и на монады? -->

Наши этапы `multiply` и `add` удовлетворяют всех свойствам этапов пайплайна: они
оба принимают слайс из `int`'ов и возвращают слайс из `int`'ов, и, поскольку в
Go есть овеществлённые функции, мы можем передавать `add` и `multiply` по кругу.
Эти свойства этапов приводят к интересным свойствам пайплайна, о которых мы
упоминали ранее: этапы становится очень легко комбинировать на более высоком
уровне без изменения самих этапов.

Например, если мы хотим добавить дополнительный этап, умножающий всё на 2, в наш
пайплайн, нам нужно просто обернуть предыдущий пайплайн в новый `multiply`-этап,
примерно вот так
([`code-samples/pipelines/new-stage.go`](code-samples/pipelines/new-stage.go)):

```go
ints := []int{1, 2, 3, 4}

for _, v := range multiply(add(multiply(ints, 2), 1), 2) {
  fmt.Println(v)
}
```

Выполнив этот код, мы получим:

```
6
10
14
18
```

Следует обратить внимание, что мы сделали это без написания новой функции,
модифицирования существующей или модифицирования того, что мы делаем с
результатом нашего пайплайна. Конечно, мы могли бы написать этот код в
процедурном стиле:

```go
ints := []int{1, 2, 3, 4}

for _, v := range ints {
  fmt.Println(2*(v*2+1))
}
```

На первый взгляд это кажется намного проще, но, как мы увидим по ходу дела,
процедурный код не обеспечивает тех преимуществ, которые предоставляет пайплайн
при работе с потоками данных.

Также обратите внимание, как каждый этап берёт _слайс_ данных и возвращает
_слайс_ данных. Эти этапы выполняют то, что называем _пакетной обработкой_
(_batch processing_). Это просто означает, что они оперируют чанками (кусками)
данных одновременно, а не одним дискретным значением за раз. Существует другой
тип этапов пайплайнов, который подразумевает выполнение _потоковую обработку_
(_stream processing_). Это означает, что этап принимает и выпускает по одному
элементу за раз.

У пакетной обработки есть свои плюсы и минусы относительно потоковой обработки,
которые мы обсудим чуть позже. А пока следует обратить внимание, что для того,
чтобы исходные данные оставались неизменными, на каждом этапе необходимо
создавать новый слайс равной длины для хранения результатов своих вычислений.
Это означает, что объём памяти, что объём памяти, занимаемой нашей программой, в
любой момент в два раза превышает размер слайса, который мы отправляем в начало
нашего пайплайна. Преобразуем наши этапы в поточные (потоковая обработка) и
посмотрим, как это выглядит
([`code-samples/pipelines/stream-oriented-stages.go`](code-samples/pipelines/stream-oriented-stages.go)):

```go
multiply := func(value, factor int) int {
  return value * factor
}

add := func(value, additive int) int {
  return value + additive
}

ints := []int{1, 2, 3, 4}

for _, v := range ints {
  fmt.Println(multiply(add(multiply(v, 2), 1), 2))
}
```

Этот код производит:

```
6
10
14
18
```

Каждый этап принимает и выпускает дискретное значение, и объём памяти нашей
программы снова сократился только до размера входных данных пайплайна. Но нам
пришлось перенести пайплайн в тело цикла `for` и заставить `range` выполнять
работу по заполнению нашего пайплайна. Это не только ограничивает повторное
использование того, как мы заполняем пайплайн, но и, как мы увидим позже, также
ограничивает нашу способность к масштабированию. По сути, мы создаём инстанс
нашего пайплайна для каждой итерации цикла. Хотя вызовы функций дешёвая
операция, мы выполняем по три вызова функций для каждой итерации цикла. А что
насчёт конкурентности, Ранее было сказано, что одним из преимуществ
использования пайплайнов является возможность одновременной обработки отдельных
этапов, и было упомянуто кое-что о разветвлении. Откуда всё это берётся?

#### Лучшие практики построения пайплайнов

Каналы уникально подходят для построения пайплайнов, поскольку они удовлетворяют
всем нашим основным требованиям. Они могут принимать и выпускать значения, их
можно потокобезопасно использовать, по ним можно пробегаться в цикле, и они
овеществлены языком. Преобразуем предыдущий пример, чтобы он работал с каналами
([`code-samples/pipelines/pipeline-on-channels.go`](code-samples/pipelines/pipeline-on-channels.go)):

```go
generator := func(done <-chan interface{}, integers ...int) <-chan int {
  intStream := make(chan int)

  go func() {
    defer close(intStream)

    for _, i := range integers {
      select {
      case <-done:
        return
      case intStream <- i:
      }
    }
  }()

  return intStream
}

multiply := func(
  done <-chan interface{},
  intStream <-chan int,
  factor int,
) <-chan int {
  multipliedStream := make(chan int)

  go func() {
    defer close(multipliedStream)

    for i := range intStream {
      select {
      case <-done:
        return
      case multipliedStream <- i * factor:
      }
    }
  }()

  return multipliedStream
}

add := func(
  done <-chan interface{},
  intStream <-chan int,
  additive int
) <-chan int {
  addedStream := make(chan int)

  go func() {
    defer close(addedStream)

    for i := range intStream {
      select {
      case <-done:
        return
      case addedStream <- i + additive:
      }
    }
  }()

  return addedStream
}

done := make(chan interface{})
defer close(done)

intStream := generator(done, 1, 2, 3, 4)
pipeline := multiply(done, add(done, multiply(done, intStream, 2), 1), 2)

for v := range pipeline {
  fmt.Println(v)
}
```

Этот код производит:

```
6
10
14
18
```

Похоже, мы просто воспроизвели желаемый результат, но за счёт использования
гораздо большего количества кода. В чём мы выиграли? Посмотрим на то, что мы
написали. Теперь у нас есть три функции вместо двух. Все они выглядят похоже —
запускают одну горутину внутри своего тела и используют паттерн рассмотренный в
разделе [«Предотвращение утечек горутин»](#предотвращение-утечек-горутин),
который подразумевает принятие канала, который может просигнализировать о том,
что горутина должна завершиться. Также все они возвращают каналы, а некоторые из
них при этом принимают дополнительный канал. Начнём разбирать этот код далее:

<!-- TODO: ставим ли кавычки для разделов? -->

```go
done := make(chan interface{})
defer close(done)
```

Первое, что наша программа делает — создаёт `done`-канал и через `defer`
откладывает вызов `close` для этого канала. Как и обсуждалось ранее, это
гарантирует то, что наша программа завершит работу чисто и никогда не произойдёт
утечки горутин. Здесь нет ничего нового. Теперь посмотрим на функцию
`generator`:

```go
generator := func(done <-chan interface{}, integers ...int) <-chan int {
  intStream := make(chan int)

  go func() {
    defer close(intStream)

    for _, i := range integers {
      select {
      case <-done:
        return
      case intStream <- i:
      }
    }
  }()

  return intStream
}

// ...

intStream := generator(done, 1, 2, 3, 4)
```

Функция `generator` принимает произвольный слайс целых чисел, собирает
буферизированный канал из целых чисел длины, равной длине входящего слайса,
запускает горутину и возвращает собранный канал. В созданной и запущенной здесь
горутине функция `generator` пробегает по всему произвольному слайсу, который мы
передали в функцию `generator` и отправляет элементы слайса в канал, который мы
создали.

Следует обратить внимание на то, что отправка в канал разделяет оператор
`select` с выбором на канале `done`. Опять же, это паттерн, который мы
рассмотрели в разделе
[«Предотвращение утечек горутин»](#предотвращение-утечек-горутин).

Итак, в двух словах, функция `generator` преобразует дискретный набор значений в
поток данных на канале. Как раз-таки такой тип функций называется _генератором_.
При работе с пайплайнами мы часто будем сталкиваться с тем, что в начале
пайплайна будет некоторый пакет данных (batch of data), который нужно
преобразовать в канал. Закончим разбор этой программы — наконец, мы строим
пайплайн:

```go
pipeline := multiply(done, add(done, multiply(done, intStream, 2), 1), 2)
```

Это такой же пайплайн, с которым мы работали всё это время: некоторый поток
чисел мы умножаем на 2, добавляем единицу, а затем результат умножаем на 2. Этот
пайплайн аналогичен предыдущему нашему пайплайну, использующему функции, из
предыдущего примера, но он отличается очень важными аспектами.

Первое — мы используем каналы. Это очевидно, но важно, потому что это позволяет
сделать две вещи: в конце нашего пайплайна мы можем использовать выражение
`range` для извлечения значений, и на каждом этапе мы можем безопасно выполнять
его конкурентно, потому что его входы и выходы безопасны в контексте
конкурентности.

Это подводит нас ко второму отличию: каждый этап пайплайна выполняется
конкурентно. Это означает, что любому этапу нужно только дождаться своих входных
данных и иметь возможность отправить свои выходные данные. Оказывается, это
имеет серьёзные последствия, которые мы обсудим в разделе "Fan-Out, Fan-In", но
пока можно просто отметить, что это позволяет нашим этапам выполняться
независимо друг от друга в течение некоторого промежутка времени.

<!-- TODO: ссылка и норм перевод "Fan-Out, Fan-In -->

И в конце нашего примера мы проходим по всему этому пайплайну и извлекаем
значения из всей этой системы:

```go
for v := range pipeline {
  fmt.Println(v)
}
```

Это таблица, демонстрирующая, как каждое из значений в системе будет попадать в
каждый канал, и когда каналы окажутся закрытыми. Номер итерации — это счётчик,
который начинается с нули и отражает номер текущей итерации цикла `for`, а число
в каждом столбце — это значение в том виде, в каком оно приходит на этап
пайплайна:

| Номер итерации | `generator` | `multiply` | `add`    | `multiply` | Результат |
| -------------- | ----------- | ---------- | -------- | ---------- | --------- |
| 0              | 1           |            |          |            |           |
| 0              |             | 1          |          |            |           |
| 0              | 2           |            | 2        |            |           |
| 0              |             | 2          |          | 3          |           |
| 0              | 3           |            | 4        |            | 6         |
| 1              |             | 3          |          | 5          |           |
| 1              | 4           |            | 6        |            | 10        |
| 2              | (закрыт)    | 4          |          | 7          |           |
| 2              |             | (закрыт)   | 8        |            | 14        |
| 3              |             |            | (закрыт) | 9          |           |
| 3              |             |            |          | (закрыт)   | 18        |

Давайте также более внимательно рассмотрим использование паттерна для подачи
горутинам сигнала о завершении. Когда мы имеем дело с несколькими
взаимозависимыми горутинами, как этот паттерн работает? Что произойдёт, если мы
вызовем `close` на канале `done` до завершения выполнения программы?

Чтобы ответить на эти вопросы, ещё раз взглянем на конструкцию нашего пайплайна:

```go
pipeline := multiply(done, add(done, multiply(done, intStream, 2), 1), 2)
```

Этапы связаны между собой двумя связями: общим каналом `done` и каналами,
которые передаются в последующие этапы пайплайна. Другими словами, канал,
созданный функцией `multiply`, передаётся в функцию `add` и т.д. Вернёмся к
предыдущей таблице и, прежде чем позволить циклу завершиться, вызовем `close` на
канале `done` и посмотрим, что произойдёт:

| Номер итерации | `generator` | `multiply` | `add`    | `multiply` | Результат        |
| -------------- | ----------- | ---------- | -------- | ---------- | ---------------- |
| 0              | 1           |            |          |            |                  |
| 0              |             | 1          |          |            |                  |
| 0              | 2           |            | 2        |            |                  |
| 0              |             | 2          |          | 3          |                  |
| 1              | 3           |            | 4        |            | 6                |
| `close(done)`  | (закрыт)    | 3          |          | 5          |                  |
|                |             | (закрыт)   | 6        |            |                  |
|                |             |            | (закрыт) | 7          |                  |
|                |             |            |          | (закрыт)   |                  |
|                |             |            |          |            | (выход из цикла) |

Видно, как закрытие канала `done` каскадно проходит по пайплайну. Это становится
возможным благодаря двум вещам на каждом этапе пайплайна:

- Перебор по входящему каналу. Когда входящий канал закрыт, перебор завершится.
- Отправка в канал разделяем одно `select`-выражение с каналом `done`.

Независимо от того, в каком состоянии находится этап пайплайна — в состоянии
ожидания на входящем канале или ожидания отправки — закрытие канала `done`
приведёт к принудительному завершению этапа пайплайна.

Здесь имеет место рекуррентное соотношение. В начале пайплайна мы установили,
что должны преобразовать дискретные значения в канал. В этом процессе есть два
момента, которые должны быть прерываемыми:

- Создание дискретного значения, которое не является мгновенным.
- Отправка дискретного значения по его каналу.

Первое зависит от нас. В нашем примере, в функции `generator`, дискретные
значения генерируются путём перебора по произвольному слайсу, который происходит
достаточно мгновенно и не требует прерывания. Второй пункт обрабатывается нашим
оператором `select` и каналом `done`, который гарантирует, что функция
`generator` может быть прервана, даже если она заблокирована при попытке записи
в `intStream`.

На другом конце пайплайна, конечный этап обеспечивается прерываемостью по
индукции. Он прерываем потому, что канал, по которому мы перебираем значения,
будет закрыт при прерывании, и, следовательно, наш перебор завершится, когда это
произойдёт. Конечный этап прерываем потому, что поток, от которого мы зависим,
является прерываемым.

Между началом и концом пайплайна код всегда перебирает канал и отправляет данные
по другому каналу в операторе `select`, этот оператор также содержит канал
`done`

Если этап заблокирован на получении значения из входного канала, он
разблокируется, когда этот канал будет закрыт. Мы знаем по индукции, что канал
будет закрыт потому, что это либо этап, написанный так же, как этот этап, внутри
которого мы находимся, либо начало пайплайна, который мы определили как
прерываемый. Если этап заблокирован на отправке значения, он прерываем благодаря
оператору `select`.

<!-- TODO: в этом абзаце в целом норм индукционная мысль, но "так же, как этот этап" вот здесь нужно уточнить или перефразировать -->

<!-- TODO: в целом вообще самому разобраться с этими индукционными размышлениями и что-то мб перефразировать -->

Таким образом, весь наш пайплайн всегда можно прервать закрытием канала `done`.
Круто!

#### Несколько удобных генераторов

Напомним, что генератор для пайплайна — это любая функция, которая преобразует
набор дискретных значений в поток значений на канале.

Взглянем на генератор под названием `repeat`:

```go
repeat := func(
  done <-chan interface{},
  values ...interface{}
) <-chan interface{} {
  valueStream := make(chan interface{})

  go func() {
    defer close(valueStream)

    for {
      for _, v := range values {
        select {
        case <-done:
          return
        case valueStream <- v:
        }
      }
    }
  }()

  return valueStream
}
```

Эта функция будет бесконечно повторять значения, которые мы ей передадим, пока
мы не скажем ей остановиться.

Рассмотрим другой общий этап пайплайна, который полезен при использовании в
сочетании с `repeat`, `take`:

```go
take := func(
  done <-chan interface{},
  valueStream <-chan interface{},
  num int,
) <-chan interface{} {
  takeStream := make(chan interface{})

  go func() {
    defer close(takeStream)

    for i := 0; i < num; i++ {
      select {
      case <-done:
        return
      case takeStream <- <-valueStream:
      }
    }
  }()

  return takeStream
}
```

Этот этап пайплайна будет извлекать только первые `num` элементов из входящего
канала `valueStream`, а затем завершать работу. Вместе они могут быть очень
мощными
([`code-samples/pipelines/generators/repeat-take.go`](code-samples/pipelines/generators/repeat-take.go)):

```go
done := make(chan interface{})
defer close(done)

for num := range take(done, repeat(done, 1), 10) {
  fmt.Printf("%d ", num)
}

fmt.Println()
```

Этот код произведёт:

```
1 1 1 1 1 1 1 1 1 1
```

В этом простом примере мы создаём `repeat`-генератор для генерации бесконечного
числа единиц, но затем берём только первые 10. Поскольку отправка значения в
`repeat`-генераторе блокирует получение на этапе `take`, `repeat`-генератор
очень эффективен. Хотя у нас есть возможность генерировать бесконечный поток
единиц, мы генерируем только $n + 1$ экземпляров, где $n$ — это число, которое
мы передаём на этап `take`.

Мы можем рассмотреть это подробнее. Создадим ещё один повторяющий генератор, но
на этот раз создадим такой, который повторно вызывает функцию. Назовём его
`repeatFn`
([`code-samples/pipelines/generators/repeat-fn.go`](code-samples/pipelines/generators/repeat-fn.go)):

```go
repeatFn := func(
  done <-chan interface{},
  fn func() interface{},
) <-chan interface{} {
  valueStream := make(chan interface{})

  go func() {
    defer close(valueStream)

    for {
      select {
      case <-done:
      return
      case valueStream <- fn():
      }
    }
  }()

  return valueStream
}
```

Используем этот генератор, чтобы сгенерировать 10 рандомных чисел:

```go
done := make(chan interface{})
defer close(done)

randFn := func() interface{} {
  return rand.Int()
}

for num := range take(done, repeatFn(done, randFn), 10) {
  fmt.Println(num)
}
```

Это произведёт что-то подобное:

```
5305141208658601736
6195187010991777015
6972756325307550674
8126717018566956418
5928375856424083536
8295798667179806995
492683986493178383
1807155695000307597
4986426348547186334
2220004159319114895
```

Отлично! Бесконечный канал рандомных чисел, генерируемых по необходимости!

> Мы могли бы с таким же успехом написать эти функции без использования
> `interface{}` и использовать явно заданный тип или даже придумать
> кодогенерацию для таких случаев.

Пустые интерфейсы немного табуированы в Go, но для этапов пайплайна кажется
нормальным работать с каналами типа `interface{}`, чтобы можно было использовать
стандартную библиотеку паттернов пайплайнов. Как мы обсуждали ранее, больша́я
часть полезности пайплайна исходит от повторно используемых этапов. Это лучше
всего достигается, когда этапы работают на уровне специфичности, соответствующем
самим себе. В генераторах `repeat` и `repeatFn` задача заключается в генерации
потока данных путём циклического перебора списка или оператора. На этапе `take`
задача заключается в ограничении (лимитировании) нашего пайплайна. Ни одна из
этих операций не требует информации о типах, с которыми она работает, а вместо
этого требует только знания [арности](https://ru.wikipedia.org/wiki/Арность) её
параметров.

Когда нужно иметь дело со специфичными типами, можно поместить в пайплайн этап,
который выполняет [type assertion](https://go.dev/tour/methods/15) за нас.
Накладные расходы (performance overhead), связанные с наличием дополнительного
этапа пайплайна (и, следовательно, горутины) и type assertion'а, как мы увидим
чуть позже, незначительны. Вот небольшой пример, который вводит этап пайплайна
`toString`
([`code-samples/pipelines/generators/to-string-stage.go`](code-samples/pipelines/generators/to-string-stage.go)):

```go
toString := func(
  done <-chan interface{},
  valueStream <-chan interface{},
) <-chan string {
  stringStream := make(chan string)

  go func() {
    defer close(stringStream)

    for v := range valueStream {
      select {
      case <-done:
        return
      case stringStream <- v.(string):
      }
    }
  }()

  return stringStream
}
```

И пример, как использовать этот этап:

```go
done := make(chan interface{})
defer close(done)

msg := ""
for token := range toString(done, take(done, repeat(done, "I", "am."), 5)) {
  msg += token
}

fmt.Printf("message: %s...\n", msg)
```

Этот код произведёт:

```
message: Iam.Iam.I...
```

Итак, давайте докажем самим себе, что затраты на генерирование частей нашего
пайплайна незначительны. Мы напишем две бенчмарк-функции: одну для тестирования
общих этапов, а вторую — для тестирования специфичных для типа этапов
([`code-samples/pipelines/generators/benchmark/pipelines_test.go`](code-samples/pipelines/generators/benchmark/pipelines_test.go)):

```go
func BenchmarkGeneric(b *testing.B) {
  done := make(chan interface{})
  defer close(done)

  b.ResetTimer()

  for range toString(done, take(done, repeat(done, "a"), b.N)) {
  }
}

func BenchmarkTyped(b *testing.B) {
  repeat := func(done <-chan interface{}, values ...string) <-chan string {
    valueStream := make(chan string)

    go func() {
      defer close(valueStream)

      for _, v := range values {
        select {
        case <-done:
          return
        case valueStream <- v:
        }
      }
    }()

    return valueStream
  }

  take := func(
    done <-chan interface{},
    valueStream <-chan string,
    num int,
  ) <-chan string {
    takeStream := make(chan string)

    go func() {
      defer close(takeStream)

      for i := num; i > 0 || i == -1; {
        if i != -1 {
          i--
        }

        select {
        case <-done:
          return
        case takeStream <- <-valueStream:
        }
      }
    }()

    return takeStream
  }

  done := make(chan interface{})
  defer close(done)

  b.ResetTimer()

  for range take(done, repeat(done, "a"), b.N) {
  }
}
```

Запустить эти бенчмарки можно следующей командой:

```bash
go test -bench=. -benchtime=1000000x -cpu=4 code-samples/pipelines/generators/benchmark/*.go
```

Следует ожидать подобные результаты:

```
goos: darwin
goarch: arm64
BenchmarkGeneric-4       1000000               637.5 ns/op
BenchmarkTyped-4         1000000               204.3 ns/op
PASS
ok      command-line-arguments  0.931s
```

Можно заметить, что этапы с явным типом, втрое быстрее, но лишь незначительно
быстрее по величине. В общем случае ограничивающим (limiting) фактором нашего
пайплайна будет либо наш генератор, либо один из этапов, требующий
вычислительных ресурсов. Если генератор не создаёт поток из памяти, как это
происходит в генераторах `repeat` и `repeatFn`, вероятно, мы будем ограничены
операциями ввода-вывода. То есть, всё равно, чтение с диска или через сеть,
скорее всего, превысит эти незначительные накладные расходы (performance
overhead).

<!-- TODO: как этом контексте лучше перевести magnitude? -->

Если один из наших этапов требует больших вычислительных затрат, это,
безусловно, затмит эти накладные расходы (performance overhead). Если всё равно
терять даже так мало в производительности не хочется, можно организовать
кодогенерацию.

### Разветвление и объединение (Fan-Out, Fan-In)

Представим, что мы настроили пайплайн. Данные отлично проходят через нашу
систему, трансформируются по мере прохождения этапов, которые мы соединили в
цепь. Это красивый поток, но он получился медленным. Почему он может занимать
так много времени?

Иногда этапы в нашем пайплайне могут быть особенно дорогостоящими с точки зрения
вычислений. Когда это происходит, вышестоящие (upstream) этапы в нашем пайплайне
могут блокироваться в ожидании завершения дорогостоящих этапов. Не только это,
но и выполнение самого пайплайна в целом может занять много времени. Как можно
решить эту проблему?

Одним из интересных свойств пайплайнов является возможность, которую они
предоставляют нам для работы с потоком данных, используя комбинацию отдельных,
часто переставляемых этапов. Мы можем многократно использовать этапы пайплайна.
Будет интересно попробовать переиспользовать конкретный один этап нашего
пайплайна в нескольких горутинах в попытке распараллелить (на самом деле просто
организовать конкурентное выполнение) запросы (pulls) с вышестоящего (upstream)
этапа. Возможно, это поможет улучшить производительность пайплайна.

На самом деле, оказывается, что такое возможно, и у этого паттерна есть
название: _fan-out, fan-in_ (_разветвление, объединение_)

Fan-out (разветвление) — это термин для описания процесса запуска нескольких
горутин для обработки входных данных пайплайна, а fan-in (объединение) — это
термин для описания процесса объединения нескольких результатов в один канал.

Итак, что же делает этап пайплайна подходящим для использования паттерна? Можно
рассмотреть возможность разветвления (fan-out) одного из наших этапов, если
применимы оба следующих утверждения:

- Он не полагается на значения, которые сам же этот этап вычислил ранее.
- Выполнение этого этапа занимает много времени.

Свойство независимости от порядка важно потому, что у нас нет гарантии, в каком
порядке будут выполняться конкурентные копии нашего этапа, и в каком порядке они
будут возвращать результат.

Взглянем на пример. Здесь использовать очень неэффективный способ поиска простых
чисел. Мы будем использовать множество этапов, созданных в разделе
[«Несколько удобных генераторов»](#несколько-удобных-генераторов)
([`code-samples/fan-out-fan-in/inefficient-primes/main.go`](code-samples/fan-out-fan-in/inefficient-primes/main.go)):

```go
randFn := func() interface{} {
  return rand.Intn(5_000_000_000)
}

done := make(chan interface{})
defer close(done)

randIntStream := stage.ToInt(done, stage.RepeatFn(done, randFn))

fmt.Println("Primes:")

start := time.Now()

for prime := range stage.TakeInt(done, stage.PrimeFinder(done, randIntStream), 10) {
  fmt.Printf("\t%d\n", prime)
}

fmt.Printf("Search took: %v\n", time.Since(start))
```

Результат выполнения этого кода:

```
Primes:
        3269281973
        3260034737
        4684901489
        4891926997
        2785052993
        4190313089
        4432837259
        3705865619
        4164671809
        1384483489
Search took: 30.518477959s
```

Мы генерируем поток случайных чисел, ограниченный `5_000_000_000`, преобразуем
поток в целочисленный, а затем передаём его на наш этап поиска простых чисел
`stage.PrimeFinder`. `stage.PrimeFinder` специально написан неэффективно — зато
это отличный пример этапа, занимающего _много_ времени.

В нашем цикле `for` мы перебираем найденные простые числа, выводим их в `stdout`
по мере поступления и, благодаря нашему этапу `stage.TakeInt`, закрываем
пайплайн после того, как найдено 10 простых чисел. Затем мы выводим в `stdout`,
сколько времени занял поиск, и `done`-канал закрывается с помощью выражения
`defer`, пайплайн перестаёт работать.

Чтобы избежать дублирования наших результатов, мы могли бы ввести ещё один этап
в наш пайплайн для кэширования простых чисел, которые были найдены в наборе, но
для простоты мы просто проигнорируем это.

Можно заметить, что для поиска десяти 10 простых чисел потребовалось примерно 30
секунд. Очень долго. Обычно в таком случае нужно критически посмотреть на наш
алгоритм поиска таких чисел и выявить в нём недостатки. Но цель данного этапа —
быть медленным. Вместо этого мы рассмотрим, как можно _разветвить_ (_fan-out_)
один или несколько этапов, чтобы быстрее выполнять медленные операции.

Это относительно простой пример, потому что у нас есть только два этапа:
генерация случайных чисел и просеивание простых чисел. В более крупной программе
наш пайплайн может состоять из гораздо большего количества этапов; как мы
узнаем, какой из них следует разветвить (fan-out)? Следует помнить наши
критерии: независимость от порядка и длительность выполнения. Наш генератор
случайных чисел, безусловно, не зависит от порядка, но его запуск не занимает
особенно много времени. Этап поиска простых чисел также не зависит от порядка —
числа либо простые, либо нет — и из-за нашего «тупого» алгоритма его выполнение
занимает много времени. Выглядит как хороший кандидат для разветвления (fanning
out).

К счастью, процесс разветвления (fanning out) этапа чрезвычайно прост. Всё, что
нам нужно сделать — это запустить несколько версий этого этапа. Поэтому вместо
этого:

```go
primeStream := primeFinder(done, randIntStream)
```

Мы можем сделать что-то вроде этого:

```go
numFinders := runtime.NumCPU()
finders := make([]<-chan int, numFinders)

for i := 0; i < numFinders; i++ {
  finders[i] = primeFinder(done, randIntStream)
}
```

Здесь мы запускаем столько копий этого этапа, скольку у нас CPU (на моём
компьютере их 8, в дальнейшем будем говорить об этом числе). В продакшене
следовало бы провести небольшое эмпирическое тестирование для определения
оптимального количества `numFinders`, но здесь мы сделаем просто предположим,
что CPU будет занят только копией этапа `findPrimes`.

И это всё! Теперь у нас восемь горутин, извлекающих данные из генератора
случайных чисел и пытающихся определить, является ли число простым. Генерация
случайных чисел не должна занимать много времени, и поэтому каждая горутина
этапа `findPrimes` должна быть в состоянии определить, является ли её число
простым, а затем немедленно получить доступ к другому случайному числу.

Однако всё ещё есть проблема: теперь, когда у нас есть восемь горутин, у нас
также есть восемь каналов, но наш перебор `range` ожидает только один канал. Это
приводит нас к _fan-in_ (объединяющей) части паттерна.

Как мы обсудили ранее, объединение (fanning in) означает _мультиплексирование_
или join нескольких потоков данных в один поток. Алгоритм для этого относительно
прост
([`code-samples/fan-out-fan-in/stage/stage.go`](code-samples/fan-out-fan-in/stage/stage.go)):

```go
// FanIn - Здесь мы принимаем наш стандартный done-канал, чтобы разрешить отмену
// наших горутин, а затем принимаем произвольный слайс типа interface{} для
// объединения (fan-in)
func FanIn(
  done <-chan interface{},
  channels ...<-chan interface{},
) <-chan interface{} {
  // Создаём sync.WaitGroup, чтобы мы могли дождаться, пока все каналы не будут
  // опустошены
  var wg sync.WaitGroup
  multiplexedStream := make(chan interface{})

  // Создаём функцию multiplex, которая при передаче канала будет считывать из
  // канала и передавать считанное значение в канал multiplexedStream
  multiplex := func(c <-chan interface{}) {
    defer wg.Done()

    for i := range c {
      select {
      case <-done:
        return
      case multiplexedStream <- i:
      }
    }
  }

  // Select из всех каналов.
  // Увеличиваем sync.WaitGroup на количество каналов, которые мы
  // мультиплексируем
  wg.Add(len(channels))
  for _, c := range channels {
    go multiplex(c)
  }

  // Ожидание завершения всех чтений.
  // Создаём горутину для ожидания, пока все каналы, которые мы
  // мультиплексируем, не будут опустошены, чтобы мы могли закрыть канал
  // multiplexedStream
  go func() {
    wg.Wait()
    close(multiplexedStream)
  }()

  return multiplexedStream
}
```

В двух словах, объединение (fanning in) включает в себя создание
мультиплексированного канала, с которого потребители будут считывать данные, а
затем запуск одной горутины для каждого входящего канала и одной горутины для
закрытия мультиплексированного канала, когда все входящие каналы будут закрыты.
Поскольку мы собираемся создать горутину, которая ожидает завершения $n$ других
горутин, имеет смысл создать `sync.WaitGroup` для координации действий. Функция
`multiplex` также уведомляет `sync.WaitGroup` о том, что работа завершена.

> **Дополнительное напоминание**
>
> Наивная реализация алгоритма fan-in, fan-out работает только в том случае,
> когда порядок, в котором поступают результаты, неважен. Мы ничего не сделали,
> чтобы гарантировать, что порядок, в котором элементы считываются из
> `randIntStream`, сохраняется при прохождении через «сито». Позже мы рассмотрим
> пример способа поддержания порядка.

Теперь объединим всё вместе и посмотрим, получим ли мы какое-либо сокращение
времени выполнения:

```go
randFn := func() interface{} {
  return rand.Intn(5_000_000_000)
}

done := make(chan interface{})
defer close(done)

randIntStream := stage.ToInt(done, stage.RepeatFn(done, randFn))

numFinders := runtime.NumCPU()

fmt.Printf("Spinning up %d prime finders.\n", numFinders)

finders := make([]<-chan int, numFinders)

fmt.Println("Primes:")
for i := 0; i < numFinders; i++ {
  finders[i] = stage.PrimeFinder(done, randIntStream)
}

start := time.Now()

for prime := range stage.TakeInt(done, stage.FanInInt(done, finders...), 10) {
  fmt.Printf("\t%d\n", prime)
}

fmt.Printf("Search took: %v\n", time.Since(start))
```

Результаты выполнения:

```
Spinning up 8 prime finders.
Primes:
        35497811
        88416457
        540747527
        1352798323
        1742810089
        2247303197
        1407857207
        1131157513
        221168177
        462010253
Search took: 3.977793459s
```

Время выполнения сократилось с ~30 секунд до ~4 секунд, очень неплохо! Мы смогли
сократить время выполнения программы в 7,5 раз без радикального изменения
структуры нашей программы.

### Канал or-done (The or-done-channel)

Иногда приходится работать с каналами из разрозненных частей нашей системы. В
отличие от пайплайнов, мы не сможем сделать никаких утверждений о том, как будет
вести себя канал, когда код, с которым мы работаем, отменяется через его канал
`done`. Другими словами, мы не знаем, означает ли отмена нашей горутины то, что
канал, из которого мы читаем, также будет отменён. По этой причине, как было
отмечено в [«Предотвращение утечек горутин»](#предотвращение-утечек-горутин),
нам нужно обернуть наше чтение из канала в оператор `select`, который также
выполняет чтение из канала `done`. Это совершенно нормально, но для этого
требуется код, который так же легко читается, как этот:

<!-- TODO: убедиться, что переведено правильно "Другими словами, мы не знаем,
означает ли отмена нашей горутины то, что канал, из которого мы читаем, также
будет отменён" -->

```go
for val := range myChan {
  // Что-то делаем с val
}
```

Но нужно, чтобы при всей этой удобочитаемости, под капотом этот код был как-то
расширен до такого:

```go
loop:
for {
  select {
  case <-done:
    break loop
  case maybeVal, ok := <-myChan:
    if !ok {
      return // или break из for
    }
    // Что-то делаем с val
  }
}
```

Это может быстро стать довольно запутанным, особенно если у нас есть вложенные
циклы. Продолжая тему использования горутин для написания более понятного
конкурентного кода, а не предварительной оптимизации, мы можем исправить это с
помощью одной горутины. Мы инкапсулируем избыточность, чтобы другим не
приходилось это делать:

```go
orDone := func(done, c <-chan interface{}) <-chan interface{} {
  valStream := make(chan interface{})

  go func() {
    defer close(valStream)

    for {
      select {
      case <-done:
        return
      case v, ok := <-c:
        if !ok {
          return
        }

        select {
        case valStream <- v:
        case <-done:
        }
      }
    }
  }()

  return valStream
}
```

Сделав так, мы можем вернуться к простым циклам `for`, например, так:

```go
for val := range orDone(done, myChan) {
  // Что-то делаем с val
}
```

В своём коде можно найти крайние случаи, когда нужен плотный цикл, использующий
серию операторов `select`, но сначала кажется более разумным для удобства чтения
избегать преждевременной оптимизации.

<!-- TODO: в книге нет примера по этому паттерну, придумать его и написать -->

### Канал-тройник (The tee-channel)

Иногда может потребоваться разделить значения, поступающие из канала, чтобы было
можно отправлять их в две разные области нашей кодовой базы. Представим канал
пользовательских команд: возможно, мы захотим принять поток пользовательских
команд по каналу, отправить их куда-то, где они выполнятся, а также отправить их
куда-то, где они залогируются для последующего аудита.

Tee-channel взял своё название от команды `tee` в Unix-like системах и выполняет
похожую функцию. Сюда можно передать канал для чтения, и этот код вернёт два
отдельных канала, которые будут получать одинаковые значения
([`code-samples/tee-channel/tee-channel.go`](code-samples/tee-channel/tee-channel.go)):

> Название _tee_ происходит от английского обозначения трубопроводного тройника,
> имеющего форму заглавной буквы T.
>
> ([Википедия, tee](https://ru.wikipedia.org/wiki/Tee)).

```go
tee := func(
  done <-chan interface{},
  in <-chan interface{},
) (<-chan interface{}, <-chan interface{}) {
  out1 := make(chan interface{})
  out2 := make(chan interface{})

  go func() {
    defer close(out1)
    defer close(out2)

    for val := range orDone(done, in) {
      // Нам нужны локальные копии out1 и out2, поэтому мы shadow'им
      // (затеняем) эти переменные
      out1, out2 := out1, out2

      // Мы собираемся использовать одно выражение select, чтобы записи в out1 и
      // out2 не блокировали друг друга. Чтобы убедиться, что запись выполняется
      // в оба, мы выполним две итерации с select: по одной для каждого
      // исходящего канала
      for i := 0; i < 2; i++ {
        select {
        case <-done:
        case out1 <- val:
          // Как только мы выполнили запись в канал, мы устанавливаем для его
          // теневой копии значение nil, чтобы дальнейшие записи были
          // заблокированы и другой канал мог продолжить работу
          out1 = nil
        case out2 <- val:
          out2 = nil
        }
      }
    }
  }()

  return out1, out2
}
```

<!-- TODO: разобраться в out1, out2 = nil, nil -->

Следует обратить внимание, что записи в `out1` и `out2` тесно связаны (tightly
coupled). Итерация по `in` не сможет продолжиться до тех пор, пока данные не
будут записаны как в `out1`, так и в `out2`. Обычно это не проблема, поскольку
управление пропускной способностью процесса чтения из каждого канала должно быть
заботой чего-то другого, кроме команды tee, но это стоит отметить. Небольшой
пример для демонстрации
([`code-samples/tee-channel/tee-channel.go`](code-samples/tee-channel/tee-channel.go)):

<!-- TODO: обычно это не проблема, поскольку управление пропускной способностью. Не понял, что имеется ввиду -->

```go
done := make(chan interface{})
defer close(done)

out1, out2 := tee(done, take(done, repeat(done, 1, 2), 4))

for val1 := range out1 {
  fmt.Printf("out1: %v, out2: %v\n", val1, <-out2)
}
```

Результат выполнения:

```
out1: 1, out2: 1
out1: 2, out2: 2
out1: 1, out2: 1
out1: 2, out2: 2
```

Используя этот паттерн, легко продолжать использовать каналы в качестве точек
соединения (join points) нашей системы.

### Канал-мост (The bridge-channel)

<!-- TODO: Перевод "Канал-мост" кажется неудачным -->

В некоторых обстоятельствах можно захотеть использовать значения из
последовательности каналов:

```go
<-chan <-chan interface{}
```

Это немного отличается от объединения слайса каналов в один канал, как мы видели
в разделе [«Канал с выбором (The or-channel)»](#канал-с-выбором-the-or-channel)
или в разделе
[«Разветвление и объединение (Fan-Out, Fan-In)»](#разветвление-и-объединение-fan-out-fan-in).
Последовательность каналов предполагает упорядоченную запись, хотя и из разных
источников. Одним из примеров может быть этап пайплайна, время жизни которого
прерывистое. Если мы будем следовать паттернам, которые установили в разделе
[«Изоляция (Confinement)»](#изоляция-confinement), и обеспечим, чтобы каналы
принадлежали горутинам, которые в них пишут, то каждый раз, когда этап пайплайна
перезапускается в рамках новой горутины, будет создаваться новый канал. Это
означает, что у нас фактически будет последовательность каналов. Мы подробнее
рассмотрим этот сценарий в разделе "Healing Unhealthy Goroutines".

<!-- TODO: ссылка на Healing Unhealthy Goroutines и норм перевод -->

<!-- TODO: не оч понятно, что написано, особенно про прерывистое время жизни -->

Как потребитель, код может не заботиться о том, что его значения поступают из
последовательности каналов. В этом случае работа с каналом каналов может быть
громоздкой. Если вместо этого мы определим функцию, которая может
деструктурировать канал каналов в простой канал — техника, называемая
соединением каналов (_bridging_ the channels), — потребителю будет намного проще
сфокусироваться на более насущной проблеме. Вот как мы можем этого добиться
([`code-samples/bridge-channel/bridge-channel.go`](code-samples/bridge-channel/bridge-channel.go)):

```go
bridge := func(
  done <-chan interface{},
  chanStream <-chan <-chan interface{},
) <-chan interface{} {
  // Это канал, который вернёт все значения из bridge
  valStream := make(chan interface{})

  go func() {
    defer close(valStream)

    // Этот цикл отвечает за извлечение каналов из chanStream и предоставление
    // их для использования во вложенном цикле
    for {
      var stream <-chan interface{}

      select {
      case maybeStream, ok := <-chanStream:
        if !ok {
          return
        }

        stream = maybeStream
      case <-done:
        return
      }

      // Этот вложенный цикл отвечает за считывание значений с заданного канала
      // и повторение этих значений в valStream. Когда поток, который мы в
      // данный момент перебираем, закрывается, мы выходим из этого вложенного
      // цикла, выполняя считывание из этого канала, и переходим к следующей
      // итерации цикла, выбирающего каналы для чтения. Это обеспечивает
      // непрерывный поток значений
      for val := range orDone(done, stream) {
        select {
        case valStream <- val:
        case <-done:
        }
      }
    }
  }()

  return valStream
}
```

Это довольно простой код. Теперь мы можем использовать `bridge`, чтобы помочь
представить одноканальный фасад поверх канала каналов. Вот пример, который
создаёт серию из 10 каналов, в каждый из которых записан один элемент, и
передаёт эти каналы в функцию `bridge`
([`code-samples/bridge-channel/bridge-channel.go`](code-samples/bridge-channel/bridge-channel.go)):

```go
genVals := func() <-chan <-chan interface{} {
  chanStream := make(chan (<-chan interface{}))

  go func() {
    defer close(chanStream)

    for i := 0; i < 10; i++ {
      stream := make(chan interface{}, 1)
      stream <- i
      close(stream)
      chanStream <- stream
    }
  }()

  return chanStream
}

for v := range bridge(nil, genVals()) {
  fmt.Printf("%v ", v)
}

fmt.Println()
```

Этот код произведёт:

```
0 1 2 3 4 5 6 7 8 9
```

Благодаря `bridge` мы можем использовать канал каналов в одном операторе `range`
и сосредоточиться на логике нашего цикла. Деструктурирование канала каналов
оставлено коду, специфичному для этой задачи.

### Очереди (Queuing)

Иногда бывает полезно начать приём работы для нашего пайплайна, даже если
пайплайн ещё не готов к большему количеству. Этот процесс называется постановкой
в очередь.

Всё это означает, что как только наш этап завершил какую-либо работу, он
сохраняет её во временном месте в памяти, чтобы другие этапы могли извлечь её
позже, и нашему этапу не нужно хранить ссылку на неё. В разделе
[«Каналы»](../building-blocks/README.md#каналы) мы обсуждали _буферизированные
каналы_, по факту, тип очереди, но с теъ пор мы ими практически не пользовались
— и на то есть веские причины.

Хотя введение системы очередей в нашу систему очень полезно, обычно это одна из
последних техник, которую мы хотим использовать для оптимизации нашей программы.
Преждевременное добавление очередей может скрыть проблемы синхронизации, такие
как deadlock'и и livelock'и, и в дальнейшем, по мере приближения нашей программы
к корректности, мы можем обнаружить, что нам требуется больше или меньше
очередей.

Итак, для чего нужна постановка в очередь? Начнём отвечать на этот вопрос с
рассмотрения одной из распространённых ошибок, которые люди совершают, пытаясь
настроить производительность системы: введение очередей для решения проблем с
производительностью. Постановка в очередь почти никогда не ускорит общее время
выполнения нашей программы; это только позволит программе вести себя по-другому.

Чтобы понять почему, взглянем на простой пайплайн:

```go
done := make(chan interface{})
defer close(done)

zeros := take(done, 3, repeat(done, 0))
short := sleep(done, 1*time.Second, zeros)
long := sleep(done, 4*time.Second, short)

pipeline := long
```

Этот пайплайн собирает в цепь четыре этапа:

1. Повторяющийся этап, который генерирует бесконечный поток нулей
2. Этап, который отменяет предыдущие этапы после просмотра трёх элементов
3. "Короткий" этап, который спит одну секунду
4. "Длинный" этап, который спит четыре секунды

Для целей этого примера давайте предположим, что этапы 1 и 2 выполняются
мгновенно, и сосредоточимся на том, как этапы, которые спят влияют на время
выполнения пайплайна.

Вот таблицы, в которой анализируются время $t$, итерация $i$ и сколько времени
осталось длинному и короткому этапу для перехода к их следующему значению:

| Время ($t$) | Итерация ($i$) | Длинный этап | Короткий этап  |
| ----------- | -------------- | ------------ | -------------- |
| 0           | 0              |              | 1s             |
| 1           | 0              | 4s           | 1s             |
| 2           | 0              | 3s           | (заблокирован) |
| 3           | 0              | 2s           | (заблокирован) |
| 4           | 0              | 1s           | (заблокирован) |
| 5           | 1              | 4s           | 1s             |
| 6           | 1              | 3s           | (заблокирован) |
| 7           | 1              | 2s           | (заблокирован) |
| 8           | 1              | 1s           | (заблокирован) |
| 9           | 2              | 4s           | (закрыт)       |
| 10          | 2              | 3s           |                |
| 11          | 2              | 2s           |                |
| 12          | 2              | 1s           |                |
| 13          | 3              | (закрыт)     |                |

Можно видеть, что работа пайплайна занимает примерно 13 секунд. Завершение
короткого этапа занимает около 9 секунд.

Что произойдёт, если мы изменим пайплайн, включив в него буфер? Рассмотрим тот
же пайплайн с буфером из 2-х, введённым между длинным и коротким этапами:

```go
done := make(chan interface{})
defer close(done)

zeros := take(done, 3, repeat(done, 0))
short := sleep(done, 1*time.Second, zeros)
buffer := buffer(done, 2, short) // Буферизирует отправку из short на 2 элемента
long := sleep(done, 4*time.Second, short)

pipeline := long
```

Время выполнения:

| Время ($t$) | Итерация ($i$) | Длинный этап | Буфер | Короткий этап |
| ----------- | -------------- | ------------ | ----- | ------------- |
| 0           | 0              |              | 0/2   | 1s            |
| 1           | 0              | 4s           | 0/2   | 1s            |
| 2           | 0              | 3s           | 1/2   | 1s            |
| 3           | 0              | 2s           | 2/2   | (закрыт)      |
| 4           | 0              | 1s           | 2/2   |               |
| 5           | 1              | 4s           | 1/2   |               |
| 6           | 1              | 3s           | 1/2   |               |
| 7           | 1              | 2s           | 1/2   |               |
| 8           | 1              | 1s           | 1/2   |               |
| 9           | 2              | 4s           | 0/2   |               |
| 10          | 2              | 3s           | 0/2   |               |
| 11          | 2              | 2s           | 0/2   |               |
| 12          | 2              | 1s           | 0/2   |               |
| 13          | 3              | (закрыт)     |       |               |

Весь пайплайн по-прежнему занимает 13 секунд. Однако короткий этап завершён
всего за 3 секунды, в отличие от 9 секунд, которые требовались ранее. Мы
сократили время выполнение этого этапа на две трети! Но если выполнение всего
пайплайна по-прежнему занимает 13 секунд, как это нам поможет?

Представьте вместо этого следующий пайплайн:

```go
p := processRequest(done, acceptConnection(done, httpHandler))
```

Здесь пайплайн не завершается до тех пор, пока он не будет отменён, и этап,
принимающий соединения, не прекращает принимать соединения до тех пор, пока
пайплайн не будет отменён. В этом случае мы бы не хотели, чтобы ожидания
соединений к нашей программе таймаутили из-за того, что наш этап
`processRequest` вызывал бы блокировку этапа `acceptConnection`. Мы хотим, чтобы
этап `acceptConnection` был разблокирован настолько, насколько это возможно. В
противном случае пользователи нашей программы могут начать замечать, что их
запросы вообще отклоняются.

Таким образом, ответ на наш вопрос о полезности введения очереди заключается не
в том, что так мы сократим время выполнения одного из этапов, а скорее в том,
что так мы сократим время его нахождения в состоянии блокировки. Это позволяет
этапу продолжать свою работу. В этом примере, пользователи, скорее всего, будут
испытывать задержку в своих запросах, но им не будет отказано в обслуживании
полностью.

Истинная полезность очередей заключается в _разделении этапов_ (_decouple
stages_) таким образом, чтобы время выполнения одного этапа не влияло на время
выполнения другого. Разделение этапов таким образом затем приводит к каскадному
изменению поведения времени выполнения (рантайма) системы в целом, что может
быть хорошо или плохо в зависимости от нашей системы.

Мы переходим к вопросу настройки нашей системы постановки в очередь. Где должны
размещаться очереди? Каким должен быть размер буфера? Ответы на эти вопросы
зависят от характера нашего пайплайна.

Начнём с анализа ситуаций, в которых организация очередей может повысить общую
производительность нашей системы. Единственными применимыми ситуациями являются:

- Если пакетная обработка (batching) запросов на этапе экономит время
- Если задержки на каком-то этапе приводят к возникновению
  [циклического процесса обратной связи](<https://ru.wikipedia.org/wiki/Обратная_связь_(техника)>)
  ([feedback loop](https://en.wikipedia.org/wiki/Feedback)) в системе.

Одним из примеров первой ситуации является этап, который буферизирует ввод во
что-то более быстрое (например, в память), чем это нам надо для отправки. В
этом, конечно же, и заключается вся цель пакета `bufio` в Go. Вот пример,
демонстрирующий простое сравнение буферизированной записи в очередь с
небуферизированной записью
([`code-samples/queuing/queuing_test.go`](code-samples/queuing/queuing_test.go)):

```go
func BenchmarkUnbufferedWrite(b *testing.B) {
  performWrite(b, tmpFileOrFatal())
}

func BenchmarkBufferedWrite(b *testing.B) {
  bufferedFile := bufio.NewWriter(tmpFileOrFatal())
  performWrite(b, bufio.NewWriter(bufferedFile))
}

func tmpFileOrFatal() *os.File {
  file, err := os.CreateTemp("", "tmp")
  if err != nil {
    log.Fatalf("error: %v", err)
  }

  return file
}

func performWrite(b *testing.B, writer io.Writer) {
  done := make(chan interface{})
  defer close(done)

  b.ResetTimer()

  for bt := range take(done, repeat(done, byte(0)), b.N) {
    _, err := writer.Write([]byte{bt.(byte)})
    if err != nil {
      log.Fatalf("error: %v", err)
    }
  }
}
```

Запустить эти бенчмарки можно следующей командой:

```bash
go test -bench=. -benchtime=1000000x -cpu=8 code-samples/queuing/queuing_test.go
```

Результаты бенчмарков:

```
goos: darwin
goarch: arm64
BenchmarkUnbufferedWrite-8       1000000              2341 ns/op
BenchmarkBufferedWrite-8         1000000               436.2 ns/op
PASS
ok      command-line-arguments  3.623s
```

Как и ожидалось, запись с буферизацией выполняется быстрее, чем запись без
буферизации. Это связано с тем, что внутри `bufio.Writer` записи _помещаются в
очередь_ внутри буфера до тех пор, пока не будет накоплен чанк (chunk)
достаточного размера, а затем этот чанк уже записывается куда надо. Этот процесс
часто называют _чанкингом_ (_chunking_) по очевидным причинам.

Чанкинг быстрее, потому что `bytes.Buffer` должен увеличить объём своей
выделенной (аллоцированной) памяти, чтобы вместить байты, которые он должен
хранить. По разным причинам увеличение объёма памяти обходится дорого;
следовательно, чем меньше раз нам приходится увеличивать объём, тем эффективнее
будет работать наша система в целом. Таким образом, организация очереди повысила
производительность нашей системы в целом.

<!-- TODO: при чём тут bytes.Buffer -->

Это всего лишь простой пример чанкинга в памяти, но мы можем часто столкнуться с
чанкингом в реальных условиях. Обычно всегда, когда выполнение операции требует
дополнительных затрат, чанкинг может повысить производительность системы.
Некоторыми примерами этого являются открытие транзакций баз данных, вычисление
контрольных сумм сообщений и выделение (аллокация) непрерывного пространства.

Помимо чанкинга, постановка в очередь также может помочь, если наш алгоритм
можно оптимизировать, добавив предпросмотры или упорядочивания.

Второй сценарий, когда задержка на этапе приводит к большему вводу в пайплайн,
немного сложнее обнаружить, но при этом он более важен, поскольку он может
привести к системному коллапсу (collapse) наших вышестоящих (upstream) систем.

Эту идею часто называют
[_отрицательной циклической обратной связью_](https://ru.wikipedia.org/wiki/Отрицательная_обратная_связь)
([_negative feedback loop_](https://en.wikipedia.org/wiki/Negative_feedback)),
нисходящей спиралью (downward-spiral) или даже смертельной спиралью (штопором,
death-spiral). Это связно с тем, что между пайплайном и его вышестоящими
(upstream) системами существует рекуррентное соотношение; скорость, с которой
вышестоящие (upstream) этапы или системы отправляют новые запросы, каким-то
образом связана с тем, насколько пайплайн эффективен.

Если эффективность пайплайна падает ниже определённого критического порога,
вышестоящие системы (upstream) начинают увеличивать свои входные данные в
пайплайны, что приводит к тому, что пайплайн теряет бо́льшую эффективность, и
начинается смертельная спираль. Без какой-либо защиты от сбоев система,
использующая пайплайн, никогда не восстановится.

Вводя очередь на входе в пайплайн, мы можем разорвать циклическую обратную связь
за счёт создания задержки (lag) для запросов. С точки зрения вызывающего
пайплайн, запрос обрабатывается, но занимает очень много времени. Пока у
вызывающего не произойдёт таймаут, наш пайплайн будет оставаться стабильным.
Если у вызывающего произойдёт таймаут, мы должны быть уверены, что поддерживаем
какую-либо проверку готовности при удалении из очереди (dequeuing). Если мы
этого не сделаем, мы можем непреднамеренно создать циклическую обратную связь,
обрабатывания умершие запросы, тем самым снижая эффективность нашего пайплайна.

> **Были ли мы когда-нибудь свидетелем смертельной спирали?**
>
> Если вы когда-нибудь пытались получить доступ к какой-либо новой системе,
> когда она только появилась онлайн (например, к новым игровым серверам,
> веб-сайтам для запуска новых продуктов и т.д.), и сайт продолжал отказывать в
> доступе, то скорее всего, тогда вы стали свидетелями отрицательной циклической
> обратной связи!
>
> Неизменно команда разработчиков пробует разные варианты, пока кто-то не
> понимает, что им нужна очередь, и она в спешке внедряется.
>
> Затем клиента начинают жаловаться на время ожидания в очереди.

Итак, из наших примеров мы можем видеть, что возникает закономерность,
организация очередей должна быть реализована:

- Либо на входе нашего пайплайна
- Либо на этапах, где пакетная обработка (batching) приведёт к повышению
  производительности.

У нас может возникнуть соблазн добавить очередь в другом месте — например, после
этапа, требующего больших вычислительных затрат, — но следует избегать этого
соблазна! Как мы узнали, существует только несколько ситуаций, когда постановка
в очередь сокращает время выполнения нашего пайплайна, и использование очередей
в попытке найти такую ситуацию, рассредотачивая очереди, может привести к
катастрофическим последствиям.

Поначалу это не интуитивно понятно: чтобы понять почему, мы должны обсудить
пропускную способность пайплайна. Это не так уж сложно, и это также поможет нам
ответить на вопрос о том, как определить, насколько большими должны быть наши
очереди.

В
[теории массового обслуживания](https://ru.wikipedia.org/wiki/Теория_массового_обслуживания)
([Queueing theory](https://en.wikipedia.org/wiki/Queueing_theory)) существует
закон, который при достаточной выборке предсказывает пропускную способность
нашего пайплайна. Это называется
[Законом Литтла](https://ru.wikipedia.org/wiki/Закон_Литтла)
([Little's law](https://en.wikipedia.org/wiki/Little's_law)), и нам нужно знать
всего несколько вещей, чтобы понять и использовать его.

<!-- TODO: Queueing и queuing — одно и то же вроде, надо убедиться и прийти к одному стилю -->

<!-- TODO: всё это время "Теория массового обслуживания в этом разделе так и
напрашивалась в перевод -->

Давайте сначала определим Закон Литтла алгебраически. Обычно он выражается
следующим образом: $L = \lambda \cdot W$, где:

- $L$ — среднее количество юнитов (элементов) в системе
- $\lambda$ — средняя скорость поступления юнитов
- $W$ — среднее время, которое юнит проводит в системе

Это уравнение применимо только к так называемым _стационарным_ (_стабильным_,
_stable_) системам. В пайплайне стационарная система — это система, в которой
скорость поступления работы в пайплайн, или _входа_ (_ingress_), равна скорости
её _выхода_ (_egress_) из системы. Если скорость _ingress_ превышает _egress_,
наша система _нестационарна_ и вошла в _смертельную спираль_. Если скорость
_ingress_ меньше скорости _egress_, у нас всё ещё нестационарная система, но
всё, что происходит, — это то, что наши ресурсы используются не полностью. Не
самая худшая ситуация в мире, но, возможно, это нас волнует, если
недоиспользование наблюдается в огромных масштабах (например, в кластерах или
дата-центрах).

Давайте предположим, что наш пайплайн стационарен. Если мы хотим уменьшить $W$
(среднее время, которое юнит проводит в системе) в $n$ раз, у нас есть только
один вариант: уменьшить среднее количество юнитов в системе
$\dfrac{L}{n} = \lambda \cdot \dfrac{W}{n}$. И мы можем уменьшить среднее
количество юнитов в системе только в том случае, если увеличим скорость egress
(выхода). Также следует обратить внимание, что если мы добавляем очереди к нашим
этапам, мы увеличиваем $L$, что либо увеличивает скорость поступления юнитов
($nL = n\lambda \cdot W$), либо увеличивает среднее время, которое юнит проводит
в системе ($nL = \lambda \cdot nW$). С помощью Закона Литтла мы доказали, что
постановка в очередь не поможет уменьшить количество времени, проводимого в
системе.

Также следует обратить внимание, что, поскольку мы наблюдаем наш пайплайн в
целом, уменьшение $W$ в $n$ раз распределяется по всем этапам нашего пайплайна.
В нашем случае Закон Литтла действительно должен быть определён следующим
образом:

$$L = \lambda \cdot \sum_{i} W_i$$

Это ещё один способ сказать, что скорость нашего пайплайна будет настолько
быстро, насколько быстро работает самый медленный этап. Оптимизируйте без
разбора (без дискриминации, indiscriminately)!

Итак, Закон Литтла точен! Это простое уравнение открывает всевозможные способы
анализа нашего пайплайна. Воспользуемся им, чтобы задать несколько интересных
вопросов. В ходе нашего анализа предположим, что наш пайплайн состоит из трёх
этапов.

Попробуем определить, сколько запросов в секунду может обрабатывать наш
пайплайн. Давайте предположим, что мы сделали выборку в нашем пайплайне и
обнаружили, что 1 запрос проходит через пайплайн примерно за 1 секунду. Введём
эти цифры!

$$3 ~ запрос = \lambda \cdot \frac{запрос}{секунда} \cdot 1 ~ секунда$$

$$3 \cdot\frac{запрос}{секунда} = \lambda \cdot \frac{запрос}{секунда}$$

$$\lambda \cdot \frac{запрос}{секунда} = 3 \cdot \frac{запрос}{секунда}$$

Мы устанавливаем значение $L$ равным $3$, потому что каждый этап в нашей
пайплайне обрабатывает запрос. Затем мы устанавливаем значение $W$ равным $1$
секунде, проводим небольшую алгебру и вуаля! В нашем пайплайне мы можем
обрабатывать три запроса в секунду.

Как насчёт определения того, насколько большой должна быть наша очередь, чтобы
обрабатывать желаемое количество запросов. Может ли Закон Литтла помочь нам
ответить на этот вопрос?

Допустим, наша выборка показывает что обработка запроса занимает $1$ мс. Какого
размера должна быть наша очередь, чтобы обрабатывать $100 000$ запросов в
секунду? И снова давайте введём эти цифры!

$$L ~ запрос - 3 ~ запрос = 100~000 \cdot \frac{запрос}{секунда} \cdot 0.001 \cdot секунда$$

$$L ~ запрос - 3 ~ запрос = 100 \cdot ~ запрос$$

$$L ~ запрос = 103 \cdot ~ запрос$$

<!-- TODO: похоже r — это размерность и s — размерность, реквесты и секунды соответственно. Уже поменял, но надо посмотреть, не просочилось ли ещё куда-то. -->

<!-- TODO: в книге какая-то беда с математикой, неверно похоже перенесены -3r направо
и 1 мс = 0,001 сек или 0,0001 сек? -->

Опять же, наш пайплайн состоит из трёх этапов, поэтому мы уменьшаем $L$ на $3$.
Устанавливаем $\lambda$ равным $100~000 \cdot \dfrac{запрос}{секунда}$ и
обнаруживаем, что если мы хотим обработать такое количество запросов,
вместимость нашей очереди должна составлять $103$. Помните, что по мере
увеличения размера очереди нашей работе требуется больше времени, чтобы пройти
через систему! Мы эффективно обмениваем задержку на использование системы.

<!-- TODO: исходя из предыдущего TODO, 103 или 7? -->

<!-- TODO: норм ли перевёл? "You’re effectively trading system utilization for lag." -->

Что-то, о чём Закон Литтла не может дать представление, — это обработка ошибок.
Следует иметь виду, что если по какой-то причине наш пайплайн запаникует
(panic), мы потеряем все запросы в очереди. Возможно, это то, с чем стоит быть
осторожным, если повторное создание запросов затруднено или не произойдёт. Чтобы
смягчить это, можно либо придерживаться размера очереди, равного нулю, либо
перейти к _постоянной очереди_ (_persistent queue_), которая просто является
очередью, которая где-то сохраняется и которую можно будет прочитать, если
возникнет необходимость.

Организация очередей может быть полезна в системе, но из-за её сложности обычно
это одна из последних оптимизаций, которая предлагается к реализации.

### Пакет `context`

Как мы уже заметили, в конкурентных программах часто бывает необходимо
прекращать операции в связи с таймаутами, отменой (cancellation) или сбоя другой
части системы. Мы рассмотрели идиому создания канала `done`, который проходит
через нашу программу и отменяет все блокирующие конкурентные операции. Это
работает хорошо, но в то же время имеет некоторые ограничения.

Было бы полезно, если бы могли сообщить дополнительную информацию наряду с
простым уведомлением об отмене: почему произошла отмена (cancellation) или есть
ли у нашей функции дедлайн, к которому она должна быть завершена.

Оказывается, необходимость обернуть готовый канал этой информацией очень
распространена в системах любого размера, и поэтому авторы Go решили создать
стандартный паттерн для этого. Это начиналось как эксперимент, который
существовал за рамками стандартной библиотеки, но в Go 1.7 пакет `context` был
перенесён в стандартную библиотеку, что сделало это стандартной идиомой Go,
которую следует иметь ввиду при работе с конкурентным кодом.

Если мы заглянем в пакет `context`, то увидим, что это очень просто:

```go
var Canceled = errors.New("context canceled")
var DeadlineExceeded error = deadlineExceededError{}

type CancelFunc func()
type Context interface {...}

func Background() Context {...}
func TODO() Context {...}
func WithCancel(parent Context) (ctx Context, cancel CancelFunc) {...}
func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {...}
func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) {
  ...
}
func WithValue(parent Context, key, val any) Context {...}
```

Мы вернёмся к этим типам и функциями, но сейчас сосредоточимся на типе
`Context`. Это тип, который будет проходить через всю нашу систему во многом так
же, как это делает канал `done`. Если мы используем пакет `context`, каждая
нижестоящая относительно нашего верхнеуровневого конкурентного вызова функция
(downstream) функция, будет принимать `Context` в качестве своего первого
аргумента. Тип выглядит следующим образом:

```go
type Context interface {
  // Deadline returns the time when work done on behalf of this context should
  // be canceled. Deadline returns ok==false when no deadline is set. Successive
  // calls to Deadline return the same results.
  Deadline() (deadline time.Time, ok bool)

  // Done returns a channel that's closed when work done on behalf of this
  // context should be canceled. Done may return nil if this context can never
  // be canceled. Successive calls to Done return the same value.
  Done() <-chan struct{}

  // If Done is not yet closed, Err returns nil.
  // If Done is closed, Err returns a non-nil error explaining why:
  // Canceled if the context was canceled or DeadlineExceeded if the context's
  // deadline passed.
  // After Err returns a non-nil error, successive calls to Err return the same
  // error.
  Err() error

  // Value returns the value associated with this context for key, or nil if no
  // value is associated with key. Successive calls to Value with the same key
  // returns the same result.
  Value(key any) any
}
```

Это также выглядит довольно просто. Есть метод `Done`, который возвращает канал,
который закрывается, когда наша функция должна быть прервана. Есть также
несколько новых, но понятных методов: метод `Deadline` для указания, будет ли
горутина отменена после определённого времени, и метод `Err`, который вернёт
ненулевое значение (значение, которое `!= nil`), если горутина была отменена. Но
метод `Value` выглядит немного неуместным. Для чего он нужен?

Авторы Go заметили, что одним из основных мест применений горутин были
программы, обслуживающие запросы. Обычно в этих программах необходимо передавать
специфичную для запроса информацию вместе с информацией о том, нужно ли
прекратить работу. Это цель функции `Value`. Чуть позже мы обсудим это
подборнее, но сейчас сейчас нужно знать лишь то, что пакет `context` служит двум
основным целям:

- Предоставить API для отмены (canceling) веток нашего графа вызовов
  (call-graph)
- Предоставить контейнер (data-bag) для транспортировки специфичных для запроса
  (request-scoped) данных через весь наш граф вызовов

Сосредоточимся на первом аспекте: отмена (cancellation).

Как мы узнали из раздела
[«Предотвращение утечек горутин»](#предотвращение-утечек-горутин), отмена
(cancellation) в функции имеет три аспекта:

- Родитель горутины может захотеть отменить горутину
- Горутина может захотеть отменить свои дочерние горутины
- Любые блокирующие операции внутри горутины должны быть прерываемыми, чтобы их
  можно было отменить.

Пакет `context` помогает управлять всеми тремя из них.

Как мы упоминали, тип `Context` будет первым аргументом в нашей функции. Если мы
посмотрим на методы в интерфейсе контекста, то увидим, что там нет ничего, что
могло бы изменить (mutate) состояние базовой структуры. Кроме того, нет ничего,
что позволяло бы функции, принимающей контекст, отменить его. Это защищает
функции в стеке вызовов от дочерних функций, отменяющих контекст. В сочетании с
методом `Done`, который предоставляет канал `done`, это позволяет типу `Context`
безопасно управлять отменой (cancellation) из его предшественников.

<!-- TODO: защищает от дочерних, это точно? -->

В связи с этим возникает вопрос: если `Context` неизменяем (immutable), как мы
можем повлиять на поведение отмен (cancellations) в функциях ниже текущей
функции в стеке вызовов?

Здесь становятся важными функции в пакете `context`. Взглянем на некоторые из
них ещё раз:

```go
func WithCancel(parent Context) (ctx Context, cancel CancelFunc) {...}
func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {...}
func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) {
  ...
}
```

Следует обратить внимание, что все эти функции принимают `Context` и также
возвращают его. Некоторые из них также принимают другие аргументы, такие как
`deadline` и `timeout`. Все эти функции генерируют новые инстансы `Context` с
параметрами, относящимися к этим функциями.

`WithCancel` возвращает новый `Context`, который закрывает свой канал `done` при
вызове возвращаемой функции `cancel`. `WithDeadline` возвращает новый `Context`,
который закрывает свой канал `done`, когда часы машины превышают заданный
`deadline`. `WithTimeout` возвращает новый контекст, который закрывает свой
канал `done` по истечении заданного времени `timeout`.

Если нашей функции необходимо каким-либо образом отменить функции, расположенные
ниже неё в графе вызовов (call-graph), она вызовет одну из этих функций и
передаст `Context`, который был передан ей, а затем передаст возвращённый
контекст своим дочерним элементам. Если нашей функции не нужно изменять
поведение отмены (cancellation), функция просто передаст далее тот же контекст,
который был передан ей.

Таким образом, последовательные слои графа вызовов (call-graph) могут создавать
`Context`, соответствующий их потребностям, не затрагивая родителей. Это
обеспечивает очень удобное и элегантное решение для управления ветвями нашего
графа вызовов (call-graph).

В этом духе, инстансы `Context` предназначены для прохождения через граф вызовов
(call-graph) нашей программы. В объектно-ориентированной парадигме принято
хранить ссылки на часто используемые данные в качестве переменных-членов, но
важно _не_ делать этого с инстансами `context.Context`. Инстансы
`context.Context` могут выглядеть эквивалентными снаружи, но внутренне они могут
меняться в каждом фрейме стека (stack-frame). По этой причине важно всегда
передавать экземпляры `Context` в наши функции по значению. Таким образом,
функции имеют `Context` предназначенный для них, а не контекст, предназначенный
для фрейма стека $n$ уровней вверх по стеку.

<!-- TODO: переменных-членов? -->

<!-- TODO: вверх по стеку? -->

В верхней части нашего асинхронного графа вызовов нашему коду, вероятно, не был
передан `Context`. Чтобы начать цепочку, пакет `context` предоставляет нам две
функции для создания пустых экземпляров контекста:

```go
func Background() Context
func TODO() Context
```

`Background` просто возвращает пустой `Context`. `TODO` не предназначен для
использования на продакшене, но также возвращает пустой контекст; Предполагаемое
назначение `TODO` — служить плейсхолдером в тех случаях, когда мы не знаем,
какой `Context` использовать, или мы ожидаем, что нашему коду будет предоставлен
`Context`, но вышестоящий (upstream) код ещё не предоставил его.

Итак, давайте применим всё это. Рассмотрим пример, в котором используется
паттерн `done`-канала, и посмотрим, какие преимущества мы могли бы получить от
перехода к использованию пакета `context`. Вот программа, которая конкурентно
печатает приветствие и прощание
([`code-samples/context-package/basic/greeting-and-farewell.go`](code-samples/context-package/basic/greeting-and-farewell.go)):

```go
func main() {
  var wg sync.WaitGroup

  done := make(chan interface{})
  defer close(done)

  wg.Add(1)
  go func() {
    defer wg.Done()

    if err := printGreeting(done); err != nil {
      fmt.Printf("%v", err)
    }
  }()

  wg.Add(1)
  go func() {
    defer wg.Done()

    if err := printFarewell(done); err != nil {
      fmt.Printf("%v", err)
    }
  }()

  wg.Wait()
}

func printGreeting(done <-chan interface{}) error {
  greeting, err := genGreeting(done)
  if err != nil {
    return err
  }

  fmt.Printf("%s, мир!\n", greeting)

  return nil
}

func printFarewell(done <-chan interface{}) error {
  farewell, err := genFarewell(done)
  if err != nil {
    return err
  }

  fmt.Printf("%s, мир!\n", farewell)

  return nil
}

func genGreeting(done <-chan interface{}) (string, error) {
  switch locale, err := locale(done); {
  case err != nil:
    return "", err
  case locale == "RU/RU":
    return "Привет", nil
  }

  return "", errors.New("unsupported locale")
}

func genFarewell(done <-chan interface{}) (string, error) {
  switch locale, err := locale(done); {
  case err != nil:
    return "", err
  case locale == "RU/RU":
    return "Пока", nil
  }

  return "", errors.New("unsupported locale")
}

func locale(done <-chan interface{}) (string, error) {
  select {
  case <-done:
    return "", errors.New("canceled")
  case <-time.After(1 * time.Minute):
  }

  return "RU/RU", nil
}
```

Приблизительно через минуту этот код произведёт:

```
Привет, мир!
Пока, мир!
```

Игнорируя состояние гонки (мы могли бы получить прощание после приветствия), мы
видим, что у нас есть две ветви нашей программы, работающие конкурентно. Мы
настроили стандартный метод отмены, создав канал `done` и передав его вниз по
нашему графу вызовов (call-graph). Если мы закроем канал `done` в любой точке в
`main`, обе ветви будут отменены.

Введя горутины в `main`, мы открыли возможность управлять этой программной
несколькими различными и интересными способами. Возможно, мы хотим, чтобы
ожидание `genGreeting` таймаутило, если она выполняется долго. Возможно мы не
хотим, чтобы `genFarewell` вызывал `locale`, если мы знаем, что его родительская
функция скоро будет отменена. В каждом фрейме стека (stack-frame) функция может
влиять на весь стек вызовов под ней.

Используя паттерн канала `done`, мы могли бы добиться этого, обернув входящий
канал `done` в другие каналы `done` и затем сделать `return`, если какой-либо из
них сработает, но у нас не было бы дополнительной информации о дедлайнах и
ошибках, которую даёт нам `Context`.

Чтобы упростить сравнение паттерна канала `done` с использованием пакета
`context`, представим эту программу в виде дерева. Каждый узел в дереве
представляет собой вызов функции.

![Стек вызовов](images/call-graph-basic.svg)

<!-- TODO: на оригинальной диаграмме нет farewell -->

Изменим нашу программу, чтобы она использовала пакет `context` вместо канала
`done`. Поскольку теперь у нас есть гибкость `context.Context`, мы можем ввести
забавный сценарий.

Предположим, что `genGreeting` хочет подождать всего одну секунду, прежде чем
прервать вызов `locale` — таймаут в одну секунду. Мы также хотим встроить
некоторую умную логику в `main`. Если `printGreeting` завершится неудачно, мы
также хотим отменить вызов `printFarewell`. В конце концов, было бы бессмысленно
прощаться, перед этим не поздоровавшись!

Реализация этого с пакетом `context` тривиальна
([`code-samples/context-package/contexted/greeting-and-farewell.go](code-samples/context-package/contexted/greeting-and-farewell.go)):

```go
func main() {
  var wg sync.WaitGroup

  // Здесь main создаёт новый Context через context.Background и заворачивает
  // его в context.WithCancel, чтобы предоставить возможность отмен
  // (cancellations)
  ctx, cancel := context.WithCancel(context.Background()) // (1)
  defer cancel()

  wg.Add(1)
  go func() {
    defer wg.Done()

    if err := printGreeting(ctx); err != nil {
      fmt.Printf("cannot print greeting: %v\n", err)

      // Эта строчка спровоцирует то, что main отменит Context, если из
      // printGreeting вернётся ошибка
      cancel() // (2)
    }
  }()

  wg.Add(1)
  go func() {
    defer wg.Done()

    if err := printFarewell(ctx); err != nil {
      fmt.Printf("cannot print farewell: %v\n", err)
    }
  }()

  wg.Wait()
}

func printGreeting(ctx context.Context) error {
  greeting, err := genGreeting(ctx)
  if err != nil {
    return err
  }

  fmt.Printf("%s, мир!\n", greeting)

  return nil
}

func printFarewell(ctx context.Context) error {
  farewell, err := genFarewell(ctx)
  if err != nil {
    return err
  }

  fmt.Printf("%s, мир!\n", farewell)

  return nil
}

func genGreeting(ctx context.Context) (string, error) {
  // Здесь genGreeting заворачивает свой Context через context.WithTimeout. Это
  // автоматически отменит возвращаемый Context через 1 секунду, тем самым
  // отменив все дочерние элементы, куда этот возвращаемый Context будет
  // передан, а именно locale
  ctx, cancel := context.WithTimeout(ctx, 1*time.Second) // (3)
  defer cancel()

  switch locale, err := locale(ctx); {
  case err != nil:
    return "", err
  case locale == "RU/RU":
    return "Привет", nil
  }

  return "", errors.New("unsupported locale")
}

func genFarewell(ctx context.Context) (string, error) {
  switch locale, err := locale(ctx); {
  case err != nil:
    return "", err
  case locale == "RU/RU":
    return "Пока", nil
  }

  return "", errors.New("unsupported locale")
}

func locale(ctx context.Context) (string, error) {
  select {
  case <-ctx.Done():
    // Эта строчка возвращает причину, по которой контекст был отменён. Эта
    // ошибка будет поочерёдно всплывать вплоть до main, что приведёт к отмене в
    // (2)
    return "", ctx.Err()
  case <-time.After(1 * time.Minute):
  }

  return "RU/RU", nil
}
```

Результат выполнения этого кода:

```
cannot print greeting: context deadline exceeded
cannot print farewell: context canceled
```

Воспользуемся нашим графом вызовов (call-graph), чтобы понять, что происходит.
Цифры здесь соответствуют комментариям в коде:

![Стек вызовов](images/call-graph-contexted.svg)

Из наших выходных данных видно, что система работает идеально. Поскольку мы
гарантируем, что выполнение `locale` не займёт менее одной минуты, наш вызов
`genGreeting` всегда будет прерываться по таймауту, что означает, что `main`
всегда будет отменять граф вызовов (call-graph) ниже `printFarewell`

<!-- TODO: тут опять в оригинальной диаграмме нет farewell -->

<!-- TODO: ниже printFarewell? откуда, как, куда? ещё раз -->

<!-- TODO: вот как бы да, мы завязались на время, 1m > 1s, но чисто теоретический
вакуумный пример, реально ли мы именно теоретически можно обоснованно
утверждать, что мы решили вот такой race condition? -->

Следует обратить внимание, как `genGreeting` смог создать кастомный
`context.Context` для своих нужд, не затрагивая родительский контекст. Если
`genGreeting` сможет успешно завершить работу и вернуть необходимое приветствие,
и `printGreeting` потребуется сделать ещё один вызов, он сможет сделать это, не
раскрывая информацию о том, как работает `genGreeting`. Такая возможность
композиции позволяет нам создавать большие системы, не смешивая различные
аспекты в нашем графе вызовов (call-graph).

<!-- TODO: что значит здесь не раскрывая инфу о том, как работает genGreeting? -->

<!-- TODO: не смешивая (различные аспекты)...? -->

Мы можем внести ещё одно усовершенствование в эту программу: поскольку мы знаем,
что запуск `locale` занимает примерно одну минуту, в `locale` мы можем
проверить, установлен ли дедлайн, и если ла, то уложимся ли мы в него. В этом
примере показано, как использовать метод `Deadline` у `context.Context` для
этого
([`code-samples/context-package/improved-contexted/greeting-and-farewell.go`](code-samples/context-package/improved-contexted/greeting-and-farewell.go)):

```go
func main() {
  var wg sync.WaitGroup

  ctx, cancel := context.WithCancel(context.Background())
  defer cancel()

  wg.Add(1)
  go func() {
    defer wg.Done()

    if err := printGreeting(ctx); err != nil {
      fmt.Printf("cannot print greeting: %v\n", err)

      cancel()
    }
  }()

  wg.Add(1)
  go func() {
    defer wg.Done()

    if err := printFarewell(ctx); err != nil {
      fmt.Printf("cannot print farewell: %v\n", err)
    }
  }()

  wg.Wait()
}

func printGreeting(ctx context.Context) error {
  greeting, err := genGreeting(ctx)
  if err != nil {
    return err
  }

  fmt.Printf("%s, мир!\n", greeting)

  return nil
}

func printFarewell(ctx context.Context) error {
  farewell, err := genFarewell(ctx)
  if err != nil {
    return err
  }

  fmt.Printf("%s, мир!\n", farewell)

  return nil
}

func genGreeting(ctx context.Context) (string, error) {
  ctx, cancel := context.WithTimeout(ctx, 1*time.Second)
  defer cancel()

  switch locale, err := locale(ctx); {
  case err != nil:
    return "", err
  case locale == "RU/RU":
    return "Привет", nil
  }

  return "", errors.New("unsupported locale")
}

func genFarewell(ctx context.Context) (string, error) {
  switch locale, err := locale(ctx); {
  case err != nil:
    return "", err
  case locale == "RU/RU":
    return "Пока", nil
  }

  return "", errors.New("unsupported locale")
}

func locale(ctx context.Context) (string, error) {
  // Здесь мы проверяем, установлен ли в нашем `Context` дедлайн. Если
  // установлен, и наши системные часы превысили дедлайн, мы просто
  // возвращаемся из функции со специальной ошибкой DeadlineExceeded,
  // определённой в пакете context
  if deadline, ok := ctx.Deadline(); ok {
    if time.Now().Add(1 * time.Minute).After(deadline) {
      return "", context.DeadlineExceeded
    }
  }

  select {
  case <-ctx.Done():
    return "", ctx.Err()
  case <-time.After(1 * time.Minute):
  }

  return "RU/RU", nil
}
```

Хотя разница в этой итерации программы невелика, она приводит к быстрому сбою
функции `locale`. В программах, которые могут потребовать больших затрат на
вызов следующего элемента функциональности, это может сэкономить значительное
количество времени. По крайней мере, это позволяет немедленно завершить работу
функции, вместо того, чтобы ждать фактического наступления таймаута.
Единственная загвоздка заключается в том, что мы должны иметь некоторое
представление, сколько времени займёт субординированный граф вызовов
(call-graph) — упражнение, которое может быть довольно сложным.

Это подводит нас ко второй половине того, что предоставляет пакет `context`:
предоставляет контейнер (data-bag) для `Context` для хранения и извлечения
специфичных для запроса данных. Следует помнить, что часто, когда функция
создаёт горутину и `Context`, она запускает процесс, который будет обслуживать
запросы, и функции дальше по стеку могут нуждаться в информации о запросе. Вот
пример того, как сохранять данные внутри `Context` и как их извлекать
([`code-samples/context-package/with-value/main.go`](code-samples/context-package/with-value/main.go)):

```go
const (
  CtxKeyUserID    = "user_id"
  CtxKeyAuthToken = "auth_token"
)

func main() {
  ProcessRequest("shuryak", "secret")
}

func ProcessRequest(userID, authToken string) {
  ctx := context.WithValue(context.Background(), CtxKeyUserID, userID)
  ctx = context.WithValue(ctx, CtxKeyAuthToken, authToken)
  HandleResponse(ctx)
}

func HandleResponse(ctx context.Context) {
  fmt.Printf(
    "handling response from %s (auth: %s)\n",
    ctx.Value(CtxKeyUserID),
    ctx.Value(CtxKeyAuthToken),
  )
}
```

Этот код производит:

```
handling response from shuryak (auth: secret)
```

Довольно простая штука. Единственное условие — это то, что:

- Используемый ключ должен удовлетворять интерфейсу `comparable` (в исходниках
  Go `src/builtin/builtin.go`), то есть операторы равенства `==` и `!=` должны
  возвращать корректные результаты при использовании
- Возвращаемые значения должны быть безопасны для доступа из нескольких горутин

Поскольку и ключ, и значение `Context`'а определены как `interface{}`, мы теряем
типобезопасность Go при попытке извлечь значения. Ключ может быть другого типа
или немного отличаться от предоставляемого нами ключи. Значение можно быть
другого типа. По этим причинам авторы Go рекомендуют соблюдать несколько правил
при сохранении и извлечении значений из `Context`.

Во-первых, они рекомендуют определить кастомный тип ключа в нашем пакете. Если
другие пакеты пакеты делают то же самое, это предотвращает коллизии в `Context`.
В качестве напоминания о том, почему, рассмотрим небольшую программу, которая
пытается сохранить ключи в мапе, которая имеют разные типы, но одинаковое
базовое значение:

```go
type foo int
type bar int

m := make(map[interface{}]int)
m[foo(1)] = 1
m[bar(1)] = 2

fmt.Println(m)
```

Этот код произведёт:

```go
map[1:2 1:1]
```

Можно видеть, что, хотя базовые значения одинаковы, информация о разных типах
вносит в них различие в пределах мапы. Поскольку тип, который мы определяем для
ключей нашего пакета, не является экспортируемым (их название начинается со
строчной буквы), другие пакеты не могут коллизировать с ключами, которые мы
генерируем в своём пакете.

Поскольку мы не экспортируем ключи, которые используем для хранения данных, мы
должны экспортировать функции, которые извлекают данные для нас. Это хорошо
работает, поскольку позволяет пользователям этих данных использовать
статические, типобезопасные функции.

Если мы соединим это вместе, получится следующий пример
([](code-samples/context-package/with-value-type-safe/main.go)):

```go
func main() {
	ProcessRequest("shuryak", "secret")
}

type ctxKey int

const (
	ctxUserID ctxKey = iota
	ctxAuthToken
)

func UserID(c context.Context) string {
	return c.Value(ctxUserID).(string)
}

func AuthToken(c context.Context) string {
	return c.Value(ctxAuthToken).(string)
}

func ProcessRequest(userID, authToken string) {
	ctx := context.WithValue(context.Background(), ctxUserID, userID)
	ctx = context.WithValue(ctx, ctxAuthToken, authToken)
	HandleResponse(ctx)
}

func HandleResponse(ctx context.Context) {
	fmt.Printf(
		"handling response for %s (auth: %s)\n",
		UserID(ctx),
		AuthToken(ctx),
	)
}
```

Этот код произведёт:

```
handling response for shuryak (auth: secret)
```

Теперь у нас есть типобезопасный способ извлечения значений из `Context`, и если
бы пользователи были в другом пакете, они бы не знали и не заботились о том,
какие ключи использовались для хранения информации. Однако эта техника создаёт
проблему.

В предыдущем примере, предположим, что `HandleResponse` действительно содержался
в другом пакете с именем `response`, а `ProcessRequest` содержался бы в пакете с
именем `process`. Пакет `process` должен был бы импортировать пакет `response`,
чтобы вызвать `HandleResponse`, но у `HandleResponse` бы не было возможности
получить доступ к функциям-аксессорам, определённым в пакете `process`,
поскольку импорт сформировал бы циклическую зависимость. Поскольку типы,
используемые для хранения ключей в `Context`, являются приватными в пакете
`process`, пакет `response` не имеет возможности получить эти данные!

Это вынуждает архитектуру создавать пакеты, ориентированные на типы данных,
которые импортируются из нескольких мест. Это, конечно, неплохо, но об этом
следует помнить.

Пакет `context` довольно удобен, но не все его единодушно оценили. В коммьюнити
Go в пакете `context` возникли некоторые разногласия. Аспект пакета, связанный с
отменой (cancellation) был воспринят довольно хорошо, но возможность хранить
произвольные данные в `Context` и нетипобезопасный способ хранения данных
взывали споры. Хотя мы частично устранили недостаток безопасности типов с
помощью наших функций-аксессоров, мы всё ещё можем создавать баги, сохраняя
неправильные типы. Однако более серьёзной проблемой, безусловно, является
природа того, _что_ разработчикам следует хранить в инстансах `Context`

Наиболее распространённым руководством того, что хранить уместно, является этот
несколько двусмысленный комментарий в пакете `context`:

```go
// Use context Values only for request-scoped data that transits processes and
// APIs, not for passing optional parameters to functions.
```

> Перевод комментария на русский язык:
>
> Используйте значения (Values, имеется ввиду `WithValue`) контекста только для
> специфичных для запроса данных, которые проходят через процессы и границы API,
> а не для передачи необязательных параметров функциям.

Довольно ясно, что такое необязательный параметры (мы не должны использовать
`Context` для выполнения своего тайного желания о том, чтобы Go поддерживал
необязательные параметры), но что такое «специфичные для запроса данные»?
Предположительно, это то, что «проходит через процессы и границы API», но это
может описывать множество вещей. В книге предлагается такой способ определить
это: разработать некоторые эвристические методы со своей командой и оценивать
это на код ревью. Эвристические методы автора книги:

1. Данные должны передаваться через границы процесса или API.

   Если мы генерируем данные в памяти нашего процесса, то, вероятно, это не
   самый лучший кандидат, чтобы стать специфичными для запроса данными, если мы
   также не передаём их через границы API.

2. Данные должны быть неизменяемыми (immutable).

   Если это не так, то по определению то, что мы сохраняем, не было получено из
   запроса.

3. Данные должны быть ориентированы на простые типы.

   Если специфичные для запроса данные предназначены для передачи через границы
   процесса и API. то другой стороне гораздо проще извлечь эти данные, если ей
   также не нужно импортировать сложный граф пакетов.

4. Данные должны быть даннами, а не типами с методами.

   Операции — это логика и относятся к вещам, которые принимают эти данные.

5. Данные должны помогать декорировать операции, а не управлять (drive) данными

   Если наш алгоритм ведёт себя по-разному в зависимости от того, что включено
   или не включено в его `Context`, мы, скорее всего, перешли на территорию
   необязательных параметров.

Это не жёсткие правила, это эвристика. Однако, если мы обнаружим, что данные,
которые мы храним в `Context`, нарушают все эти пять рекомендаций, возможно, нам
захочется хорошенько подумать о том, что мы собираемся делать.

Ещё один аспект, который следует учитывать, — это то, сколько слоёв этим данным
может потребоваться пройти перед непосредственным использованием. Если между
моментом, когда данные принимаются, и моментом их использования есть несколько
фреймворков и десятки функций, захотим ли мы использовать подробные,
самодокументирующиеся сигнатуры функций и добавлять данные в качестве параметры?
Или мы бы предпочли поместить это в `Context` и тем самым создать невидимую
зависимость? У каждого подхода есть свои преимущества, и в конечном итоге это
решение придётся принимать нам и нашей команде.

Даже с учётом этих эвристических методов, остаётся сложным ответить на вопрос,
относится ли значение к специфичным для запроса данным. Взглянем на следующую
таблицу. В ней приведены мнения автора книги о том, соответствует ли каждый тип
данных пяти перечисленным выше эвристическим методам:

| Данные                    | 1   | 2   | 3   | 4   | 5   |
| ------------------------- | --- | --- | --- | --- | --- |
| ID запроса                | +   | +   | +   | +   | +   |
| ID пользователя           | +   | +   | +   | +   |     |
| URL                       | +   | +   |     |     |     |
| Подключение к серверу API |     |     |     |     |     |
| Токен авторизации         | +   | +   | +   | +   |     |
| Токен запроса             | +   | +   | +   |     |     |

Иногда ясно, что что-то не должно храниться в `Context`, как это происходит к
подключениями к серверу API, но иногда это не так очевидно. Как насчёт токена
авторизации? Он неизменяем (immutable) и, скорее всего, представляет собой слайс
байт, но не будут ли получатели этих данных использовать его для определения,
следует ли обрабатывать запрос? Принадлежит ли эта информация `Context`'у?
Ситуация ещё больше запутана тем, что то, что приемлемо для одной команды, может
быть неприемлемо для другой.

В конечном счёте, здесь нет простых ответов. Пакет был добавлен в стандартную
библиотеку, и поэтому мы должны составить _некоторое_ мнение о его
использовании, но это мнение может (и, вероятно, должно) измениться в
зависимости от того, к какому проекту мы обращаемся. Последний совет от автора
книги по этому поводу — функциональность отмены (cancellation), предоставляемая
`Context`, очень полезна, и наши чувства по поводу аспекта контейнера (data-bag)
не должны удерживать нас от её использования.
